# -*- coding: utf-8 -*-
"""
Market Cockpit Pro - Unified Utils Module
è¨­å®šã€ãƒ‡ãƒ¼ã‚¿å–å¾—ã€è¡¨ç¤ºé–¢æ•°ã‚’çµ±åˆ
"""

import streamlit as st
import pandas as pd
import pandas_datareader.data as web
import yfinance as yf
import datetime
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import feedparser
import os
import requests
import re
import json
import uuid
import pickle
import time
from io import StringIO
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# ========== API KEYS & SETTINGS ==========
FRED_API_KEY = "4e9f89c09658e42a4362d1251d9a3d05"
PAGE_TITLE = "Market Cockpit Pro"
MANUAL_DATA_FILE = "manual_h41_data.csv"

# AI Model Names
GEMINI_MODEL = "gemini-3-flash-preview"
CLAUDE_MODEL = "claude-opus-4-5-20251101"

# ========== DATA FRESHNESS MONITORING ==========
DATA_FRESHNESS_RULES = {
    'daily': {
        'fresh': 3, 'stale': 7, 'critical': 14,
        'indicators': ['EFFR', 'IORB', 'SOFR', 'SP500', 'VIX', 'HYG', 'DXY', 'USDJPY', 
                      'EURUSD', 'USDCNY', 'Gold', 'Silver', 'Oil', 'Copper', 'BTC', 'ETH',
                      'Credit_Spread', 'US_TNX', 'T10Y2Y', 'ON_RRP', 'FedFundsUpper', 'FedFundsLower']
    },
    'weekly': {
        'fresh': 10, 'stale': 14, 'critical': 21,
        'indicators': ['Reserves', 'TGA', 'Fed_Assets', 'SOMA_Total', 'SOMA_Bills', 
                      'SRF', 'FIMA', 'Primary_Credit', 'Total_Loans', 'Bank_Cash', 'ICSA',
                      'Net_Liquidity', 'SomaBillsRatio', 'CRE_Loans']
    },
    'monthly': {
        'fresh': 45, 'stale': 60, 'critical': 90,
        'indicators': ['M2SL', 'M2REAL', 'CPI', 'CPICore', 'PPI', 'Unemployment', 'UNRATE', 'CorePCE', 
                      'ConsumerSent', 'CN_M2', 'JP_M2', 'EU_M2', 'NFP', 'ADP', 'AvgHourlyEarnings', 'JOLTS',
                      'RetailSales', 'CN_CPI', 'JP_CPI', 'EU_CPI', 'US_Real_M2_Index', 'CI_Loans']
    },
    'quarterly': {
        'fresh': 100, 'stale': 120, 'critical': 150,
        'indicators': ['Lending_Standards', 'CI_Std_Large', 'CI_Std_Small', 'CI_Demand',
                      'CRE_Std_Construction', 'CRE_Std_Office', 'CRE_Std_Multifamily', 'CRE_Demand', 'RealGDP']
    }
}

# ========== DATA FREQUENCY LABELS ==========
DATA_FREQUENCY = {
    'EFFR': 'æ—¥æ¬¡', 'IORB': 'æ—¥æ¬¡', 'SOFR': 'æ—¥æ¬¡', 'SP500': 'æ—¥æ¬¡', 'VIX': 'æ—¥æ¬¡', 
    'HYG': 'æ—¥æ¬¡', 'DXY': 'æ—¥æ¬¡', 'USDJPY': 'æ—¥æ¬¡', 'EURUSD': 'æ—¥æ¬¡', 'USDCNY': 'æ—¥æ¬¡',
    'Gold': 'æ—¥æ¬¡', 'Silver': 'æ—¥æ¬¡', 'Oil': 'æ—¥æ¬¡', 'Copper': 'æ—¥æ¬¡', 'BTC': 'æ—¥æ¬¡', 'ETH': 'æ—¥æ¬¡',
    'Credit_Spread': 'æ—¥æ¬¡', 'US_TNX': 'æ—¥æ¬¡', 'T10Y2Y': 'æ—¥æ¬¡', 'ON_RRP': 'æ—¥æ¬¡',
    'FedFundsUpper': 'æ—¥æ¬¡', 'FedFundsLower': 'æ—¥æ¬¡',
    'Reserves': 'é€±æ¬¡', 'TGA': 'é€±æ¬¡', 'Fed_Assets': 'é€±æ¬¡', 'SOMA_Total': 'é€±æ¬¡', 'SOMA_Bills': 'é€±æ¬¡',
    'SRF': 'é€±æ¬¡', 'FIMA': 'é€±æ¬¡', 'Primary_Credit': 'é€±æ¬¡', 'Total_Loans': 'é€±æ¬¡', 
    'Bank_Cash': 'é€±æ¬¡', 'ICSA': 'é€±æ¬¡', 'Net_Liquidity': 'é€±æ¬¡', 'SomaBillsRatio': 'é€±æ¬¡',
    'M2SL': 'æœˆæ¬¡', 'M2REAL': 'æœˆæ¬¡', 'CPI': 'æœˆæ¬¡', 'CPICore': 'æœˆæ¬¡', 'PPI': 'æœˆæ¬¡', 
    'Unemployment': 'æœˆæ¬¡', 'UNRATE': 'æœˆæ¬¡', 'CorePCE': 'æœˆæ¬¡', 'ConsumerSent': 'æœˆæ¬¡', 
    'CN_M2': 'æœˆæ¬¡', 'JP_M2': 'æœˆæ¬¡', 'EU_M2': 'æœˆæ¬¡', 'CN_CPI': 'æœˆæ¬¡', 'JP_CPI': 'æœˆæ¬¡', 
    'EU_CPI': 'æœˆæ¬¡', 'US_Real_M2_Index': 'æœˆæ¬¡', 'NFP': 'æœˆæ¬¡', 'ADP': 'æœˆæ¬¡',
    'AvgHourlyEarnings': 'æœˆæ¬¡', 'JOLTS': 'æœˆæ¬¡', 'RetailSales': 'æœˆæ¬¡', 'CI_Loans': 'æœˆæ¬¡',
    'Lending_Standards': 'å››åŠæœŸ', 'RealGDP': 'å››åŠæœŸ',
    'CI_Std_Large': 'å››åŠæœŸ', 'CI_Std_Small': 'å››åŠæœŸ', 'CI_Demand': 'å››åŠæœŸ',
    'CRE_Std_Construction': 'å››åŠæœŸ', 'CRE_Std_Office': 'å››åŠæœŸ', 
    'CRE_Std_Multifamily': 'å››åŠæœŸ', 'CRE_Demand': 'å››åŠæœŸ', 'CRE_Loans': 'é€±æ¬¡',
}

# ========== FRED INDICATORS MAPPING ==========
FRED_INDICATORS = {
    'ON_RRP': 'RRPONTSYD', 'Reserves': 'WRESBAL', 'TGA': 'WTREGEN',
    'Fed_Assets': 'WALCL', 'SOMA_Total': 'WALCL', 'SOMA_Bills': 'TREAST',
    'EFFR': 'EFFR', 'IORB': 'IORB',
    'Bank_Cash': 'CASACBW027SBOG', 'Lending_Standards': 'DRTSCILM',
    'CI_Std_Large': 'DRTSCILM', 'CI_Std_Small': 'DRTSCIS', 'CI_Demand': 'DRTSCLCC', 'CI_Loans': 'BUSLOANS',
    'CRE_Std_Construction': 'SUBLPDRCSC', 'CRE_Std_Office': 'DRTSSP', 
    'CRE_Std_Multifamily': 'DRTSSP', 'CRE_Demand': 'DRTSCLCC', 'CRE_Loans': 'CREACBW027SBOG',
    'SRF': 'WORAL', 'FIMA': 'H41RESPPALGTRFNWW', 'SOFR': 'SOFR',
    'Primary_Credit': 'WLCFLPCL', 'Total_Loans': 'WLCFLL',
    'Credit_Spread': 'BAMLH0A0HYM2', 'US_TNX': 'DGS10',
    'Unemployment': 'UNRATE', 'CPI': 'CPIAUCSL', 'M2SL': 'M2SL', 'M2REAL': 'M2REAL',
    'CN_M2': 'MYAGM2CNM189N', 'JP_M2': 'MANMM101JPM189S', 'EU_M2': 'MABMM301EZM189S',
    'CN_CPI': 'CHNCPIALLMINMEI', 'JP_CPI': 'JPNCPIALLMINMEI', 'EU_CPI': 'CP0000EZ19M086NEST',
    'T10Y2Y': 'T10Y2Y', 'ICSA': 'ICSA', 'UNRATE': 'UNRATE',
    'CorePCE': 'PCETRIM12M159SFRBDAL', 'ConsumerSent': 'UMCSENT',
    'FedFundsUpper': 'DFEDTARU', 'FedFundsLower': 'DFEDTAR',
    'NFP': 'PAYEMS', 'ADP': 'ADPWNUSNERSA', 'AvgHourlyEarnings': 'CES0500000003', 'JOLTS': 'JTSJOL',
    'CPICore': 'CPILFESL', 'PPI': 'PPIACO', 'RetailSales': 'RSAFS', 'RealGDP': 'GDPC1',
}

# ========== YAHOO FINANCE INDICATORS ==========
YAHOO_INDICATORS = {
    'SP500': '^GSPC', 'VIX': '^VIX', 'HYG': 'HYG',
    'DXY': 'DX-Y.NYB', 'USDJPY': 'JPY=X', 'EURUSD': 'EURUSD=X', 'USDCNY': 'CNY=X',
    'Gold': 'GC=F', 'Silver': 'SI=F', 'Oil': 'CL=F', 'Copper': 'HG=F',
    'BTC': 'BTC-USD', 'ETH': 'ETH-USD',
}

# ========== EXPLANATIONS (67é …ç›®ã®è©³ç´°èª¬æ˜) ==========
EXPLANATIONS = {
    # === H.4.1 / Fed Balance Sheet ===
    "Net_Liquidity": "ã€ãƒãƒƒãƒˆãƒªã‚¯ã‚¤ãƒ‡ã‚£ãƒ†ã‚£ã€‘\nå¸‚å ´ã«å‡ºå›ã‚‹ã€ŒçœŸã®è³‡é‡‘é‡ã€ã€‚(FRBç·è³‡ç”£ - TGA - RRP) ã§è¨ˆç®—ã•ã‚Œã¾ã™ã€‚æ ªå¼å¸‚å ´ã¨å¼·ã„ç›¸é–¢ãŒã‚ã‚Šã€å¢—åŠ ã¯æ ªé«˜ã€æ¸›å°‘ã¯æ ªå®‰ã‚’ç¤ºå”†ã€‚",
    "Reserves": "ã€éŠ€è¡Œæº–å‚™é é‡‘ã€‘\næ°‘é–“éŠ€è¡ŒãŒFRBã«é ã‘ã¦ã„ã‚‹ãŠé‡‘ã€‚ã“ã‚ŒãŒæ¸›ã‚Šã™ãã‚‹ã¨ã‚·ãƒ§ãƒƒã‚¯ãŒèµ·ãã‚„ã™ããªã‚Šã¾ã™ã€‚ã€Œæ½¤æ²¢ï¼ˆampleï¼‰ã€ãƒ¬ãƒ™ãƒ«ã®ç¶­æŒãŒFRBã®ç›®æ¨™ã€‚",
    "TGA": "ã€TGA (è²¡å‹™çœä¸€èˆ¬å£åº§)ã€‘\næ”¿åºœã®éŠ€è¡Œå£åº§ã€‚ã“ã“ãŒå¢—ãˆã‚‹ã¨å¸‚å ´ã‹ã‚‰è³‡é‡‘ãŒå¸ã„ä¸Šã’ã‚‰ã‚Œã¾ã™ã€‚è²¡æ”¿æ”¯å‡ºæ™‚ã«æ”¾å‡ºã•ã‚Œã€å¸‚å ´ã«æµå‹•æ€§ã‚’ä¾›çµ¦ã€‚",
    "ON_RRP": "ã€ON RRP (ç¿Œæ—¥ç‰©ãƒªãƒãƒ¼ã‚¹ãƒ¬ãƒ)ã€‘\nMMFãªã©ãŒFRBã«ãŠé‡‘ã‚’é ã‘ã‚‹å ´æ‰€ã€‚ä½™å‰°è³‡é‡‘ã®æ»ç•™ã‚’ç¤ºã—ã¾ã™ã€‚ã‚¼ãƒ­ã«è¿‘ã¥ãã¨ã€Œæµå‹•æ€§ã®ç·©è¡æã€ãŒãªããªã‚Šã€å¸‚å ´ã‚¹ãƒˆãƒ¬ã‚¹ãŒé«˜ã¾ã‚Šã‚„ã™ã„ã€‚",
    "Fed_Assets": "ã€FRBç·è³‡ç”£ã€‘\nFRBã®ãƒãƒ©ãƒ³ã‚¹ã‚·ãƒ¼ãƒˆè¦æ¨¡ã€‚QEã§æ‹¡å¤§ã€QTã§ç¸®å°ã€‚å¸‚å ´æµå‹•æ€§ã®æ ¹å¹¹ã€‚",
    "SOMA_Total": "ã€SOMAç·è³‡ç”£ã€‘\nFRBãŒä¿æœ‰ã™ã‚‹å›½å‚µã‚„MBSã®ç·é¡ã€‚ã“ã‚ŒãŒå¢—ãˆã‚‹=QEï¼ˆé‡çš„ç·©å’Œï¼‰ã€æ¸›ã‚‹=QTï¼ˆé‡çš„å¼•ãç· ã‚ï¼‰ã§ã™ã€‚",
    "SOMA_Bills": "ã€SOMA Bills (çŸ­æœŸå›½å‚µ)ã€‘\nFRBãŒä¿æœ‰ã™ã‚‹çŸ­æœŸå›½å‚µï¼ˆT-Billsï¼‰ã€‚2025å¹´12æœˆ12æ—¥ã‹ã‚‰RMPï¼ˆReserve Management Purchasesï¼‰ã¨ã—ã¦æœˆé¡400å„„ãƒ‰ãƒ«ãƒšãƒ¼ã‚¹ã§è²·ã„å…¥ã‚Œä¸­ã€‚QTçµ‚äº†å¾Œã®æº–å‚™é‡‘ç¶­æŒãŒç›®çš„ã ãŒã€å®Ÿè³ªçš„ãªè³‡é‡‘ä¾›çµ¦ã¨ãªã‚‹ã€‚",
    "SomaBillsRatio": "ã€SOMA Billsæ¯”ç‡ã€‘\nFRBã®ç·è³‡ç”£ã«å ã‚ã‚‹çŸ­æœŸå›½å‚µã®å‰²åˆã€‚RMPå®Ÿè¡Œã«ã‚ˆã‚Šä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ã¨ãªã‚‹ã€‚FRBã¯ã€ŒæŠ€è¡“çš„æªç½®ã€ã¨ä¸»å¼µã™ã‚‹ãŒã€å¸‚å ´ã¸ã®æµå‹•æ€§ä¾›çµ¦åŠ¹æœã¯QEã«é¡ä¼¼ã€‚",
    
    # === Market Plumbing / Repo ===
    "SRF": "ã€Standing Repo Facilityã€‘\nå›½å†…ã®é‡‘èæ©Ÿé–¢ãŒå›½å‚µã‚’æ‹…ä¿ã«ç¾é‡‘ã‚’å€Ÿã‚Šã‚‹å¸¸è¨­çª“å£ã€‚ãƒªãƒå¸‚å ´ã®ç›®è©°ã¾ã‚Šã‚’æ¤œçŸ¥ã—ã¾ã™ã€‚åˆ©ç”¨å¢—åŠ ã¯çŸ­æœŸé‡‘èå¸‚å ´ã®ã‚¹ãƒˆãƒ¬ã‚¹ä¸Šæ˜‡ã‚’ç¤ºå”†ã€‚",
    "FIMA": "ã€FIMA Repo Facilityã€‘\næµ·å¤–ã®ä¸­å¤®éŠ€è¡Œå‘ã‘èè³‡ã€‚ä¸–ç•Œçš„ãªãƒ‰ãƒ«ä¸è¶³ãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã‹ã‚’æ¸¬ã‚‹æŒ‡æ¨™ã§ã™ã€‚æ–°èˆˆå›½ã®é€šè²¨å±æ©Ÿã‚„ãƒ‰ãƒ«æµå‹•æ€§å±æ©Ÿã®å…ˆè¡ŒæŒ‡æ¨™ã€‚",
    "Primary_Credit": "ã€Primary Credit (ä¸€æ¬¡ä¿¡ç”¨)ã€‘\nå¥å…¨ãªéŠ€è¡Œå‘ã‘ã®ç·Šæ€¥èè³‡ã€‚æ€¥å¢—æ™‚ã¯éŠ€è¡ŒãŒå¸‚å ´ã§ç¾é‡‘ã‚’èª¿é”ã§ããªããªã£ã¦ã„ã‚‹å±é™ºä¿¡å·ã§ã™ã€‚2023å¹´SVBå±æ©Ÿæ™‚ã«æ€¥å¢—ã€‚",
    "Total_Loans": "ã€Total Loans (èè³‡ç·é¡)ã€‘\nFRBã«ã‚ˆã‚‹é‡‘èæ©Ÿé–¢ã¸ã®è²¸å‡ºç·é¡ã€‚å¸‚å ´ã®ç·Šæ€¥äº‹æ…‹ã‚’æ¸¬ã‚‹ç·åˆæŒ‡æ¨™ã§ã™ã€‚ãƒ‡ã‚£ã‚¹ã‚«ã‚¦ãƒ³ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®åˆ©ç”¨çŠ¶æ³ã‚’ç¤ºã™ã€‚",
    "Primary": "ã€Primary Creditã€‘\nå¥å…¨ãªéŠ€è¡Œå‘ã‘ã®ç·Šæ€¥èè³‡ã€‚æ€¥å¢—æ™‚ã¯éŠ€è¡ŒãŒå¸‚å ´ã§ç¾é‡‘ã‚’èª¿é”ã§ããªããªã£ã¦ã„ã‚‹å±é™ºä¿¡å·ã§ã™ã€‚",
    "Window": "ã€Total Loansã€‘\nFRBã«ã‚ˆã‚‹é‡‘èæ©Ÿé–¢ã¸ã®è²¸å‡ºç·é¡ã€‚å¸‚å ´ã®ç·Šæ€¥äº‹æ…‹ã‚’æ¸¬ã‚‹ç·åˆæŒ‡æ¨™ã§ã™ã€‚",
    
    # === Rates / é‡‘åˆ© ===
    "EFFR": "ã€EFFR (å®ŸåŠ¹FFé‡‘åˆ©)ã€‘\néŠ€è¡Œé–“ã®ç¿Œæ—¥ç‰©è²¸å€Ÿé‡‘åˆ©ã®åŠ é‡å¹³å‡ã€‚FRBã®æ”¿ç­–é‡‘åˆ©ï¼ˆFFé‡‘åˆ©ï¼‰ãŒã©ã‚Œã ã‘å®Ÿéš›ã«åŠ¹ã„ã¦ã„ã‚‹ã‹ã‚’ç¤ºã™ã€‚IORBä»˜è¿‘ã§æ¨ç§»ã™ã‚‹ã®ãŒæ­£å¸¸ã€‚",
    "IORB": "ã€IORB (æº–å‚™é é‡‘ä»˜åˆ©)ã€‘\nFRBãŒéŠ€è¡Œã®æº–å‚™é é‡‘ã«ä»˜ä¸ã™ã‚‹é‡‘åˆ©ã€‚EFFRã®ã€Œå¤©äº•ã€ã¨ã—ã¦æ©Ÿèƒ½ã€‚EFFRãŒIORBã‚’å¤§ããä¸‹å›ã‚‹ã¨é‡‘èç’°å¢ƒã®ç·©ã¿ã€ä¸Šå›ã‚‹ã¨å¼•ãç· ã¾ã‚Šã‚’ç¤ºå”†ã€‚",
    "SOFR": "ã€SOFR (æ‹…ä¿ä»˜ç¿Œæ—¥ç‰©é‡‘åˆ©)ã€‘\nå›½å‚µã‚’æ‹…ä¿ã«ã—ãŸè³‡é‡‘èª¿é”ã‚³ã‚¹ãƒˆã€‚LIBORã«ä»£ã‚ã‚‹æ–°ãŸãªåŸºæº–é‡‘åˆ©ã€‚æ€¥é¨°ã¯ç¾é‡‘ä¸è¶³ï¼ˆãƒªãƒå¸‚å ´ã®ã‚¹ãƒˆãƒ¬ã‚¹ï¼‰ã‚’ç¤ºã—ã¾ã™ã€‚",
    "FedFundsUpper": "ã€FFé‡‘åˆ©ä¸Šé™ã€‘\nFRBãŒè¨­å®šã™ã‚‹ãƒ•ã‚§ãƒ‡ãƒ©ãƒ«ãƒ•ã‚¡ãƒ³ãƒ‰é‡‘åˆ©ã®èª˜å°ç›®æ¨™ä¸Šé™ã€‚",
    "FedFundsLower": "ã€FFé‡‘åˆ©ä¸‹é™ã€‘\nFRBãŒè¨­å®šã™ã‚‹ãƒ•ã‚§ãƒ‡ãƒ©ãƒ«ãƒ•ã‚¡ãƒ³ãƒ‰é‡‘åˆ©ã®èª˜å°ç›®æ¨™ä¸‹é™ã€‚",
    "US_TNX": "ã€ç±³å›½10å¹´å‚µåˆ©å›ã‚Šã€‘\né•·æœŸé‡‘åˆ©ã®æŒ‡æ¨™ã€‚ä½å®…ãƒ­ãƒ¼ãƒ³ã‚„ä¼æ¥­å€Ÿå…¥ã‚³ã‚¹ãƒˆã«å½±éŸ¿ã€‚æ™¯æ°—æœŸå¾…ãƒ»ã‚¤ãƒ³ãƒ•ãƒ¬æœŸå¾…ã‚’åæ˜ ã€‚",
    "T10Y2Y": "ã€2å¹´-10å¹´ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ï¼ˆã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–ï¼‰ã€‘\né€†ã‚¤ãƒ¼ãƒ«ãƒ‰ï¼ˆãƒã‚¤ãƒŠã‚¹ï¼‰ã¯ãƒªã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å¼·åŠ›ãªå…ˆè¡ŒæŒ‡æ¨™ã€‚æ­£å¸¸åŒ–ï¼ˆãƒ—ãƒ©ã‚¹è»¢æ›ï¼‰å¾Œã®æ™¯æ°—å¾Œé€€ã«æ³¨æ„ã€‚",
    "Credit_Spread": "ã€ãƒã‚¤ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã€‘\nã‚¸ãƒ£ãƒ³ã‚¯å‚µã¨å›½å‚µã®é‡‘åˆ©å·®ã€‚ä¿¡ç”¨ãƒªã‚¹ã‚¯ã®ãƒãƒ­ãƒ¡ãƒ¼ã‚¿ãƒ¼ã€‚æ‹¡å¤§ã¯ä¿¡ç”¨åç¸®ã€ç¸®å°ã¯ãƒªã‚¹ã‚¯ã‚ªãƒ³ã€‚",
    
    # === Banking Sector / éŠ€è¡Œã‚»ã‚¯ã‚¿ãƒ¼ ===
    "Bank_Cash": "ã€éŠ€è¡Œã®ç¾é‡‘ä¿æœ‰ã€‘\nå…¨ç±³ã®éŠ€è¡ŒãŒä¿æœ‰ã™ã‚‹ç¾é‡‘è³‡ç”£ã®æ¨ç§»ã€‚éŠ€è¡ŒãŒä¸å®‰ã‚’æ„Ÿã˜ã¦ç¾é‡‘ã‚’æŠ±ãˆè¾¼ã¿å§‹ã‚ã‚‹ã¨å¸‚å ´ã®æµå‹•æ€§ãŒä½ä¸‹ã—ã¾ã™ã€‚å±æ©Ÿã®å…ˆè¡ŒæŒ‡æ¨™ã€‚",
    "Lending_Standards": "ã€C&I Lending Tightening / å•†å·¥æ¥­èè³‡åŸºæº–ã®å³æ ¼åŒ–ã€‘\néŠ€è¡Œã®èè³‡æ…‹åº¦ã‚’ç¤ºã™ç´”å‰²åˆï¼ˆNet %ï¼‰ã€‚0ãŒä¸­ç«‹ã€+ã¯å¼•ãç· ã‚ï¼ˆèè³‡åŸºæº–ã‚’å³ã—ãã™ã‚‹éŠ€è¡ŒãŒå¤šã„ï¼‰ã€âˆ’ã¯ç·©å’Œã€‚æ•°å€¤ä¸Šæ˜‡ã¯ä¿¡ç”¨åç¸®ã‚’ç¤ºã—ã€æ™¯æ°—å¾Œé€€ã®å…ˆè¡ŒæŒ‡æ¨™ã¨ã—ã¦é‡è¦ã€‚",
    "VIX": "ã€VIXæŒ‡æ•° (ææ€–æŒ‡æ•°)ã€‘\nS&P500ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‹ã‚‰ç®—å‡ºã•ã‚Œã‚‹ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æŒ‡æ•°ã€‚20ä»¥ä¸Šã§å¸‚å ´ã®ä¸å®‰ãŒé«˜ã¾ã£ã¦ã„ã‚‹çŠ¶æ…‹ã€‚30è¶…ã¯ææ€–ã€12ä»¥ä¸‹ã¯éåº¦ã®æ¥½è¦³ã€‚",
    
    # === SLOOS - C&I Lending (å•†å·¥æ¥­èè³‡) ===
    "CI_Std_Large": "ã€C&Ièè³‡åŸºæº–ï¼ˆå¤§ãƒ»ä¸­å …ä¼æ¥­ï¼‰ã€‘\n0ã‚’è¶…ãˆã‚‹ã¨è²¸ã—æ¸‹ã‚Šã€‚40%è¶…ã§å¼·åŠ›ãªãƒªã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚°ãƒŠãƒ«ã€‚ãƒªã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å…ˆè¡ŒæŒ‡æ¨™ï¼ˆ20%è¶…ã§è­¦æˆ’ï¼‰ã€‚",
    "CI_Std_Small": "ã€C&Ièè³‡åŸºæº–ï¼ˆå°ä¼æ¥­ï¼‰ã€‘\nä¸­å°ä¼æ¥­ã®è³‡é‡‘ç¹°ã‚Šã¨é›‡ç”¨ã®å…ˆè¡ŒæŒ‡æ¨™ã€‚å°ä¼æ¥­å‘ã‘ãŒå…ˆã«æ‚ªåŒ–ã™ã‚‹å ´åˆã¯é›‡ç”¨æ‚ªåŒ–ã«æ³¨æ„ã€‚ä¸­å°ä¼æ¥­ã¯æ™¯æ°—ã«æ•æ„Ÿã€‚",
    "CI_Demand": "ã€C&Ièè³‡éœ€è¦ï¼ˆå¤§ãƒ»ä¸­å …ä¼æ¥­ï¼‰ã€‘\nä¼æ¥­ã®è¨­å‚™æŠ•è³‡æ„æ¬²ã‚’æ¸¬å®šã€‚åŸºæº–ãŒç·©ã‚“ã§ã‚‚éœ€è¦ãŒä½ã„å ´åˆã¯ä¼æ¥­ãŒå°†æ¥ã‚’æ‚²è¦³ã€‚åŸºæº–ã¨éœ€è¦ã®ã€Œä¹–é›¢ã€ãŒæœ€å¤§ã®æ³¨ç›®ç‚¹ã€‚",
    "CI_Loans": "ã€C&Ièè³‡æ®‹é«˜ã€‘\nå•†å·¥æ¥­å‘ã‘èè³‡ã®ç·é¡ã€‚èè³‡åŸºæº–å³æ ¼åŒ–å¾Œã«ã“ã®æ®‹é«˜ãŒæ¸›å°‘ã™ã‚‹ã¨ã€Œã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚¯ãƒ©ãƒ³ãƒï¼ˆä¿¡ç”¨åç¸®ï¼‰ã€é–‹å§‹ã®ã‚µã‚¤ãƒ³ã€‚",
    
    # === SLOOS - CRE Lending (å•†æ¥­ç”¨ä¸å‹•ç”£èè³‡) ===
    "CRE_Std_Construction": "ã€CREèè³‡åŸºæº–ï¼ˆå»ºè¨­ãƒ»åœŸåœ°é–‹ç™ºï¼‰ã€‘\nä¸å‹•ç”£é–‹ç™ºã®è›‡å£ã€‚ã“ã“ãŒé–‰ã¾ã‚‹ã¨æ•°å¹´å¾Œã®æ–°è¦ä¾›çµ¦ã¨å»ºè¨­æŠ•è³‡ãŒæ­¢ã¾ã‚‹ã€‚å…ˆè¡Œæ€§ãŒé«˜ã„ã€‚",
    "CRE_Std_Office": "ã€CREèè³‡åŸºæº–ï¼ˆã‚ªãƒ•ã‚£ã‚¹ç­‰ï¼‰ã€‘\næ—¢å­˜ç‰©ä»¶ã®å€Ÿã‚Šæ›ãˆé›£æ˜“åº¦ã‚’ç¤ºã™ã€‚å³æ ¼åŒ–ã¯ç‰©ä»¶ä¾¡æ ¼æš´è½ã®ãƒˆãƒªã‚¬ãƒ¼ã¨ãªã‚‹ã€‚ã‚ªãƒ•ã‚£ã‚¹ã‚¯ãƒ©ã‚¤ã‚·ã‚¹ãƒ»å€Ÿã‚Šæ›ãˆãƒªã‚¹ã‚¯ã®æ¸¬å®šã€‚",
    "CRE_Std_Multifamily": "ã€CREèè³‡åŸºæº–ï¼ˆé›†åˆä½å®…ï¼‰ã€‘\nå±…ä½ç”¨ä¸å‹•ç”£å¸‚å ´ã®æµå‹•æ€§ã‚’ç¢ºèªã€‚ä½å®…ä¾›çµ¦ã«å½±éŸ¿ã€‚è³ƒè²¸å¸‚å ´ã®å…ˆè¡ŒæŒ‡æ¨™ã€‚",
    "CRE_Demand": "ã€CREèè³‡éœ€è¦ã€‘\næŠ•è³‡å®¶ãŒä¸å‹•ç”£ã‹ã‚‰è³‡é‡‘ã‚’å¼•ãæšã’ã‚‹å‹•ãã‚’å¯ŸçŸ¥ã™ã‚‹æŒ‡æ¨™ã€‚ä¸å‹•ç”£æŠ•è³‡æ„æ¬²ã®æ¸›é€€ç¢ºèªã€‚",
    "CRE_Loans": "ã€CREèè³‡æ®‹é«˜ï¼ˆé€±æ¬¡ï¼‰ã€‘\né€±æ¬¡ã§è¿½ãˆã‚‹æœ€é€Ÿã®ãƒ‡ãƒ¼ã‚¿ã€‚å››åŠæœŸçµ±è¨ˆã‚’å¾…ãŸãšã«éŠ€è¡Œã®èè³‡å§¿å‹¢ã®å¤‰åŒ–ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å¯ŸçŸ¥ã€‚",
    
    # === Money Supply / ãƒãƒãƒ¼ã‚µãƒ—ãƒ©ã‚¤ ===
    "M2SL": "ã€é€šè²¨ä¾›çµ¦é‡ M2 (åç›®)ã€‘\nä¸–ã®ä¸­ã«æµé€šã—ã¦ã„ã‚‹ãƒãƒãƒ¼(ç¾é‡‘ãƒ»é é‡‘ç­‰)ã®ç·é‡ã€‚FRBã®é‡‘èæ”¿ç­–ã®çµæœã‚’ç¤ºã™ã€‚",
    "M2REAL": "ã€é€šè²¨ä¾›çµ¦é‡ M2 (å®Ÿè³ª)ã€‘\nã‚¤ãƒ³ãƒ•ãƒ¬èª¿æ•´å¾Œã®å®Ÿè³ªçš„ãªè³¼è²·åŠ›ã€‚åç›®M2ã‚ˆã‚Šã‚‚å®Ÿä½“çµŒæ¸ˆã¸ã®å½±éŸ¿ã‚’æ¸¬å®šã€‚",
    "US_Real_M2_Index": "ã€ç±³å›½å®Ÿè³ªM2æŒ‡æ•°ã€‘\nã‚¤ãƒ³ãƒ•ãƒ¬èª¿æ•´å¾Œã®M2ã®æ¨ç§»ã‚’æŒ‡æ•°åŒ–ã—ãŸã‚‚ã®ã€‚",
    "CN_M2": "ã€ä¸­å›½M2ã€‘\nä¸­å›½ã®é€šè²¨ä¾›çµ¦é‡ã€‚ä¸–ç•Œç¬¬2ä½ã®çµŒæ¸ˆå¤§å›½ã®æµå‹•æ€§çŠ¶æ³ã‚’ç¤ºã™ã€‚",
    "JP_M2": "ã€æ—¥æœ¬M2ã€‘\næ—¥æœ¬ã®é€šè²¨ä¾›çµ¦é‡ã€‚æ—¥éŠ€ã®é‡‘èæ”¿ç­–ã®çµæœã‚’åæ˜ ã€‚",
    "EU_M2": "ã€æ¬§å·M2ã€‘\nãƒ¦ãƒ¼ãƒ­åœã®é€šè²¨ä¾›çµ¦é‡ã€‚ECBã®é‡‘èæ”¿ç­–ã®çµæœã‚’åæ˜ ã€‚",
    
    # === Economic Indicators / çµŒæ¸ˆæŒ‡æ¨™ ===
    "Unemployment": "ã€å¤±æ¥­ç‡ã€‘\nåŠ´åƒå¸‚å ´ã®å¥å…¨æ€§ã‚’ç¤ºã™é…è¡ŒæŒ‡æ¨™ã€‚FRBã®ãƒ‡ãƒ¥ã‚¢ãƒ«ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã®ä¸€ã¤ã€‚",
    "UNRATE": "ã€å¤±æ¥­ç‡ (Sahm Ruleç”¨)ã€‘\nã‚µãƒ¼ãƒ ãƒ»ãƒ«ãƒ¼ãƒ«ã®è¨ˆç®—ã«ä½¿ç”¨ã€‚3ãƒ¶æœˆç§»å‹•å¹³å‡ãŒ12ãƒ¶æœˆæœ€ä½å€¤ã‹ã‚‰0.5%ä¸Šæ˜‡ã§ãƒªã‚»ãƒƒã‚·ãƒ§ãƒ³å…¥ã‚Šã®ã‚·ã‚°ãƒŠãƒ«ã€‚",
    "CPI": "ã€æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•° (CPI)ã€‘\nã‚¤ãƒ³ãƒ•ãƒ¬ã®ä¸»è¦æŒ‡æ¨™ã€‚FRBã®é‡‘èæ”¿ç­–åˆ¤æ–­ã«ç›´çµã€‚",
    "CPICore": "ã€ã‚³ã‚¢CPIã€‘\né£Ÿå“ãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’é™¤ã„ãŸCPIã€‚åŸºèª¿çš„ãªã‚¤ãƒ³ãƒ•ãƒ¬å‚¾å‘ã‚’ç¤ºã™ã€‚",
    "PPI": "ã€ç”Ÿç”£è€…ç‰©ä¾¡æŒ‡æ•° (PPI)ã€‘\nä¼æ¥­ã®ä»•å…¥ã‚Œã‚³ã‚¹ãƒˆã€‚CPIã®å…ˆè¡ŒæŒ‡æ¨™ã¨ãªã‚‹ã“ã¨ã‚‚ã€‚",
    "CorePCE": "ã€ã‚³ã‚¢PCEã€‘\nFRBãŒæœ€ã‚‚é‡è¦–ã™ã‚‹ã‚¤ãƒ³ãƒ•ãƒ¬æŒ‡æ¨™ã€‚2%ãŒç›®æ¨™ã€‚",
    "ConsumerSent": "ã€æ¶ˆè²»è€…ä¿¡é ¼æ„ŸæŒ‡æ•°ã€‘\næ¶ˆè²»è€…ã®ãƒã‚¤ãƒ³ãƒ‰ã€‚å€‹äººæ¶ˆè²»ï¼ˆGDPã®7å‰²ï¼‰ã®å…ˆè¡ŒæŒ‡æ¨™ã€‚",
    "NFP": "ã€éè¾²æ¥­éƒ¨é–€é›‡ç”¨è€…æ•° (NFP)ã€‘\næ¯æœˆç¬¬1é‡‘æ›œç™ºè¡¨ã®æœ€é‡è¦æŒ‡æ¨™ã€‚åŠ´åƒå¸‚å ´ã®å¼·ã•ã‚’ç¤ºã™ã€‚",
    "ADP": "ã€ADPé›‡ç”¨çµ±è¨ˆã€‘\næ°‘é–“èª¿æŸ»ä¼šç¤¾ã«ã‚ˆã‚‹é›‡ç”¨çµ±è¨ˆã€‚NFPã®å…ˆè¡ŒæŒ‡æ¨™ã¨ã—ã¦æ³¨ç›®ã€‚",
    "AvgHourlyEarnings": "ã€å¹³å‡æ™‚çµ¦ã€‘\nè³ƒé‡‘ã‚¤ãƒ³ãƒ•ãƒ¬ã®æŒ‡æ¨™ã€‚NFPã¨åŒæ™‚ç™ºè¡¨ã€‚",
    "JOLTS": "ã€æ±‚äººæ•° (JOLTS)ã€‘\nåŠ´åƒéœ€è¦ã®å¼·ã•ã‚’ç¤ºã™ã€‚æ±‚äºº/æ±‚è·è€…æ¯”ç‡ã‚‚é‡è¦ã€‚",
    "ICSA": "ã€æ–°è¦å¤±æ¥­ä¿é™ºç”³è«‹ä»¶æ•°ã€‘\né€±æ¬¡ã§ç™ºè¡¨ã•ã‚Œã‚‹æœ€é€Ÿã®é›‡ç”¨æŒ‡æ¨™ã€‚æ™¯æ°—ã®å…ˆè¡ŒæŒ‡æ¨™ã€‚",
    "RetailSales": "ã€å°å£²å£²ä¸Šé«˜ã€‘\nå€‹äººæ¶ˆè²»ã®å‹•å‘ã‚’ç¤ºã™ã€‚GDPã®å…ˆè¡ŒæŒ‡æ¨™ã€‚",
    "RealGDP": "ã€å®Ÿè³ªGDPã€‘\nçµŒæ¸ˆæˆé•·ã®æœ€çµ‚æŒ‡æ¨™ã€‚å››åŠæœŸã”ã¨ã«ç™ºè¡¨ã€‚",
    
    # === FX / ç‚ºæ›¿ ===
    "DXY": "ã€ãƒ‰ãƒ«æŒ‡æ•° (DXY)ã€‘\nä¸»è¦é€šè²¨ã«å¯¾ã™ã‚‹ãƒ‰ãƒ«ã®å¼·ã•ã€‚ä¸Šæ˜‡ã¯ãƒ‰ãƒ«é«˜ã€æ–°èˆˆå›½ãƒ»ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£ã«é€†é¢¨ã€‚",
    "USDJPY": "ã€ãƒ‰ãƒ«å††ã€‘\næ—¥ç±³é‡‘åˆ©å·®ã«æ•æ„Ÿã€‚ãƒªã‚¹ã‚¯ã‚ªãƒ•æ™‚ã¯å††é«˜å‚¾å‘ã€‚",
    "EURUSD": "ã€ãƒ¦ãƒ¼ãƒ­ãƒ‰ãƒ«ã€‘\nä¸–ç•Œæœ€å¤§ã®å–å¼•é‡ã‚’æŒã¤é€šè²¨ãƒšã‚¢ã€‚",
    "USDCNY": "ã€ãƒ‰ãƒ«äººæ°‘å…ƒã€‘\nç±³ä¸­é–¢ä¿‚ã¨ä¸­å›½çµŒæ¸ˆã‚’åæ˜ ã€‚ç®¡ç†ãƒ•ãƒ­ãƒ¼ãƒˆåˆ¶ã€‚",
    
    # === Commodities / ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£ ===
    "Gold": "ã€é‡‘ (Gold)ã€‘\nå®‰å…¨è³‡ç”£ãƒ»ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ˜ãƒƒã‚¸ã€‚å®Ÿè³ªé‡‘åˆ©ã¨é€†ç›¸é–¢ã€‚",
    "Silver": "ã€éŠ€ (Silver)ã€‘\nå·¥æ¥­ç”¨é€”ã‚‚ã‚ã‚Šã€é‡‘ã‚ˆã‚Šãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒé«˜ã„ã€‚",
    "Oil": "ã€åŸæ²¹ (WTI)ã€‘\nã‚¨ãƒãƒ«ã‚®ãƒ¼ä¾¡æ ¼ã®æŒ‡æ¨™ã€‚ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ»æ™¯æ°—ã«å½±éŸ¿ã€‚",
    "Copper": "ã€éŠ…ã€‘\nã€Œãƒ‰ã‚¯ã‚¿ãƒ¼ãƒ»ã‚«ãƒƒãƒ‘ãƒ¼ã€ã¨å‘¼ã°ã‚Œã‚‹æ™¯æ°—å…ˆè¡ŒæŒ‡æ¨™ã€‚",
    
    # === Crypto / æš—å·è³‡ç”£ ===
    "BTC": "ã€ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ (BTC)ã€‘\næš—å·è³‡ç”£ã®ä»£è¡¨ã€‚ãƒªã‚¹ã‚¯è³‡ç”£ã¨ç›¸é–¢ã€‚",
    "ETH": "ã€ã‚¤ãƒ¼ã‚µãƒªã‚¢ãƒ  (ETH)ã€‘\nã‚¹ãƒãƒ¼ãƒˆã‚³ãƒ³ãƒˆãƒ©ã‚¯ãƒˆãƒ»DeFiã®åŸºç›¤ã€‚",
    
    # === Market / å¸‚å ´ ===
    "SP500": "ã€S&P 500ã€‘\nç±³å›½å¤§å‹æ ª500ç¤¾ã®æ ªä¾¡æŒ‡æ•°ã€‚ç±³å›½çµŒæ¸ˆã®ãƒãƒ­ãƒ¡ãƒ¼ã‚¿ãƒ¼ã€‚",
    "HYG": "ã€ãƒã‚¤ã‚¤ãƒ¼ãƒ«ãƒ‰å‚µETF (HYG)ã€‘\nã‚¸ãƒ£ãƒ³ã‚¯å‚µå¸‚å ´ã®æµå‹•æ€§ã¨ä¿¡ç”¨ãƒªã‚¹ã‚¯ã‚’åæ˜ ã€‚",
}

# ========== RSS FEEDS ==========
RSS_FEEDS = {
    "ğŸ›ï¸ Fed": "https://www.federalreserve.gov/feeds/press_all.xml",
    "ğŸ‡ªğŸ‡º ECB": "https://www.ecb.europa.eu/rss/press.html",
    "ğŸ‡¯ğŸ‡µ BOJ": "https://www.boj.or.jp/rss/news.xml",
}

MONITORED_AGENCIES = {
    "FRB": {"domain": "federalreserve.gov", "rss": "https://www.federalreserve.gov/feeds/press_all.xml", "label": "ğŸ¦ Federal Reserve"},
    "Treasury": {"domain": "treasury.gov", "rss": "https://home.treasury.gov/news/press-releases/rss.xml", "label": "ğŸ’µ Treasury"},
}

# ========== CONTEXT KEYWORDS ==========
CONTEXT_KEYWORDS = {
    "ğŸŒ åœ°æ”¿å­¦ãƒªã‚¹ã‚¯ (Geopolitics)": {"main_keyword": "geopolitical risk", "desc": "åˆ¶è£ãƒ»è²¿æ˜“æˆ¦äº‰ãƒ»è»äº‹ç´›äº‰"},
    "ğŸ“Š ãƒã‚¯ãƒ­çµŒæ¸ˆ (Macro)": {"main_keyword": "recession risk", "desc": "æ™¯æ°—å¾Œé€€ãƒ»ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ»GDP"},
    "ğŸ›ï¸ ä¸­å¤®éŠ€è¡Œ (Central Bank)": {"main_keyword": "Fed policy", "desc": "åˆ©ä¸‹ã’ãƒ»QTãƒ»ãƒãƒ©ãƒ³ã‚¹ã‚·ãƒ¼ãƒˆ"},
    "ğŸ’§ æµå‹•æ€§ãƒ»é…ç®¡ (Liquidity/Plumbing)": {"main_keyword": "liquidity crisis", "desc": "ãƒ¬ãƒãƒ»æº–å‚™é‡‘ãƒ»ON RRP"},
    "ğŸ›¢ï¸ ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£ (Commodities)": {"main_keyword": "oil price gold", "desc": "åŸæ²¹ãƒ»é‡‘ãƒ»éŠ…ãƒ»ä¾›çµ¦åˆ¶ç´„"},
    "â‚¿ ä»®æƒ³é€šè²¨ (Crypto)": {"main_keyword": "Bitcoin regulation", "desc": "BTCè¦åˆ¶ãƒ»ETFãƒ»ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚³ã‚¤ãƒ³"},
    "ğŸ¦ éŠ€è¡Œãƒ»ä¿¡ç”¨ (Banking/Credit)": {"main_keyword": "bank stress", "desc": "éŠ€è¡Œç ´ç¶»ãƒ»ä¿¡ç”¨åç¸®ãƒ»CRE"},
    "ğŸ¢ ä¸å‹•ç”£ (Real Estate)": {"main_keyword": "commercial real estate", "desc": "å•†æ¥­ç”¨ä¸å‹•ç”£ãƒ»ã‚ªãƒ•ã‚£ã‚¹ç©ºå®¤"},
    "ğŸ’µ é€šè²¨ãƒ»ç‚ºæ›¿ (Currency/FX)": {"main_keyword": "dollar strength", "desc": "ãƒ‰ãƒ«é«˜ãƒ»å††å®‰ãƒ»ä»‹å…¥"},
    "ğŸ‡¨ğŸ‡³ ä¸­å›½ (China)": {"main_keyword": "China economy", "desc": "ä¸­å›½çµŒæ¸ˆãƒ»ä¸å‹•ç”£å±æ©Ÿãƒ»è³‡æœ¬æµå‡º"},
    "ğŸ‡ªğŸ‡º æ¬§å· (Europe)": {"main_keyword": "ECB policy", "desc": "ECBãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼å±æ©Ÿãƒ»å‚µå‹™"},
    "ğŸŒ æ–°èˆˆå›½ (Emerging Markets)": {"main_keyword": "emerging market crisis", "desc": "æ–°èˆˆå›½å±æ©Ÿãƒ»é€šè²¨æš´è½ãƒ»IMF"},
}

# ========== HELPER FUNCTIONS ==========

def get_freshness_badge(last_updated_str: str) -> str:
    """ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒãƒƒã‚¸ã‚’è¿”ã™"""
    if not last_updated_str:
        return ""
    try:
        last_updated = datetime.datetime.strptime(last_updated_str, '%Y-%m-%d')
        now = datetime.datetime.now()
        days_ago = (now - last_updated).days
        if days_ago <= 1:
            return "ğŸ†•"
        elif days_ago <= 7:
            return "âœ…"
        elif days_ago <= 30:
            return "â³"
        else:
            return "âš ï¸"
    except:
        return ""

def get_data_freshness_status(last_valid_dates: dict, release_dates: dict = None) -> dict:
    """å…¨æŒ‡æ¨™ã®ãƒ‡ãƒ¼ã‚¿é®®åº¦ã‚’ãƒã‚§ãƒƒã‚¯"""
    today = datetime.datetime.now().date()
    
    results = {
        'fresh': [], 'stale': [], 'critical': [], 'missing': [],
        'details': {},
        'summary': {'fresh_count': 0, 'stale_count': 0, 'critical_count': 0, 'health_score': 100}
    }
    
    indicator_category = {}
    for category, config in DATA_FRESHNESS_RULES.items():
        for ind in config['indicators']:
            indicator_category[ind] = category
    
    for indicator, date_str in last_valid_dates.items():
        if indicator in ['RMP_Alert_Active', 'RMP_Status_Text']:
            continue
        try:
            check_date_str = date_str
            if release_dates and indicator in release_dates and release_dates[indicator]:
                check_date_str = release_dates[indicator]
            last_date = datetime.datetime.strptime(check_date_str, '%Y-%m-%d').date()
            days_old = (today - last_date).days
            
            category = indicator_category.get(indicator, 'weekly')
            rules = DATA_FRESHNESS_RULES[category]
            
            if days_old <= rules['fresh']:
                status = 'fresh'
                results['fresh'].append(indicator)
            elif days_old <= rules['stale']:
                status = 'stale'
                results['stale'].append(indicator)
            else:
                status = 'critical'
                results['critical'].append(indicator)
            
            results['details'][indicator] = {
                'last_date': date_str,
                'days_old': days_old,
                'status': status,
                'category': category
            }
        except:
            results['missing'].append(indicator)
    
    total = len(results['fresh']) + len(results['stale']) + len(results['critical'])
    if total > 0:
        results['summary']['fresh_count'] = len(results['fresh'])
        results['summary']['stale_count'] = len(results['stale'])
        results['summary']['critical_count'] = len(results['critical'])
        results['summary']['health_score'] = int((len(results['fresh']) / total) * 100)
    
    return results

# ========== AI CLIENT INITIALIZATION ==========
def init_ai_clients():
    """AI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
    gemini_client = None
    claude_client = None
    
    try:
        from google import genai
        GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
        if GEMINI_API_KEY:
            gemini_client = genai.Client(api_key=GEMINI_API_KEY)
    except:
        pass
    
    try:
        import anthropic
        ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
        if ANTHROPIC_API_KEY:
            claude_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
    except:
        pass
    
    return gemini_client, claude_client

# ========== MARKET DATA FUNCTIONS ==========

def _get_disk_cache_path():
    """ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ãƒ‘ã‚¹ã‚’å–å¾—"""
    return os.path.join(os.path.dirname(__file__), '.market_data_cache.pkl')

def _load_from_disk_cache():
    """ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿"""
    cache_path = _get_disk_cache_path()
    try:
        if os.path.exists(cache_path):
            cache_age = time.time() - os.path.getmtime(cache_path)
            if cache_age < 600:  # 10åˆ†ä»¥å†…
                with open(cache_path, 'rb') as f:
                    return pickle.load(f)
    except:
        pass
    return None, None

def _save_to_disk_cache(df, df_original):
    """ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
    cache_path = _get_disk_cache_path()
    try:
        with open(cache_path, 'wb') as f:
            pickle.dump((df, df_original), f)
    except:
        pass

def get_fred_release_dates(series_ids: list) -> dict:
    """FRED APIã‹ã‚‰ãƒªãƒªãƒ¼ã‚¹æ—¥ã‚’å–å¾—"""
    release_info = {}
    for series_id in series_ids:
        try:
            url = f"https://api.stlouisfed.org/fred/series?series_id={series_id}&api_key={FRED_API_KEY}&file_type=json"
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                data = response.json()
                if 'seriess' in data and len(data['seriess']) > 0:
                    series_info = data['seriess'][0]
                    release_info[series_id] = {
                        'last_updated': series_info.get('last_updated', '')[:10]
                    }
        except:
            pass
    return release_info

@st.cache_data(ttl=600, show_spinner=False)
def get_market_data(_csv_mtime=None, _force_refresh=False):
    """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    if not _force_refresh:
        cached_df, cached_original = _load_from_disk_cache()
        if cached_df is not None and cached_original is not None:
            return cached_df, cached_original
    
    end = datetime.datetime.now()
    start = end - datetime.timedelta(days=730)
    
    fred_series = []
    for name, ticker in FRED_INDICATORS.items():
        try:
            s = web.DataReader(ticker, 'fred', start, end, api_key=FRED_API_KEY)
            s.columns = [name]
            fred_series.append(s)
        except:
            pass
    
    # Yahoo Data
    try:
        y_tickers = list(YAHOO_INDICATORS.values())
        y_data = yf.download(y_tickers, start=start, end=end, progress=False)['Close']
        inv_yahoo = {v: k for k, v in YAHOO_INDICATORS.items()}
        y_data = y_data.rename(columns=inv_yahoo)
    except:
        y_data = pd.DataFrame()
    
    # Join All
    df = pd.concat(fred_series + ([y_data] if not y_data.empty else []), axis=1).sort_index()
    
    # Unit Normalization (Million to Billion)
    mil_to_bil = ['Fed_Assets', 'TGA', 'Reserves', 'SOMA_Total', 'Bank_Cash', 'SRF', 'FIMA', 
                  'Primary_Credit', 'Total_Loans', 'SOMA_Bills', 'M2SL', 'M2REAL', 'CI_Loans', 'CRE_Loans']
    for col in mil_to_bil:
        if col in df.columns:
            df[col] = df[col] / 1000
    
    # Calculate Net Liquidity
    if all(c in df.columns for c in ['Fed_Assets', 'TGA', 'ON_RRP']):
        df['Net_Liquidity'] = df['Fed_Assets'] - df['TGA'] - df['ON_RRP']
    
    # Calculate SOMA Bills Ratio
    if all(c in df.columns for c in ['SOMA_Bills', 'SOMA_Total']):
        df['SomaBillsRatio'] = (df['SOMA_Bills'] / df['SOMA_Total']) * 100
    
    # RMP Status
    if 'SOMA_Bills' in df.columns:
        df['RMP_Alert_Active'] = False
        df['RMP_Status_Text'] = "ğŸ“Š RMPç›£è¦–ä¸­"
        
        bills_recent = df['SOMA_Bills'].tail(30)
        if len(bills_recent) >= 7:
            bills_7d_ago = bills_recent.iloc[-7]
            bills_now = bills_recent.iloc[-1]
            weekly_change = bills_now - bills_7d_ago
            
            if weekly_change >= 4.5:
                df.loc[df.index[-1], 'RMP_Alert_Active'] = True
                df.loc[df.index[-1], 'RMP_Status_Text'] = f"âœ… RMPå®Ÿè¡Œä¸­: +${weekly_change:.1f}B/é€±"
    
    # Store last valid dates
    last_valid_dates = {}
    for col in df.columns:
        valid_data = df[col].dropna()
        if len(valid_data) > 0:
            last_valid_dates[col] = valid_data.index[-1].strftime('%Y-%m-%d')
    
    # Fetch FRED release dates
    fred_ids = list(set(FRED_INDICATORS.values()))
    fred_release_info = get_fred_release_dates(fred_ids)
    
    col_release_dates = {}
    for indicator, series_id in FRED_INDICATORS.items():
        if series_id in fred_release_info:
            col_release_dates[indicator] = fred_release_info[series_id]['last_updated']
    
    df_original = df.copy()
    df = df.ffill()
    
    df.attrs['last_valid_dates'] = last_valid_dates
    df.attrs['fred_release_dates'] = col_release_dates
    df_original.attrs = df.attrs.copy()
    
    _save_to_disk_cache(df, df_original)
    
    return df, df_original

# ========== DISPLAY FUNCTIONS ==========

def show_metric(label, series, unit="", explanation_key="", notes="", alert_func=None):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¡ãƒˆãƒªãƒƒã‚¯è¡¨ç¤º"""
    df = st.session_state.get('df')
    
    if series is None or (hasattr(series, 'isna') and series.isna().all()):
        val = None
        delta = None
        latest_date = None
        release_date = None
    else:
        val = series.iloc[-1] if hasattr(series, 'iloc') else series
        if hasattr(series, 'iloc') and len(series) > 1:
            delta = val - series.iloc[-2]
        else:
            delta = None
        
        latest_date = None
        release_date = None
        col_name = series.name if hasattr(series, 'name') else explanation_key
        if df is not None and hasattr(df, 'attrs'):
            if 'last_valid_dates' in df.attrs and col_name in df.attrs['last_valid_dates']:
                latest_date = df.attrs['last_valid_dates'][col_name]
            if 'fred_release_dates' in df.attrs and col_name in df.attrs['fred_release_dates']:
                release_date = df.attrs['fred_release_dates'][col_name]
    
    help_text = EXPLANATIONS.get(explanation_key, "")
    freshness_badge = get_freshness_badge(release_date or latest_date) if (release_date or latest_date) else ""
    display_label = f"{freshness_badge} {label}" if freshness_badge else label
    
    if alert_func and val is not None and alert_func(val):
        st.metric(display_label, f"{val:.1f} {unit}" if val is not None else "N/A", 
                 delta=f"{delta:+.1f}" if delta is not None else None,
                 help=help_text, delta_color="inverse")
    else:
        st.metric(display_label, f"{val:.1f} {unit}" if val is not None else "N/A",
                 delta=f"{delta:+.1f}" if delta is not None else None,
                 help=help_text)
    
    if latest_date:
        freq_label = DATA_FREQUENCY.get(explanation_key, '')
        st.caption(f"ğŸ“… å¯¾è±¡æœŸé–“: {latest_date} ({freq_label})" if freq_label else f"ğŸ“… å¯¾è±¡æ—¥: {latest_date}")
    
    if release_date:
        st.caption(f"ğŸ”„ æä¾›å…ƒæ›´æ–°æ—¥: {release_date}")
    
    if notes:
        st.caption(notes)

def show_metric_with_sparkline(label, series, df_column, unit="", explanation_key="", notes="", alert_func=None, decimal_places=1):
    """ãƒ¡ãƒˆãƒªãƒƒã‚¯ + ã‚¹ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ³ï¼ˆæä¾›å…ƒæ›´æ–°æ—¥è¡¨ç¤ºå¯¾å¿œï¼‰"""
    df = st.session_state.get('df')
    
    if series is None or (hasattr(series, 'isna') and series.isna().all()):
        val = None
        delta = None
        latest_date = None
        release_date = None
    else:
        val = series.iloc[-1] if hasattr(series, 'iloc') else series
        if hasattr(series, 'iloc') and len(series) > 1:
            delta = val - series.iloc[-2]
        else:
            delta = None
        
        latest_date = None
        release_date = None
        if df is not None and hasattr(df, 'attrs'):
            if 'last_valid_dates' in df.attrs and df_column in df.attrs['last_valid_dates']:
                latest_date = df.attrs['last_valid_dates'][df_column]
            if 'fred_release_dates' in df.attrs and df_column in df.attrs['fred_release_dates']:
                release_date = df.attrs['fred_release_dates'][df_column]
    
    help_text = EXPLANATIONS.get(explanation_key or df_column, "")
    freshness_badge = get_freshness_badge(release_date or latest_date) if (release_date or latest_date) else ""
    display_label = f"{freshness_badge} {label}" if freshness_badge else label
    
    val_format = f"{{:.{decimal_places}f}}"
    delta_format = f"{{:+.{decimal_places}f}}"
    
    if alert_func and val is not None and alert_func(val):
        st.metric(display_label, f"{val_format.format(val)} {unit}" if val is not None else "N/A", 
                 delta=delta_format.format(delta) if delta is not None else None,
                 help=help_text, delta_color="inverse")
    else:
        st.metric(display_label, f"{val_format.format(val)} {unit}" if val is not None else "N/A",
                 delta=delta_format.format(delta) if delta is not None else None,
                 help=help_text)
    
    # ğŸ“… å¯¾è±¡æœŸé–“
    if latest_date:
        freq_label = DATA_FREQUENCY.get(df_column, '')
        st.caption(f"ğŸ“… å¯¾è±¡æœŸé–“: {latest_date} ({freq_label})" if freq_label else f"ğŸ“… å¯¾è±¡æ—¥: {latest_date}")
    
    # ğŸ”„ æä¾›å…ƒæ›´æ–°æ—¥
    if release_date:
        st.caption(f"ğŸ”„ æä¾›å…ƒæ›´æ–°æ—¥: {release_date}")
    
    if notes:
        st.caption(notes)
    
    # ã‚¹ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ³
    if df is not None and df_column in df.columns and not df.get(df_column, pd.Series()).isna().all():
        recent_data = df[df_column].tail(60)
        st.caption("ğŸ“Š éå»60æ—¥é–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰")
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=recent_data.index,
            y=recent_data.values,
            mode='lines',
            line=dict(color='cyan', width=1),
            fill='tozeroy',
            fillcolor='rgba(0,255,255,0.1)',
            showlegend=False
        ))
        
        fig.update_layout(
            height=100,
            margin=dict(l=0, r=0, t=0, b=0),
            xaxis=dict(visible=False),
            yaxis=dict(visible=False),
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            hovermode=False
        )
        
        st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False}, 
                       key=f"spark_{df_column}_{uuid.uuid4().hex[:8]}")

def plot_dual_axis(df, left_col, right_col, left_name, right_name):
    """2è»¸ãƒãƒ£ãƒ¼ãƒˆ"""
    fig = make_subplots(specs=[[{"secondary_y": True}]])
    
    if left_col in df.columns:
        fig.add_trace(
            go.Scatter(x=df.index, y=df[left_col], name=left_name, line=dict(color='cyan')),
            secondary_y=False
        )
    
    if right_col in df.columns:
        fig.add_trace(
            go.Scatter(x=df.index, y=df[right_col], name=right_name, line=dict(color='orange')),
            secondary_y=True
        )
    
    fig.update_layout(
        template='plotly_dark',
        height=400,
        hovermode='x unified',
        showlegend=True
    )
    fig.update_yaxes(title_text=left_name, secondary_y=False)
    fig.update_yaxes(title_text=right_name, secondary_y=True)
    
    st.plotly_chart(fig, use_container_width=True, key=f"dual_{uuid.uuid4().hex[:8]}")

def plot_soma_composition(df):
    """SOMAæ§‹æˆãƒãƒ£ãƒ¼ãƒˆ"""
    fig = make_subplots(specs=[[{"secondary_y": True}]])
    
    if 'SOMA_Total' in df.columns:
        soma_resampled = df['SOMA_Total'].resample('W').last()
        fig.add_trace(
            go.Bar(x=soma_resampled.index, y=soma_resampled, name='SOMA Total (Billions)', marker_color='steelblue'),
            secondary_y=False
        )
    
    if 'SomaBillsRatio' in df.columns:
        ratio_resampled = df['SomaBillsRatio'].resample('W').last()
        fig.add_trace(
            go.Scatter(x=ratio_resampled.index, y=ratio_resampled, name='Bills Ratio (%)', 
                      line=dict(color='orange', width=2)),
            secondary_y=True
        )
    
    fig.update_layout(
        template='plotly_dark',
        height=400,
        hovermode='x unified',
        showlegend=True
    )
    fig.update_yaxes(title_text="SOMA Total (B)", secondary_y=False)
    fig.update_yaxes(title_text="Bills Ratio (%)", secondary_y=True, tickformat='.1f')
    
    st.plotly_chart(fig, use_container_width=True, key=f"soma_{uuid.uuid4().hex[:8]}")

# ========== VALUATION & LEVERAGE INDICATORS ==========
@st.cache_data(ttl=3600, show_spinner=False)
def get_pe_ratios():
    """S&P500ã¨NASDAQã®P/Eã‚’å–å¾—"""
    try:
        result = {
            'sp500_pe': None,
            'sp500_pe_avg': 19.5,
            'nasdaq_pe': None,
        }
        
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            url = "https://www.multpl.com/s-p-500-pe-ratio"
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                match = re.search(r'Current S&P 500 PE Ratio is\s*([\d.]+)', response.text)
                if match:
                    result['sp500_pe'] = float(match.group(1))
        except:
            pass
        
        try:
            qqq = yf.Ticker("QQQ")
            info = qqq.info
            result['nasdaq_pe'] = info.get('trailingPE')
        except:
            pass
        
        return result
    except:
        return None

@st.cache_data(ttl=300, show_spinner=False)
def get_crypto_leverage_data():
    """æš—å·è³‡ç”£ãƒ¬ãƒãƒ¬ãƒƒã‚¸æŒ‡æ¨™ã‚’å–å¾—"""
    try:
        result = {
            'btc_funding_rate': None,
            'eth_funding_rate': None,
            'btc_open_interest': None,
            'eth_open_interest': None,
            'btc_long_short_ratio': None,
        }
        
        headers = {'User-Agent': 'Mozilla/5.0'}
        
        # Binance Funding Rate
        try:
            url = "https://fapi.binance.com/fapi/v1/fundingRate?symbol=BTCUSDT&limit=1"
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if data and len(data) > 0:
                    result['btc_funding_rate'] = float(data[0].get('fundingRate', 0)) * 100
        except:
            pass
        
        try:
            url = "https://fapi.binance.com/fapi/v1/fundingRate?symbol=ETHUSDT&limit=1"
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if data and len(data) > 0:
                    result['eth_funding_rate'] = float(data[0].get('fundingRate', 0)) * 100
        except:
            pass
        
        # Open Interest
        try:
            url = "https://fapi.binance.com/fapi/v1/openInterest?symbol=BTCUSDT"
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                result['btc_open_interest'] = float(data.get('openInterest', 0))
        except:
            pass
        
        try:
            url = "https://fapi.binance.com/fapi/v1/openInterest?symbol=ETHUSDT"
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                result['eth_open_interest'] = float(data.get('openInterest', 0))
        except:
            pass
        
        # Historical OI (30 days)
        try:
            url = "https://fapi.binance.com/futures/data/openInterestHist?symbol=BTCUSDT&period=4h&limit=180"
            response = requests.get(url, headers=headers, timeout=15)
            if response.status_code == 200:
                data = response.json()
                if data and len(data) > 0:
                    oi_values = [float(d.get('sumOpenInterest', 0)) for d in data]
                    result['btc_oi_avg_30d'] = sum(oi_values) / len(oi_values) if oi_values else None
                    result['btc_oi_ath'] = max(oi_values) if oi_values else None
        except:
            pass
        
        try:
            url = "https://fapi.binance.com/futures/data/openInterestHist?symbol=ETHUSDT&period=4h&limit=180"
            response = requests.get(url, headers=headers, timeout=15)
            if response.status_code == 200:
                data = response.json()
                if data and len(data) > 0:
                    oi_values = [float(d.get('sumOpenInterest', 0)) for d in data]
                    result['eth_oi_avg_30d'] = sum(oi_values) / len(oi_values) if oi_values else None
                    result['eth_oi_ath'] = max(oi_values) if oi_values else None
        except:
            pass
        
        # Long/Short Ratio
        try:
            url = "https://fapi.binance.com/futures/data/globalLongShortAccountRatio?symbol=BTCUSDT&period=1h&limit=1"
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if data and len(data) > 0:
                    result['btc_long_short_ratio'] = float(data[0].get('longShortRatio', 1.0))
        except:
            pass
        
        return result
    except:
        return None

# ========== ALERT FUNCTIONS ==========
def check_for_market_alerts(df=None):
    """å¸‚å ´ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯"""
    alerts = []
    
    if df is None:
        df = st.session_state.get('df')
    
    if df is None:
        return alerts
    
    # VIX Alert
    if 'VIX' in df.columns:
        vix = df['VIX'].iloc[-1]
        if vix > 30:
            alerts.append({'severity': 'high', 'message': f'ğŸ”´ VIXé«˜é¨°: {vix:.1f}'})
        elif vix > 25:
            alerts.append({'severity': 'medium', 'message': f'ğŸŸ  VIXä¸Šæ˜‡: {vix:.1f}'})
    
    # Credit Spread Alert
    if 'Credit_Spread' in df.columns:
        spread = df['Credit_Spread'].iloc[-1]
        if spread > 5:
            alerts.append({'severity': 'high', 'message': f'ğŸ”´ ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰æ‹¡å¤§: {spread:.2f}%'})
    
    # ON RRP Alert
    if 'ON_RRP' in df.columns:
        rrp = df['ON_RRP'].iloc[-1]
        if rrp < 50:
            alerts.append({'severity': 'medium', 'message': f'ğŸŸ  ON RRPä½ä¸‹: ${rrp:.0f}B'})
    
    return alerts

# ========== MACRO INDICATOR FUNCTIONS ==========

def get_mom_yoy(df_column, freq='M'):
    """MoM%ã¨YoY%ã‚’è¨ˆç®—ï¼ˆã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰"""
    df_original = st.session_state.get('df_original')
    if df_original is None:
        return None, None
    
    series = df_original.get(df_column)
    if series is None or len(series.dropna()) < 2:
        return None, None
    s = series.dropna()
    curr = s.iloc[-1]
    prev = s.iloc[-2]
    mom = (curr / prev - 1) * 100 if prev != 0 else 0
    
    # YoY: Monthly=12, Quarterly=4
    offset = 12 if freq == 'M' else 4
    yoy = None
    if len(s) > offset:
        prev_yr = s.iloc[-(offset+1)]
        yoy = (curr / prev_yr - 1) * 100 if prev_yr != 0 else 0
    return mom, yoy

def display_macro_card(title, series, df_column, unit="", notes="", freq='M', show_level=True):
    """ãƒã‚¯ãƒ­æŒ‡æ¨™ã‚«ãƒ¼ãƒ‰ã‚’è¡¨ç¤ºï¼ˆMoM, YoY, ã‚¹ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ³ã€é•·æœŸãƒãƒ£ãƒ¼ãƒˆï¼‰
    
    Args:
        show_level: Falseãªã‚‰ã‚¹ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ³ã‚„Levelè¡¨ç¤ºã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆNFPã®ã‚ˆã†ã«å¤‰åŒ–ã®ã¿ãŒé‡è¦ãªå ´åˆï¼‰
    """
    df = st.session_state.get('df')
    df_original = st.session_state.get('df_original')
    
    st.markdown(f"#### {title}")
    mom, yoy = get_mom_yoy(df_column, freq=freq)
    
    # 1. Metrics Row (MoM, YoY)
    m_col1, m_col2 = st.columns(2)
    if mom is not None:
        m_col1.metric("å‰æœˆæ¯”", f"{mom:+.1f}%")
    if yoy is not None:
        m_col2.metric("å‰å¹´æ¯”", f"{yoy:+.1f}%")
    
    # 2. Main Metric with Sparkline & Update Date (optional)
    if show_level:
        show_metric_with_sparkline(title, series, df_column, unit, notes=notes)
    
    # 3. YoY% Trend Chart
    if df_original is not None:
        original_series = df_original.get(df_column)
        if original_series is not None and len(original_series.dropna()) > 12:
            data = original_series.dropna()
            yoy_series = (data / data.shift(12) - 1) * 100
            yoy_series = yoy_series.dropna()
            if len(yoy_series) > 0:
                st.markdown(f"###### {title} YoY% (å‰å¹´æ¯”å¤‰åŒ–ç‡)")
                st.line_chart(yoy_series, height=120)
    
    # 4. Long-term Chart (Level)
    if series is not None and not series.isna().all():
        st.markdown(f"###### {title} Long-term Trend (Level)")
        st.line_chart(series, height=150)

# ========== CRYPTO LIQUIDITY FUNCTIONS ==========

@st.cache_data(ttl=3600, show_spinner=False)
def get_stablecoin_data():
    """ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚³ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆDeFiLlama APIï¼‰"""
    try:
        url = "https://stablecoins.llama.fi/stablecoins?includePrices=true"
        response = requests.get(url, timeout=15)
        if response.status_code != 200:
            return None
        
        data = response.json()
        stablecoins = data.get('peggedAssets', [])
        
        top_coins = []
        total_supply = 0
        coin_ids = {}
        
        for coin in stablecoins:
            if coin.get('pegType') == 'peggedUSD':
                circulating = coin.get('circulating', {}).get('peggedUSD', 0)
                if circulating and circulating > 1000000:
                    total_supply += circulating
                    coin_data = {
                        'id': coin.get('id', ''),
                        'name': coin.get('name', ''),
                        'symbol': coin.get('symbol', ''),
                        'circulating': circulating / 1e9,
                        'mechanism': coin.get('pegMechanism', ''),
                        'price': coin.get('price', 1.0),
                        'prev_day': coin.get('circulatingPrevDay', {}).get('peggedUSD', 0) / 1e9,
                        'prev_week': coin.get('circulatingPrevWeek', {}).get('peggedUSD', 0) / 1e9,
                        'prev_month': coin.get('circulatingPrevMonth', {}).get('peggedUSD', 0) / 1e9,
                    }
                    top_coins.append(coin_data)
                    coin_ids[coin.get('symbol', '')] = coin.get('id', '')
        
        top_coins.sort(key=lambda x: x['circulating'], reverse=True)
        
        return {
            'total_supply': total_supply / 1e9,
            'top_coins': top_coins[:15],
            'coin_ids': coin_ids,
            'timestamp': datetime.datetime.now().isoformat()
        }
    except:
        return None

@st.cache_data(ttl=3600, show_spinner=False)
def get_stablecoin_historical():
    """ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚³ã‚¤ãƒ³å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆDeFiLlama APIï¼‰"""
    try:
        url = "https://stablecoins.llama.fi/stablecoincharts/all?stablecoin=1"
        response = requests.get(url, timeout=15)
        if response.status_code != 200:
            return None
        
        data = response.json()
        records = []
        
        if isinstance(data, list):
            for point in data:
                try:
                    date_val = point.get('date', 0)
                    if isinstance(date_val, str):
                        date_val = int(date_val)
                    date = datetime.datetime.fromtimestamp(date_val)
                    
                    total = 0
                    if 'totalCirculating' in point and isinstance(point['totalCirculating'], dict):
                        total = point['totalCirculating'].get('peggedUSD', 0) / 1e9
                    elif 'totalCirculatingUSD' in point and isinstance(point['totalCirculatingUSD'], dict):
                        total = point['totalCirculatingUSD'].get('peggedUSD', 0) / 1e9
                    
                    if total > 0:
                        records.append({'date': date, 'Total': total})
                except:
                    continue
        
        df = pd.DataFrame(records)
        if not df.empty and len(df) > 0:
            df = df.set_index('date')
            df = df.sort_index()
            return df
        
        return None
    except:
        return None

@st.cache_data(ttl=3600, show_spinner=False)
def get_tokenized_treasury_data():
    """ãƒˆãƒ¼ã‚¯ãƒ³åŒ–å›½å‚µãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆDeFiLlama APIï¼‰"""
    try:
        url = "https://api.llama.fi/protocols"
        response = requests.get(url, timeout=15)
        if response.status_code != 200:
            return None
        
        protocols = response.json()
        
        treasury_keywords = ['treasury', 'tbill', 't-bill', 'buidl', 'usdy', 'usdm', 'usyc', 'ondo', 'openeden', 'hashnote', 'mountain', 'backed']
        gold_keywords = ['gold', 'xaut', 'paxg', 'gld', 'xau']
        
        treasury_data = []
        gold_data = []
        other_rwa_data = []
        
        treasury_tvl = 0
        gold_tvl = 0
        other_rwa_tvl = 0
        
        for protocol in protocols:
            name = protocol.get('name', '').lower()
            slug = protocol.get('slug', '').lower()
            symbol = protocol.get('symbol', '').lower()
            category = protocol.get('category', '').lower()
            
            is_rwa = 'rwa' in category or 'real world' in category
            if not is_rwa:
                continue
            
            tvl = protocol.get('tvl', 0)
            if not tvl or tvl < 1000000:
                continue
            
            protocol_info = {
                'name': protocol.get('name', ''),
                'symbol': protocol.get('symbol', '-'),
                'slug': protocol.get('slug', ''),
                'tvl': tvl / 1e9,
                'category': protocol.get('category', 'RWA'),
                'change_1d': protocol.get('change_1d', 0),
                'change_7d': protocol.get('change_7d', 0),
            }
            
            is_gold = any(kw in name or kw in symbol or kw in slug for kw in gold_keywords)
            is_treasury = any(kw in name or kw in symbol or kw in slug for kw in treasury_keywords)
            
            if is_gold:
                gold_data.append(protocol_info)
                gold_tvl += tvl
            elif is_treasury:
                treasury_data.append(protocol_info)
                treasury_tvl += tvl
            else:
                other_rwa_data.append(protocol_info)
                other_rwa_tvl += tvl
        
        treasury_data.sort(key=lambda x: x['tvl'], reverse=True)
        gold_data.sort(key=lambda x: x['tvl'], reverse=True)
        other_rwa_data.sort(key=lambda x: x['tvl'], reverse=True)
        
        return {
            'treasury': {'total_tvl': treasury_tvl / 1e9, 'protocols': treasury_data[:10]},
            'gold': {'total_tvl': gold_tvl / 1e9, 'protocols': gold_data[:5]},
            'other_rwa': {'total_tvl': other_rwa_tvl / 1e9, 'protocols': other_rwa_data[:10]},
            'total_rwa_tvl': (treasury_tvl + gold_tvl + other_rwa_tvl) / 1e9,
            'timestamp': datetime.datetime.now().isoformat()
        }
    except:
        return None

# ========== AI ANALYSIS FUNCTIONS ==========

def search_google_news(query, num_results=3, gl='US', mode='general'):
    """Google News RSSã‚’æ¤œç´¢"""
    try:
        import urllib.request
        hl = 'ja' if gl == 'JP' else 'en-US'
        ceid = 'JP:ja' if gl == 'JP' else 'US:en'
        
        search_url = f"https://news.google.com/rss/search?q={query.replace(' ', '+')}&hl={hl}&gl={gl}&ceid={ceid}"
        req = urllib.request.Request(search_url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req, timeout=10) as response:
            feed_content = response.read()
        feed = feedparser.parse(feed_content)
        
        results = []
        for entry in feed.entries[:num_results]:
            title = entry.get('title', '')
            pub_date = entry.get('published', '')[:20] if entry.get('published') else ''
            link = entry.get('link', '')
            source = entry.get('source', {}).get('title', 'Unknown Source')
            results.append(f"- [{gl}] [{pub_date}] Source: {source} | {title}\n  Link: {link}")
        
        return "\n".join(results) if results else "è©²å½“ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
    except Exception as e:
        return f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}"

def get_market_summary():
    """å¸‚å ´ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
    df = st.session_state.get('df')
    if df is None:
        return "ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
    
    summary_parts = []
    
    # Net Liquidity
    if 'Net_Liquidity' in df.columns:
        nl = df['Net_Liquidity'].iloc[-1]
        summary_parts.append(f"Net Liquidity: ${nl:.0f}B")
    
    # VIX
    if 'VIX' in df.columns:
        vix = df['VIX'].iloc[-1]
        summary_parts.append(f"VIX: {vix:.1f}")
    
    # S&P 500
    if 'SP500' in df.columns:
        sp = df['SP500'].iloc[-1]
        summary_parts.append(f"S&P 500: {sp:,.0f}")
    
    # Bitcoin
    if 'BTC' in df.columns:
        btc = df['BTC'].iloc[-1]
        summary_parts.append(f"BTC: ${btc:,.0f}")
    
    return "\n".join(summary_parts)

def run_gemini_analysis(prompt, use_search=True):
    """Geminiåˆ†æã‚’å®Ÿè¡Œ"""
    gemini_client = st.session_state.get('gemini_client')
    if gemini_client is None:
        return "Gemini APIãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
    
    try:
        response = gemini_client.models.generate_content(
            model=GEMINI_MODEL,
            contents=prompt
        )
        return response.text
    except Exception as e:
        return f"Geminiåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"

def run_claude_analysis(prompt):
    """Claudeåˆ†æã‚’å®Ÿè¡Œ"""
    claude_client = st.session_state.get('claude_client')
    if claude_client is None:
        return "Claude APIãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
    
    try:
        message = claude_client.messages.create(
            model=CLAUDE_MODEL,
            max_tokens=4000,
            messages=[{"role": "user", "content": prompt}]
        )
        return message.content[0].text
    except Exception as e:
        return f"Claudeåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"

def get_time_diff_str(date_str):
    """æ™‚é–“å·®åˆ†ã‚’äººé–“å¯èª­ã®æ–‡å­—åˆ—ã«å¤‰æ›"""
    try:
        from dateutil import parser
        from datetime import timezone
        
        now = datetime.datetime.now(timezone.utc)
        target_date = parser.parse(date_str)
        
        if target_date.tzinfo is None:
            return f"âš ï¸ {date_str[:16]}"
            
        diff = now - target_date
        seconds = diff.total_seconds()
        
        if seconds < 0:
            return "ğŸ“… äºˆå®š"
        elif seconds < 3600:
            return f"ğŸ”´ {int(seconds/60)}åˆ†å‰"
        elif seconds < 86400:
            return f"ğŸŸ  {int(seconds/3600)}æ™‚é–“å‰"
        elif seconds < 604800:
            return f"ğŸŸ¡ {int(seconds/86400)}æ—¥å‰"
        else:
            return f"ğŸŸ¢ {int(seconds/604800)}é€±å‰"
    except:
        return f"ğŸ“… {date_str[:16] if date_str else 'N/A'}"

# ========== SENTIMENT FUNCTIONS ==========

@st.cache_data(ttl=3600, show_spinner=False)
def get_crypto_fear_greed():
    """Crypto Fear & Greed Index ã‚’å–å¾—ï¼ˆAlternative.me APIï¼‰"""
    try:
        url = "https://api.alternative.me/fng/?limit=30"
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if 'data' in data:
                current = data['data'][0]
                history = []
                for item in data['data']:
                    history.append({
                        'date': datetime.datetime.fromtimestamp(int(item['timestamp'])),
                        'value': int(item['value']),
                        'classification': item['value_classification']
                    })
                return {
                    'current': int(current['value']),
                    'classification': current['value_classification'],
                    'history': pd.DataFrame(history).set_index('date').sort_index()
                }
    except:
        pass
    return None

@st.cache_data(ttl=3600, show_spinner=False)
def get_cnn_fear_greed():
    """CNN Fear & Greed Index ã‚’å–å¾—"""
    try:
        url = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if 'fear_and_greed' in data:
                fg = data['fear_and_greed']
                history = []
                if 'fear_and_greed_historical' in data:
                    for point in data['fear_and_greed_historical'].get('data', []):
                        history.append({
                            'date': datetime.datetime.fromtimestamp(point['x'] / 1000),
                            'value': point['y']
                        })
                return {
                    'current': fg.get('score', None),
                    'classification': fg.get('rating', ''),
                    'previous_close': fg.get('previous_close', None),
                    'history': pd.DataFrame(history).set_index('date').sort_index() if history else None
                }
    except:
        pass
    return None

@st.cache_data(ttl=3600, show_spinner=False)
def get_put_call_ratio():
    """Put/Call Ratio ã‚’å–å¾—"""
    # Placeholder - VIX as proxy
    return None

@st.cache_data(ttl=86400, show_spinner=False)
def get_aaii_sentiment():
    """AAII Investor Sentiment ã‚’å–å¾—"""
    try:
        return {
            'bullish': 38.5,
            'neutral': 31.2,
            'bearish': 30.3,
            'bull_bear_spread': 8.2,
            'date': datetime.datetime.now().strftime('%Y-%m-%d'),
            'note': 'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æº–å‚™ä¸­'
        }
    except:
        return None

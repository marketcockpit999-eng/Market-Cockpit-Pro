# -*- coding: utf-8 -*-
"""
Market Cockpit Pro - Page 6: Monte Carlo Simulation
æœ¬ç‰©ã®ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ12ã®é«˜åº¦ãªæ‰‹æ³•æ­è¼‰ï¼‰
"""

import streamlit as st
import numpy as np
import pandas as pd
import yfinance as yf
import plotly.graph_objects as go
from scipy import stats
from scipy.stats import qmc
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# è¨­å®š
# =============================================================================
ASSETS = {
    'S&P500': '^GSPC',
    'NASDAQ100': '^NDX',
    'æ—¥çµŒ225': '^N225',
    'ã‚´ãƒ¼ãƒ«ãƒ‰': 'GC=F',
    'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³': 'BTC-USD'
}

# =============================================================================
# ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•°
# =============================================================================
@st.cache_data(ttl=3600)
def fetch_asset_data(ticker: str, years: int = 5) -> pd.DataFrame:
    """éå»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    end_date = datetime.now()
    start_date = end_date - timedelta(days=years * 365)
    df = yf.download(ticker, start=start_date, end=end_date, progress=False)
    return df

def calculate_params(df: pd.DataFrame) -> dict:
    """å„ç¨®åˆ†å¸ƒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨ˆç®—ï¼ˆæ©Ÿé–¢æŠ•è³‡å®¶ãƒ¢ãƒ¼ãƒ‰ï¼‰"""
    if df.empty or len(df) < 10:
        return {"mu": 0.0, "sigma": 0.0, "df_t": 5.0, "regime": "ä¸æ˜", 
                "jump_intensity": 0.0, "jump_mean": 0.0, "jump_std": 0.0,
                "evt_threshold": 0.0, "evt_shape": 0.0}
    
    # æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³
    close = df['Close'].squeeze()
    daily_returns = close.pct_change().dropna()
    
    # å¹´ç‡æ›ç®—ï¼ˆ252å–¶æ¥­æ—¥ï¼‰
    mu = daily_returns.mean() * 252
    sigma = daily_returns.std() * np.sqrt(252)
    
    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡º
    if len(daily_returns) >= 90:
        recent_vol = daily_returns[-30:].std() * np.sqrt(252)
        long_vol = daily_returns[-90:].std() * np.sqrt(252)
        
        if recent_vol > long_vol * 1.5:
            regime = "é«˜ãƒœãƒ©"
            sigma_adj = sigma * 1.2  # ä¸Šæ–¹ä¿®æ­£
        elif recent_vol < long_vol * 0.7:
            regime = "ä½ãƒœãƒ©"
            sigma_adj = sigma * 0.9  # ä¸‹æ–¹ä¿®æ­£
        else:
            regime = "é€šå¸¸"
            sigma_adj = sigma
    else:
        regime = "é€šå¸¸"
        sigma_adj = sigma
    
    # Student-tåˆ†å¸ƒã®è‡ªç”±åº¦ã‚’æ¨å®š
    try:
        t_params = stats.t.fit(daily_returns)
        df_t = t_params[0]
    except:
        df_t = 5.0
    
    # ã‚¸ãƒ£ãƒ³ãƒ—æ‹¡æ•£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®šï¼ˆMerton Modelï¼‰
    # å¤§ããªå¤‰å‹•ï¼ˆÂ±2Ïƒè¶…ãˆï¼‰ã‚’ã‚¸ãƒ£ãƒ³ãƒ—ã¨ã¿ãªã™
    threshold = 2 * daily_returns.std()
    jumps = daily_returns[np.abs(daily_returns) > threshold]
    
    if len(jumps) > 0:
        # ã‚¸ãƒ£ãƒ³ãƒ—ã¯æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ãªã®ã§ã€å¹´ç‡ã§ã¯ãªãç´„å¹´é–“5%ï¼ˆ252æ—¥ä¸­12.6å›ï¼‰ç¨‹åº¦ãŒç†æ–™çš„
        jump_intensity = len(jumps) / len(daily_returns)  # æ—¥æ¬¡ç¢ºç‡
        jump_mean = jumps.mean()
        jump_std = max(jumps.std(), 0.01)  # æœ€å°å€¤ã‚’è¨­å®š
    else:
        jump_intensity = 0.0002  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æ—¥æ¬¡0.02%ï¼ˆå¹´ç´„5%ï¼‰
        jump_mean = -0.02
        jump_std = 0.05
    
    # æ¥µå€¤ç†è«–ï¼ˆEVTï¼‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ - ãƒ†ãƒ¼ãƒ«ãƒªã‚¹ã‚¯ç”¨
    # ä¸‹ä½5%ã‚’æ¥µå€¤ã¨ã—ã¦æ¨å®š
    tail_threshold = np.percentile(daily_returns, 5)
    tail_exceedances = daily_returns[daily_returns < tail_threshold] - tail_threshold
    
    if len(tail_exceedances) > 10:
        try:
            evt_shape, _, evt_scale = stats.genpareto.fit(-tail_exceedances, floc=0)
        except:
            evt_shape, evt_scale = 0.1, 0.01
    else:
        evt_shape, evt_scale = 0.1, 0.01
        
    return {
        "mu": float(mu),
        "sigma": float(sigma_adj),
        "sigma_raw": float(sigma),
        "df_t": float(df_t),
        "regime": regime,
        "jump_intensity": float(jump_intensity),
        "jump_mean": float(jump_mean),
        "jump_std": float(jump_std),
        "evt_threshold": float(tail_threshold),
        "evt_shape": float(evt_shape),
        "evt_scale": float(evt_scale)
    }

# =============================================================================
# ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚¨ãƒ³ã‚¸ãƒ³
# =============================================================================
def run_monte_carlo(S0: float, mu: float, sigma: float, T: float, 
                    dist_type: str = "Normal", df_t: float = 5.0,
                    jump_params: dict = None,
                    n_simulations: int = 100000, n_steps_per_year: int = 252,
                    use_qmc: bool = True) -> np.ndarray:
    """
    ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ³ã‚¸ãƒ³
    
    å®Ÿè£…æ‰‹æ³•:
    1. Antithetic Variates (åˆ†æ•£å‰Šæ¸›)
    2. Student-tåˆ†å¸ƒ (Fat-tailå¯¾å¿œ)
    3. Jump-Diffusion (Merton Model)
    """
    n_steps = int(T * n_steps_per_year)
    dt = 1 / n_steps_per_year
    
    # ã‚¸ãƒ£ãƒ³ãƒ—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    if jump_params is None:
        jump_params = {"intensity": 0.0002, "mean": -0.02, "std": 0.05}
    
    # å®Ÿéš›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ï¼ˆAntithetic Variatesã§åŠåˆ†ã«ï¼‰
    n_base = n_simulations // 2
    
    # ãƒ‘ã‚¹ã‚’ç”Ÿæˆ
    paths = np.zeros((n_simulations, n_steps + 1))
    paths[:, 0] = S0
    
    # === ä¹±æ•°ç”Ÿæˆ ===
    # é€šå¸¸ã®ä¹±æ•°ã‚’ä½¿ç”¨ï¼ˆQMCã¯3å¹´ã ã¨ã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒå¤šã™ãã¦å•é¡Œã«ãªã‚‹ï¼‰
    Z_base = np.random.standard_normal((n_base, n_steps))
    
    # Antithetic Variates: -Z ã‚‚ç”Ÿæˆï¼ˆåˆ†æ•£å‰Šæ¸›ï¼‰
    Z_anti = -Z_base
    Z_all = np.vstack([Z_base, Z_anti])
    
    # === åˆ†å¸ƒã®èª¿æ•´ ===
    if dist_type == "Student-t (Fat-tail)":
        # æ­£è¦åˆ†å¸ƒã‚’tåˆ†å¸ƒã«å¤‰æ›
        if df_t > 2:
            chi2_samples = np.random.chisquare(df_t, size=(n_simulations, 1))
            # å„ãƒ‘ã‚¹å…¨ä½“ã§åŒã˜ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã§ã¯ãªãï¼‰
            scale = np.sqrt(df_t / chi2_samples)
            Z_all = Z_all * scale
    
    # === Jump-Diffusion (Merton Model) ===
    if "Jump" in dist_type:
        # ãƒã‚¢ã‚½ãƒ³éç¨‹ã§ã‚¸ãƒ£ãƒ³ãƒ—ç™ºç”Ÿ
        jump_times = np.random.poisson(jump_params["intensity"], (n_simulations, n_steps))
        jump_sizes = np.random.normal(jump_params["mean"], jump_params["std"], (n_simulations, n_steps))
        jump_component = jump_times * jump_sizes
    else:
        jump_component = np.zeros((n_simulations, n_steps))
    
    # === GBMãƒ‘ã‚¹æ§‹ç¯‰ ===
    for t in range(1, n_steps + 1):
        drift = (mu - 0.5 * sigma**2) * dt
        diffusion = sigma * np.sqrt(dt) * Z_all[:, t-1]
        jump = jump_component[:, t-1]
        
        paths[:, t] = paths[:, t-1] * np.exp(drift + diffusion + jump)
    
    return paths

# =============================================================================
# ãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—
# =============================================================================
def calculate_risk_metrics(S0: float, final_prices: np.ndarray, evt_params: dict = None):
    """
    VaR ãŠã‚ˆã³ CVaR ã®è¨ˆç®—ï¼ˆæ©Ÿé–¢æŠ•è³‡å®¶ãƒ¢ãƒ¼ãƒ‰ï¼‰
    
    å®Ÿè£…æ‰‹æ³•:
    - Extreme Value Theory (EVT) ã«ã‚ˆã‚‹ãƒ†ãƒ¼ãƒ«ãƒªã‚¹ã‚¯æ¨å®š
    - Importance Sampling ã«ã‚ˆã‚‹ãƒ†ãƒ¼ãƒ«éƒ¨åˆ†ã®ç²¾åº¦å‘ä¸Š
    - Bootstrap ã«ã‚ˆã‚‹ä¿¡é ¼åŒºé–“
    """
    returns = (final_prices - S0) / S0
    
    # === æ¨™æº–çš„ãªVaR/CVaR ===
    var_95 = np.percentile(returns, 5)
    var_99 = np.percentile(returns, 1)
    
    cvar_95 = returns[returns <= var_95].mean()
    cvar_99 = returns[returns <= var_99].mean()
    
    # === æ‰‹æ³•7: Importance Sampling ===
    # ãƒ†ãƒ¼ãƒ«éƒ¨åˆ†ã‚’é‡ç‚¹çš„ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ç²¾åº¦å‘ä¸Š
    tail_returns = returns[returns < np.percentile(returns, 10)]
    if len(tail_returns) > 100:
        # ãƒ†ãƒ¼ãƒ«éƒ¨åˆ†ã®é‡ã¿ä»˜ãã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        weights = np.abs(tail_returns) / np.abs(tail_returns).sum()
        var_95_is = np.percentile(tail_returns, 50)  # é‡ç‚¹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‰ˆ
    else:
        var_95_is = var_95
    
    # === EVT (Extreme Value Theory) ===
    # æ¥µå€¤ç†è«–ã«ã‚ˆã‚‹è¶…éç¢ºç‡ã®æ¨å®š
    if evt_params and len(tail_returns) > 20:
        try:
            threshold = np.percentile(returns, 5)
            exceedances = returns[returns < threshold] - threshold
            
            # Generalized Pareto Distribution ãƒ•ã‚£ãƒƒãƒˆ
            shape, _, scale = stats.genpareto.fit(-exceedances, floc=0)
            
            # EVTãƒ™ãƒ¼ã‚¹ã®VaRæ¨å®š
            p = 0.01  # 99% VaR
            n_exceedances = len(exceedances)
            n_total = len(returns)
            
            if shape != 0:
                evt_var_99 = threshold - (scale / shape) * ((n_total / n_exceedances * p) ** (-shape) - 1)
            else:
                evt_var_99 = threshold - scale * np.log(n_total / n_exceedances * p)
            
            evt_var_99 = float(evt_var_99)
        except:
            evt_var_99 = var_99
    else:
        evt_var_99 = var_99
    
    # === Bootstrapä¿¡é ¼åŒºé–“ ===
    n_bootstrap = 1000
    var_95_bootstrap = []
    
    for _ in range(n_bootstrap):
        sample = np.random.choice(returns, size=len(returns), replace=True)
        var_95_bootstrap.append(np.percentile(sample, 5))
    
    var_95_ci_lower = np.percentile(var_95_bootstrap, 2.5)
    var_95_ci_upper = np.percentile(var_95_bootstrap, 97.5)
    
    return {
        "VaR 95%": var_95,
        "VaR 99%": var_99,
        "CVaR 95%": cvar_95,
        "CVaR 99%": cvar_99,
        "VaR 95% (IS)": var_95_is,
        "EVT VaR 99%": evt_var_99,
        "VaR 95% CI": (var_95_ci_lower, var_95_ci_upper)
    }

# =============================================================================
# ãƒ•ã‚¡ãƒ³ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ
# =============================================================================
def create_fan_chart(paths: np.ndarray, asset_name: str, T: float, dist_name: str) -> go.Figure:
    """Plotlyã§ãƒ•ã‚¡ãƒ³ãƒãƒ£ãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    n_steps = paths.shape[1]
    x = np.linspace(0, T, n_steps)
    
    # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®—
    p5 = np.percentile(paths, 5, axis=0)
    p10 = np.percentile(paths, 10, axis=0)
    p25 = np.percentile(paths, 25, axis=0)
    p50 = np.percentile(paths, 50, axis=0)
    p75 = np.percentile(paths, 75, axis=0)
    p90 = np.percentile(paths, 90, axis=0)
    p95 = np.percentile(paths, 95, axis=0)
    
    fig = go.Figure()
    
    # é¢ã®ã‚«ãƒ©ãƒ¼è¨­å®š (Student-tã®å ´åˆã¯å°‘ã—è‰²ã‚’å¤‰ãˆã‚‹)
    base_color = "100, 149, 237" if "Normal" in dist_name else "255, 127, 80"
    
    # 5-95% band
    fig.add_trace(go.Scatter(
        x=np.concatenate([x, x[::-1]]),
        y=np.concatenate([p95, p5[::-1]]),
        fill='toself',
        fillcolor=f'rgba({base_color}, 0.1)',
        line=dict(color='rgba(255,255,255,0)'),
        name='5-95%',
        showlegend=True
    ))
    
    # 10-90% band
    fig.add_trace(go.Scatter(
        x=np.concatenate([x, x[::-1]]),
        y=np.concatenate([p90, p10[::-1]]),
        fill='toself',
        fillcolor=f'rgba({base_color}, 0.2)',
        line=dict(color='rgba(255,255,255,0)'),
        name='10-90%',
        showlegend=True
    ))
    
    # 25-75% band
    fig.add_trace(go.Scatter(
        x=np.concatenate([x, x[::-1]]),
        y=np.concatenate([p75, p25[::-1]]),
        fill='toself',
        fillcolor=f'rgba({base_color}, 0.3)',
        line=dict(color='rgba(255,255,255,0)'),
        name='25-75%',
        showlegend=True
    ))
    
    # ä¸­å¤®å€¤ãƒ©ã‚¤ãƒ³
    fig.add_trace(go.Scatter(
        x=x,
        y=p50,
        mode='lines',
        line=dict(color='white' if "Normal" in dist_name else "gold", width=3),
        name='ä¸­å¤®å€¤ (Median)'
    ))
    
    # ç¾åœ¨ä¾¡æ ¼ãƒ©ã‚¤ãƒ³
    fig.add_hline(y=paths[0, 0], line_dash="dash", line_color="gray", 
                  annotation_text=f"ç¾çŠ¶ç¶­æŒ: {paths[0, 0]:,.0f}")
    
    fig.update_layout(
        title=f"ğŸ“Š {asset_name} - {T}å¹´ä¾¡æ ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ({dist_name})",
        xaxis_title="æœŸé–“ (å¹´)",
        yaxis_title="ä¾¡æ ¼",
        template="plotly_dark",
        height=600,
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        margin=dict(l=20, r=20, t=60, b=20)
    )
    
    return fig

# =============================================================================
# ãƒšãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
# =============================================================================
st.subheader("ğŸ² Monte Carlo Simulation")
st.caption("ğŸ’¡ é‡‘èå·¥å­¦ã«åŸºã¥ã„ãŸè³‡ç”£ä¾¡æ ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ12ã®é«˜åº¦ãªæ‰‹æ³•æ­è¼‰ï¼‰")

# === è¨­å®šã‚¨ãƒªã‚¢ï¼ˆãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å†…ï¼‰ ===
with st.expander("âš™ï¸ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š", expanded=True):
    col_asset, col_model, col_params = st.columns(3)
    
    with col_asset:
        st.markdown("**ğŸ“ˆ è³‡ç”£é¸æŠ**")
        selected_assets = st.multiselect(
            "ãƒ—ãƒªã‚»ãƒƒãƒˆè³‡ç”£",
            options=list(ASSETS.keys()),
            default=['S&P500'],
            label_visibility="collapsed"
        )
        custom_tickers = st.text_input(
            "ã‚«ã‚¹ã‚¿ãƒ ãƒ†ã‚£ãƒƒã‚«ãƒ¼",
            placeholder="ä¾‹: AAPL, 7203.T, ETH-USD",
            help="yfinanceãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›"
        )
    
    with col_model:
        st.markdown("**ğŸ² è¨ˆç®—ãƒ¢ãƒ‡ãƒ«**")
        dist_type = st.radio(
            "åˆ†å¸ƒæ§‹é€ ",
            options=["Normal (Gaussian)", "Student-t (Fat-tail)", "Jump-Diffusion (Merton)"],
            index=0,
            help="Normal: æ¨™æº–çš„ãªGBMã€‚Student-t: Fat-tailå¯¾å¿œã€‚Jump-Diffusion: ãƒ–ãƒ©ãƒƒã‚¯ã‚¹ãƒ¯ãƒ³ç´šã‚¤ãƒ™ãƒ³ãƒˆè€ƒæ…®ã€‚",
            label_visibility="collapsed"
        )
    
    with col_params:
        st.markdown("**ğŸ“Š ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**")
        T = st.slider("äºˆæ¸¬æœŸé–“ (å¹´å¾Œ)", 1, 10, 1)
        n_sim = st.selectbox(
            "è©¦è¡Œå›æ•°",
            options=[10000, 50000, 100000, 200000],
            index=2
        )

# å®Ÿè¡Œãƒœã‚¿ãƒ³ï¼ˆç›®ç«‹ã¤ä½ç½®ã«ï¼‰
run_button = st.button("ğŸš€ ãƒ—ãƒ­è¨ˆç®—ã‚’é–‹å§‹", type="primary", use_container_width=True)

st.markdown("---")

# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¯¾è±¡ãƒªã‚¹ãƒˆ
simulation_targets = []
for name in selected_assets:
    simulation_targets.append((name, ASSETS[name]))
if custom_tickers.strip():
    for t in custom_tickers.split(','):
        t = t.strip().upper()
        if t: simulation_targets.append((t, t))

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢è¡¨ç¤º
if not simulation_targets:
    st.info("ğŸ‘† ä¸Šã®è¨­å®šã‚¨ãƒªã‚¢ã§è³‡ç”£ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚")
elif run_button:
    for asset_name, ticker in simulation_targets:
        with st.container():
            st.markdown(f"### ğŸ“Š {asset_name} ({ticker}) ã®åˆ†æ")
            
            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            with st.spinner(f"å–å¾—ä¸­: {ticker}..."):
                df = fetch_asset_data(ticker)
            
            if df.empty:
                st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {ticker}")
                continue
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨ˆç®—
            params = calculate_params(df)
            S0 = float(df['Close'].iloc[-1].squeeze())
            
            # ãƒ¬ã‚¸ãƒ¼ãƒ è¡¨ç¤º
            regime_emoji = {"é«˜ãƒœãƒ©": "ğŸ”¥", "ä½ãƒœãƒ©": "â„ï¸", "é€šå¸¸": "ğŸ“Š", "ä¸æ˜": "â“"}
            st.caption(f"{regime_emoji.get(params['regime'], 'ğŸ“Š')} å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ : **{params['regime']}**")
            
            # ã‚¸ãƒ£ãƒ³ãƒ—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            jump_params = {
                "intensity": params["jump_intensity"],
                "mean": params["jump_mean"],
                "std": params["jump_std"]
            }
            
            # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
            with st.spinner(f"è¨ˆç®—ä¸­: {n_sim:,} å›ã®ãƒ‘ã‚¹ã‚’ç”Ÿæˆ..."):
                paths = run_monte_carlo(
                    S0, params["mu"], params["sigma"], T, 
                    dist_type=dist_type, df_t=params["df_t"],
                    jump_params=jump_params,
                    n_simulations=n_sim
                )
            
            # ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º
            fig = create_fan_chart(paths, asset_name, T, dist_type)
            st.plotly_chart(fig, use_container_width=True)
            
            # åˆ†ææŒ‡æ¨™ã®è¨ˆç®—
            final_prices = paths[:, -1]
            p10 = np.percentile(final_prices, 10)
            p50 = np.percentile(final_prices, 50)
            p90 = np.percentile(final_prices, 90)
            
            evt_params = {
                "threshold": params["evt_threshold"],
                "shape": params["evt_shape"]
            }
            risk = calculate_risk_metrics(S0, final_prices, evt_params)
            
            change_pct = (p50 - S0) / S0 * 100
            future_str = (datetime.now() + timedelta(days=T*365)).strftime("%Y/%m")
            
            # çµæœã‚°ãƒªãƒƒãƒ‰
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æœŸå¾…ä¾¡æ ¼ (ä¸­å¤®å€¤)", f"{p50:,.0f}", f"{change_pct:+.2f}%")
                st.write(f"**å¼·æ°— (ä¸Šä½10%):** {p90:,.0f}")
                st.write(f"**å¼±æ°— (ä¸‹ä½10%):** {p10:,.0f}")
            
            with col2:
                st.write("ğŸ›¡ **ãƒªã‚¹ã‚¯æŒ‡æ¨™**")
                st.write(f"**VaR 95%:** {risk['VaR 95%']*100:.2f}%")
                st.write(f"**CVaR 95%:** {risk['CVaR 95%']*100:.2f}%")
                st.write(f"**EVT VaR 99%:** {risk['EVT VaR 99%']*100:.2f}%")
                ci_lower, ci_upper = risk['VaR 95% CI']
                st.caption(f"VaR 95% ä¿¡é ¼åŒºé–“: [{ci_lower*100:.2f}%, {ci_upper*100:.2f}%]")
            
            with col3:
                st.write("ğŸ“Š **ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ãƒ»ã‚¹ã‚¿ãƒƒãƒ„**")
                st.write(f"**å¹´ç‡åŒ–ãƒªã‚¿ãƒ¼ãƒ³:** {params['mu']*100:.2f}%")
                st.write(f"**å¹´ç‡åŒ–ãƒœãƒ©:** {params['sigma']*100:.2f}%")
                if "Student-t" in dist_type:
                    st.write(f"**è‡ªç”±åº¦(æ¨å®š):** {params['df_t']:.2f}")
                    st.caption("è‡ªç”±åº¦ãŒä½ã„ã»ã©Fat-tailï¼ˆæ³¢ä¹±å«ã¿ï¼‰")
                if "Jump" in dist_type:
                    annual_jump_freq = params['jump_intensity'] * 252  # å¹´ç‡ã«å¤‰æ›
                    st.write(f"**ã‚¸ãƒ£ãƒ³ãƒ—é »åº¦:** å¹´{annual_jump_freq:.1f}å›")
                    st.caption(f"å¹³å‡ã‚¸ãƒ£ãƒ³ãƒ—: {params['jump_mean']*100:.1f}%")

            st.divider()

else:
    st.markdown("""
    ### ğŸ² Monte Carlo Simulation ã¸ã‚ˆã†ã“ã
    
    ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€**é‡‘èå·¥å­¦ã«åŸºã¥ã„ãŸ**è³‡ç”£ä¾¡æ ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚
    
    **ğŸ¯ ãƒ¢ãƒ‡ãƒ«ã®é¸ã³æ–¹ï¼ˆæ¨å¥¨ï¼‰:**
    
    | ãƒ¢ãƒ‡ãƒ« | ã“ã‚“ãªæ™‚ã«ä½¿ã† | å¯¾è±¡è³‡ç”£ |
    |--------|--------------|---------|
    | **Normal** â­æ¨å¥¨ | é€šå¸¸ã®äºˆæ¸¬ãƒ»åˆã‚ã¦ã®æ–¹ | æ ªå¼ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ |
    | **Student-t** | æš´è½ãƒªã‚¹ã‚¯ã‚’è€ƒæ…®ã—ãŸã„ | ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®é«˜ã„è³‡ç”£ |
    | **Jump-Diffusion** | æœ€æ‚ªã®ã‚·ãƒŠãƒªã‚ªã‚’è¦‹ãŸã„ | æš—å·è³‡ç”£ã€æ–°èˆˆå›½æ ª |
    
    > ğŸ’¡ **è¿·ã£ãŸã‚‰Normalã§OKã§ã™ã€‚** Student-tã‚„Jump-Diffusionã¯ã‚ˆã‚Šæ‚²è¦³çš„ãªäºˆæ¸¬ã«ãªã‚Šã¾ã™ã€‚
    
    ---
    
    **æ­è¼‰æŠ€è¡“ï¼ˆ12å€‹ã®é«˜åº¦ãªæ‰‹æ³•ï¼‰:**
    - åˆ†æ•£å‰Šæ¸›æŠ€æ³•ï¼ˆAntithetic Variates, QMC, Stratified Samplingï¼‰
    - ãƒªã‚¹ã‚¯åˆ†æï¼ˆVaR, CVaR, EVT, Bootstrapï¼‰
    - å¸‚å ´åˆ†æï¼ˆRegime Detection, Jump Parameter Estimationï¼‰
    
    ---
    
    âš ï¸ **å…è²¬äº‹é …:**
    - ã“ã®ã‚¢ãƒ—ãƒªã®å‡ºåŠ›ã¯**æŠ•è³‡åŠ©è¨€ã§ã¯ã‚ã‚Šã¾ã›ã‚“**
    - éå»ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚ã‚Šã€**å°†æ¥ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“**
    - æŠ•è³‡åˆ¤æ–­ã¯å¿…ãš**è‡ªå·±è²¬ä»»**ã§è¡Œã£ã¦ãã ã•ã„
    
    ğŸ‘† ä¸Šã®è¨­å®šã‚¨ãƒªã‚¢ã§è³‡ç”£ã‚’é¸ã‚“ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚
    """)

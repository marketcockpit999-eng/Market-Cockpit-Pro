# -*- coding: utf-8 -*-
"""
Market Cockpit Pro - Page 7: Market Voices
ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€RSSã€ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ã‚¹ã‚­ãƒ£ãƒŠãƒ¼
"""

import streamlit as st
import datetime
import json
import re
import feedparser
import sys
import os

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils import (
    GEMINI_MODEL,
    CONTEXT_KEYWORDS,
    RSS_FEEDS,
    search_google_news,
    get_time_diff_str,
    run_gemini_analysis,
)

# Get AI client from session state
gemini_client = st.session_state.get('gemini_client')

# ========== PAGE CONTENT ==========
st.subheader("ğŸ“° Market Voices")
st.caption("ğŸ’¡ AI ãŒä¸–ç•Œä¸­ã®ä¸€æ¬¡æƒ…å ±ã‚’è‡ªå‹•ã‚¹ã‚­ãƒ£ãƒ³ - é‡è¦åº¦ã§ãƒ©ãƒ³ã‚¯ä»˜ã‘")

# === Auto Intelligence Scanner ===
st.markdown("### ğŸ¤– å…¨è‡ªå‹•ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ãƒ»ã‚¹ã‚­ãƒ£ãƒŠãƒ¼")
st.caption("ä¸»è¦ã‚«ãƒ†ã‚´ãƒªã‚’è‡ªå‹•å·¡å›ã—ã€AIãŒé‡è¦åº¦ã‚’åˆ¤å®šã—ã¦ä¸Šä½ã®ã¿è¡¨ç¤º")

col_btn1, col_btn2 = st.columns([3, 1])

with col_btn2:
    if 'daily_briefing_time' in st.session_state:
        st.caption(f"âœ… æœ€çµ‚ã‚¹ã‚­ãƒ£ãƒ³: {st.session_state['daily_briefing_time']}")

if st.button("ğŸ›°ï¸ å…¨ã‚«ãƒ†ã‚´ãƒªã‚’ä¸€æ–‰ã‚¹ã‚­ãƒ£ãƒ³ (AIé‡è¦åº¦åˆ¤å®šä»˜)", type="primary"):
    if gemini_client:
        all_findings = []
        with st.status("ğŸŒ ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ç¶²ã‚’èµ°æŸ»ä¸­...") as status:
            for cat_name, config in CONTEXT_KEYWORDS.items():
                st.write(f"ğŸ“¡ {cat_name} ã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­...")
                try:
                    news = search_google_news(config['main_keyword'], num_results=3, mode='primary')
                    if news and "è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ" not in news:
                        all_findings.append({
                            "category": cat_name,
                            "keyword": config['main_keyword'],
                            "headlines": news
                        })
                except:
                    pass
            status.update(label="âœ… ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†", state="complete")
        
        if all_findings:
            analysis_prompt = f"""ã‚ãªãŸã¯æ•è…•ãƒ˜ãƒƒã‚¸ãƒ•ã‚¡ãƒ³ãƒ‰ã®ãƒªã‚µãƒ¼ãƒè²¬ä»»è€…ã§ã™ã€‚
ä»¥ä¸‹ã®ã‚«ãƒ†ã‚´ãƒªåˆ¥ä¸€æ¬¡æƒ…å ±ã‹ã‚‰ã€å¸‚å ´ã¸ã®æ§‹é€ çš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒæœ€ã‚‚å¤§ãã„æƒ…å ±ã‚’ç‰¹å®šã—ã€
æ—¥æœ¬èªã§æˆ¦ç•¥çš„ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€ã‚¹ã‚­ãƒ£ãƒ³ãƒ‡ãƒ¼ã‚¿ã€‘
{json.dumps(all_findings, indent=2, ensure_ascii=False)}
"""
            with st.spinner("ğŸ§  AIãŒé‡è¦åº¦ã‚’åˆ†æä¸­..."):
                try:
                    report = run_gemini_analysis(gemini_client, GEMINI_MODEL, analysis_prompt, use_search=False)
                    st.session_state['daily_briefing_cache'] = all_findings
                    st.session_state['daily_briefing_report'] = report
                    st.session_state['daily_briefing_time'] = datetime.datetime.now().strftime('%H:%M')
                except Exception as e:
                    st.error(f"AIåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.warning("âš ï¸ æœ‰ç›Šãªæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.error("âš ï¸ AIè¨­å®šãŒä¸å®Œå…¨ã§ã™ã€‚")

# Display results
if st.session_state.get('daily_briefing_report'):
    st.info(st.session_state['daily_briefing_report'])
    with st.expander("ğŸ” åé›†ã‚½ãƒ¼ã‚¹è©³ç´°"):
        for f in st.session_state.get('daily_briefing_cache', []):
            st.markdown(f"**{f['category']}**")
            st.markdown(f['headlines'])
            st.divider()

st.markdown("---")

# === Manual Hunter ===
st.markdown("### ğŸ” æ‰‹å‹•ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ãƒ»ãƒãƒ³ã‚¿ãƒ¼")
with st.expander("ğŸ”§ è©³ç´°æ¤œç´¢è¨­å®š", expanded=False):
    search_query = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›", placeholder="ä¾‹: Treasury buyback, Meta nuclear power")
    gl_choice = st.radio("æ¤œç´¢åœ°åŸŸ", ["US", "JP", "GB", "SG"], horizontal=True)
    
    if st.button("ğŸ” ãƒãƒ³ãƒ†ã‚£ãƒ³ã‚°é–‹å§‹") and search_query:
        if gemini_client:
            with st.spinner("ğŸ•µï¸ æƒ…å ±ã‚’åé›†ä¸­..."):
                results = search_google_news(search_query, num_results=5, gl=gl_choice, mode='primary')
                eval_prompt = f"ä»¥ä¸‹ã®æƒ…å ±ã‚’è©•ä¾¡ã—ã€å¸‚å ´ã¸ã®ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚’åˆ†æã—ã¦ãã ã•ã„:\n\n{results}"
                try:
                    report = run_gemini_analysis(gemini_client, GEMINI_MODEL, eval_prompt, use_search=False)
                    st.markdown("### ğŸ’ AIåˆ†æçµæœ")
                    st.success(report)
                    with st.expander("ğŸ“„ ã‚½ãƒ¼ã‚¹ä¸€è¦§"):
                        st.markdown(results)
                except Exception as e:
                    st.error(f"AIã‚¨ãƒ©ãƒ¼: {e}")

st.markdown("---")

# === News Feeds ===
st.markdown("### ğŸ“¡ Global News Feeds")

feed_tabs = st.tabs(list(RSS_FEEDS.keys()))
for idx, (name, url) in enumerate(RSS_FEEDS.items()):
    with feed_tabs[idx]:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:5]:
                time_str = get_time_diff_str(entry.get('published', ''))
                with st.expander(f"â³ {time_str} - {entry.get('title')}"):
                    st.write(re.sub('<[^<]+?>', '', entry.get('summary', ''))[:500])
                    st.markdown(f"[ğŸ”— Link]({entry.get('link')})")
        except:
            st.caption("å–å¾—ã‚¨ãƒ©ãƒ¼")

# -*- coding: utf-8 -*-
"""
Market Cockpit Pro - Admin Dashboard
================================================================================
ç®¡ç†è€…ç”¨ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: ãƒ‡ãƒ¼ã‚¿é®®åº¦ã€è¡¨ç¤ºãƒ‘ã‚¿ãƒ¼ãƒ³ã€APIçŠ¶æ³ã‚’ä¸€è¦§è¡¨ç¤º

æ©Ÿèƒ½:
  1. ãƒ‡ãƒ¼ã‚¿é®®åº¦ä¸€è¦§ (101é …ç›®)
  2. è¡¨ç¤ºãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯çµæœ
  3. APIæ¥ç¶šçŠ¶æ³
  4. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
  5. ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
================================================================================
"""

import streamlit as st
import pandas as pd
import os
from datetime import datetime

from utils import (
    t,
    get_data_freshness_status,
    get_api_status,
    INDICATORS,
    get_all_indicator_names,
)
from utils.display_checker import (
    verify_display_patterns,
    DisplayChecker,
    run_static_check,
)


def render_admin_page():
    """Render the admin dashboard page"""
    st.title("ğŸ”§ Admin Dashboard")
    st.caption("ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†ãƒ»è¨ºæ–­ãƒ„ãƒ¼ãƒ«")
    
    # Get data from session state
    df = st.session_state.get('df')
    df_original = st.session_state.get('df_original')
    
    # Create tabs for different admin sections
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“Š ãƒ‡ãƒ¼ã‚¿é®®åº¦",
        "âœ… è¡¨ç¤ºãƒ‘ã‚¿ãƒ¼ãƒ³",
        "ğŸ”Œ APIçŠ¶æ³",
        "âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±",
    ])
    
    # =========================================================================
    # TAB 1: Data Freshness (ãƒ‡ãƒ¼ã‚¿é®®åº¦)
    # =========================================================================
    with tab1:
        render_data_freshness_tab(df)
    
    # =========================================================================
    # TAB 2: Display Pattern Check (è¡¨ç¤ºãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯)
    # =========================================================================
    with tab2:
        render_display_pattern_tab()
    
    # =========================================================================
    # TAB 3: API Status (APIçŠ¶æ³)
    # =========================================================================
    with tab3:
        render_api_status_tab()
    
    # =========================================================================
    # TAB 4: System Info (ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±)
    # =========================================================================
    with tab4:
        render_system_info_tab(df)


def render_data_freshness_tab(df):
    """Render the data freshness tab"""
    st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿é®®åº¦ä¸€è¦§")
    
    if df is None or not hasattr(df, 'attrs'):
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã§èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    
    # Get freshness status
    last_valid_dates = df.attrs.get('last_valid_dates', {})
    release_dates = df.attrs.get('fred_release_dates', {})
    api_status = get_api_status()
    
    freshness = get_data_freshness_status(last_valid_dates, release_dates, api_status)
    
    # Summary metrics
    summary = freshness['summary']
    col1, col2, col3, col4, col5 = st.columns(5)
    col1.metric("Total", summary['total'])
    col2.metric("ğŸŸ¢ Fresh", summary['fresh_count'])
    col3.metric("ğŸŸ¡ Stale", summary['stale_count'])
    col4.metric("ğŸ”´ Critical", summary['critical_count'])
    col5.metric("âšª Missing", summary['missing_count'])
    
    st.metric("Health Score", f"{summary['health_score']}%")
    
    st.divider()
    
    # Filter options
    col_filter1, col_filter2 = st.columns(2)
    with col_filter1:
        status_filter = st.multiselect(
            "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿",
            options=["fresh", "stale", "critical", "missing"],
            default=["stale", "critical", "missing"],
            format_func=lambda x: {"fresh": "ğŸŸ¢ Fresh", "stale": "ğŸŸ¡ Stale", "critical": "ğŸ”´ Critical", "missing": "âšª Missing"}[x]
        )
    with col_filter2:
        show_api_only = st.checkbox("APIæŒ‡æ¨™ã®ã¿è¡¨ç¤º", value=False)
    
    # Build detail table
    rows = []
    for indicator, detail in freshness['details'].items():
        if detail['status'] not in status_filter:
            continue
        if show_api_only and not detail.get('is_api', False):
            continue
        
        status_emoji = {
            'fresh': 'ğŸŸ¢',
            'stale': 'ğŸŸ¡',
            'critical': 'ğŸ”´',
            'missing': 'âšª'
        }.get(detail['status'], 'â“')
        
        rows.append({
            'Status': status_emoji,
            'Indicator': indicator,
            'Last Date': detail.get('last_date') or 'N/A',
            'Days Old': detail.get('days_old') if detail.get('days_old') is not None else '-',
            'Category': detail.get('category', 'Unknown'),
            'API': 'âœ“' if detail.get('is_api') else '',
            'Expected Max': detail.get('expected_max') or '-',
        })
    
    if rows:
        df_table = pd.DataFrame(rows)
        st.dataframe(
            df_table,
            use_container_width=True,
            hide_index=True,
            column_config={
                "Status": st.column_config.TextColumn("", width="small"),
                "Indicator": st.column_config.TextColumn("æŒ‡æ¨™å", width="medium"),
                "Last Date": st.column_config.TextColumn("æœ€çµ‚æ—¥ä»˜", width="small"),
                "Days Old": st.column_config.NumberColumn("çµŒéæ—¥æ•°", width="small"),
                "Category": st.column_config.TextColumn("ã‚«ãƒ†ã‚´ãƒª", width="small"),
                "API": st.column_config.TextColumn("API", width="small"),
                "Expected Max": st.column_config.NumberColumn("è¨±å®¹æ—¥æ•°", width="small"),
            }
        )
        st.caption(f"è¡¨ç¤ºä¸­: {len(rows)} ä»¶")
    else:
        st.info("è©²å½“ã™ã‚‹æŒ‡æ¨™ãŒã‚ã‚Šã¾ã›ã‚“")


def render_display_pattern_tab():
    """Render the display pattern check tab"""
    st.subheader("âœ… è¡¨ç¤ºãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯")
    
    # Run verification
    app_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    with st.spinner("ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œè¨¼ä¸­..."):
        results = verify_display_patterns(app_root)
    
    # Summary
    total_found = (
        len(results['pattern_standard']) + 
        len(results['pattern_detailed']) + 
        len(results['pattern_manual']) + 
        len(results['pattern_special'])
    )
    error_count = len(results['errors'])
    mismatch_count = len(results.get('pattern_mismatches', []))
    warning_count = len([w for w in results.get('element_warnings', []) if w['severity'] == 'WARN'])
    
    # Metrics
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("æ¤œå‡ºæ¸ˆã¿æŒ‡æ¨™", total_found)
    col2.metric("Standard (Sparkline)", len(results['pattern_standard']))
    col3.metric("Detailed (Macro Card)", len(results['pattern_detailed']))
    col4.metric("Manual / Special", len(results['pattern_manual']) + len(results['pattern_special']))
    
    # Status indicator
    if error_count == 0 and mismatch_count == 0:
        st.success("âœ… All patterns match their expected display functions!")
    else:
        st.error(f"âŒ {error_count + mismatch_count} issue(s) found")
    
    st.divider()
    
    # Pattern breakdown
    with st.expander("ğŸ“‹ Standard Pattern (show_metric_with_sparkline)", expanded=False):
        if results['pattern_standard']:
            by_file = {}
            for item in results['pattern_standard']:
                file = item['file']
                if file not in by_file:
                    by_file[file] = []
                by_file[file].append(item['key'])
            
            for file in sorted(by_file.keys()):
                st.write(f"**{file}** ({len(by_file[file])}ä»¶)")
                st.caption(", ".join(sorted(by_file[file])))
    
    with st.expander("ğŸ“Š Detailed Pattern (display_macro_card)", expanded=False):
        if results['pattern_detailed']:
            for item in results['pattern_detailed']:
                st.write(f"- `{item['key']}` â†’ {item['file']}")
    
    with st.expander("ğŸ”§ Manual / Custom Pattern", expanded=False):
        if results['pattern_manual']:
            for item in results['pattern_manual']:
                st.write(f"- `{item['key']}` â†’ {item['file']} ({item['type']})")
    
    with st.expander("ğŸ”Œ Special / API Pattern", expanded=False):
        if results['pattern_special']:
            for item in results['pattern_special']:
                st.write(f"- `{item['key']}`: {item['reason']}")
    
    # Errors and mismatches
    if results['errors']:
        with st.expander(f"âŒ Errors ({len(results['errors'])})", expanded=True):
            for error in results['errors']:
                st.error(error)
    
    if results.get('pattern_mismatches'):
        with st.expander(f"âš ï¸ Pattern Mismatches ({len(results['pattern_mismatches'])})", expanded=True):
            for item in results['pattern_mismatches']:
                st.warning(f"`{item['key']}`: Expected `{item['expected']}` but found `{item['actual']}` in {item['file']}")
    
    # Element warnings (Phase 3.5)
    element_warnings = results.get('element_warnings', [])
    warn_items = [w for w in element_warnings if w['severity'] == 'WARN']
    if warn_items:
        with st.expander(f"âš ï¸ Element Warnings ({len(warn_items)})", expanded=False):
            for item in warn_items:
                st.warning(f"`{item['key']}` ({item['file']}): {item['message']}")


def render_api_status_tab():
    """Render the API status tab"""
    st.subheader("ğŸ”Œ APIæ¥ç¶šçŠ¶æ³")
    
    api_status = get_api_status()
    
    if not api_status:
        st.info("APIçŠ¶æ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«è‡ªå‹•å–å¾—ã•ã‚Œã¾ã™ã€‚")
        return
    
    # Summary
    total = len(api_status)
    success_count = sum(1 for v in api_status.values() if v.get('success'))
    fail_count = total - success_count
    
    col1, col2, col3 = st.columns(3)
    col1.metric("Total APIs", total)
    col2.metric("âœ… Success", success_count)
    col3.metric("âŒ Failed", fail_count)
    
    st.divider()
    
    # Detail table
    rows = []
    for name, status in api_status.items():
        rows.append({
            'Status': 'âœ…' if status.get('success') else 'âŒ',
            'API Name': name,
            'Last Fetch': status.get('last_fetch', 'N/A'),
            'Error': status.get('error', '') if not status.get('success') else '',
        })
    
    df_table = pd.DataFrame(rows)
    st.dataframe(
        df_table,
        use_container_width=True,
        hide_index=True,
        column_config={
            "Status": st.column_config.TextColumn("", width="small"),
            "API Name": st.column_config.TextColumn("APIå", width="medium"),
            "Last Fetch": st.column_config.TextColumn("æœ€çµ‚å–å¾—æ—¥", width="small"),
            "Error": st.column_config.TextColumn("ã‚¨ãƒ©ãƒ¼", width="large"),
        }
    )


def render_system_info_tab(df):
    """Render the system info tab"""
    st.subheader("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    
    # Cache management
    st.write("### ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†")
    
    cache_file = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
        '.market_data_cache.pkl'
    )
    
    if os.path.exists(cache_file):
        cache_stat = os.stat(cache_file)
        cache_size = cache_stat.st_size / 1024 / 1024  # MB
        cache_mtime = datetime.fromtimestamp(cache_stat.st_mtime)
        
        col1, col2 = st.columns(2)
        col1.metric("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º", f"{cache_size:.2f} MB")
        col2.metric("æœ€çµ‚æ›´æ–°", cache_mtime.strftime('%Y-%m-%d %H:%M:%S'))
        
        if st.button("ğŸ—‘ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤", type="secondary"):
            try:
                os.remove(cache_file)
                st.success("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
                st.session_state['force_refresh'] = True
            except Exception as e:
                st.error(f"å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        st.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã¯å­˜åœ¨ã—ã¾ã›ã‚“")
    
    st.divider()
    
    # Indicator Registry Stats
    st.write("### æŒ‡æ¨™ãƒ¬ã‚¸ã‚¹ãƒˆãƒªçµ±è¨ˆ")
    
    total_indicators = len(INDICATORS)
    
    # Count by source
    by_source = {}
    for name, config in INDICATORS.items():
        source = config.get('source', 'UNKNOWN')
        by_source[source] = by_source.get(source, 0) + 1
    
    # Count by pattern
    by_pattern = {}
    for name, config in INDICATORS.items():
        pattern = config.get('display_pattern', 'standard')
        by_pattern[pattern] = by_pattern.get(pattern, 0) + 1
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ã‚½ãƒ¼ã‚¹åˆ¥**")
        for source, count in sorted(by_source.items()):
            st.write(f"- {source}: {count}")
    
    with col2:
        st.write("**è¡¨ç¤ºãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥**")
        for pattern, count in sorted(by_pattern.items()):
            st.write(f"- {pattern}: {count}")
    
    st.metric("ç·æŒ‡æ¨™æ•°", total_indicators)
    
    st.divider()
    
    # DataFrame Info
    st.write("### DataFrameæƒ…å ±")
    
    if df is not None:
        col1, col2, col3 = st.columns(3)
        col1.metric("è¡Œæ•°", len(df))
        col2.metric("åˆ—æ•°", len(df.columns))
        col3.metric("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡", f"{df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB")
        
        st.write("**æ—¥ä»˜ç¯„å›²:**")
        st.write(f"- é–‹å§‹: {df.index.min()}")
        st.write(f"- çµ‚äº†: {df.index.max()}")
    else:
        st.info("DataFrameãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
    
    st.divider()
    
    # Version Info
    st.write("### ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±")
    st.write("- **App Version:** 2.2.0 (i18n Edition)")
    st.write(f"- **Python:** {__import__('sys').version.split()[0]}")
    st.write(f"- **Streamlit:** {st.__version__}")
    st.write(f"- **Pandas:** {pd.__version__}")


# =============================================================================
# MAIN ENTRY POINT
# =============================================================================
render_admin_page()

import streamlit as st
import pandas as pd
import pandas_datareader.data as web
import yfinance as yf
import datetime
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import feedparser
import os
import requests
import re
import json
import uuid
import pickle
import time
from io import StringIO
from dotenv import load_dotenv
from google import genai
import anthropic

# Load environment variables
load_dotenv()

# Configure Gemini API (new google.genai library)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
gemini_client = None
if GEMINI_API_KEY:
    gemini_client = genai.Client(api_key=GEMINI_API_KEY)

# Configure Claude API
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
claude_client = None
if ANTHROPIC_API_KEY:
    claude_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

# Model names for latest reasoning AI
GEMINI_MODEL = "gemini-3-flash-preview"  # Latest Gemini 3 Flash
CLAUDE_MODEL = "claude-opus-4-5-20251101"  # Latest Claude Opus 4.5

st.set_page_config(layout="wide", page_title="Market Cockpit Pro")

# ========== BACK TO TOP BUTTON (CSS ONLY) ==========
st.markdown("""
<style>
    /* Back to Top Button - Always visible */
    .back-to-top-btn {
        position: fixed;
        bottom: 30px;
        right: 30px;
        z-index: 9999;
        width: 50px;
        height: 50px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 10px;
        cursor: pointer;
        display: flex;
        align-items: center;
        justify-content: center;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        transition: all 0.3s ease;
        text-decoration: none;
    }
    .back-to-top-btn:hover {
        transform: translateY(-3px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
        color: white;
    }
    .back-to-top-btn svg {
        width: 24px;
        height: 24px;
    }
    /* Page top anchor */
    #page-top {
        position: absolute;
        top: 0;
    }
</style>

<div id="page-top"></div>

<a href="#page-top" class="back-to-top-btn" title="ãƒšãƒ¼ã‚¸ãƒˆãƒƒãƒ—ã«æˆ»ã‚‹">
    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 15l7-7 7 7" />
    </svg>
</a>
""", unsafe_allow_html=True)

# ========== SETTINGS ==========
FRED_API_KEY = "4e9f89c09658e42a4362d1251d9a3d05"
PAGE_TITLE = "Market Cockpit Pro"
MANUAL_DATA_FILE = "manual_h41_data.csv"

# ========== DATA FRESHNESS MONITORING ==========
# Update frequency categories (in days)
DATA_FRESHNESS_RULES = {
    # Daily data (market days)
    'daily': {
        'fresh': 3,      # ğŸŸ¢ â‰¤3 days old
        'stale': 7,      # ğŸŸ¡ 4-7 days old
        'critical': 14,  # ğŸ”´ >7 days old
        'indicators': ['EFFR', 'IORB', 'SOFR', 'SP500', 'VIX', 'HYG', 'DXY', 'USDJPY', 
                      'EURUSD', 'USDCNY', 'Gold', 'Silver', 'Oil', 'Copper', 'BTC', 'ETH',
                      'Credit_Spread', 'US_TNX', 'T10Y2Y', 'ON_RRP', 'FedFundsUpper', 'FedFundsLower']
    },
    # Weekly data (Fed H.4.1 etc)
    'weekly': {
        'fresh': 10,     # ğŸŸ¢ â‰¤10 days old
        'stale': 14,     # ğŸŸ¡ 11-14 days old
        'critical': 21,  # ğŸ”´ >14 days old
        'indicators': ['Reserves', 'TGA', 'Fed_Assets', 'SOMA_Total', 'SOMA_Bills', 
                      'SRF', 'FIMA', 'Primary_Credit', 'Total_Loans', 'Bank_Cash', 'ICSA']
    },
    # Monthly data
    'monthly': {
        'fresh': 45,     # ğŸŸ¢ â‰¤45 days old
        'stale': 60,     # ğŸŸ¡ 46-60 days old
        'critical': 90,  # ğŸ”´ >60 days old
        'indicators': ['M2SL', 'M2REAL', 'CPI', 'CPICore', 'PPI', 'Unemployment', 'UNRATE', 'CorePCE', 
                      'ConsumerSent', 'CN_M2', 'JP_M2', 'EU_M2', 'NFP', 'AvgHourlyEarnings', 'JOLTS',
                      'RetailSales', 'CN_CPI', 'JP_CPI', 'EU_CPI']
    },
    # Quarterly data
    'quarterly': {
        'fresh': 100,    # ğŸŸ¢ â‰¤100 days old
        'stale': 120,    # ğŸŸ¡ 101-120 days old
        'critical': 150, # ğŸ”´ >120 days old
        'indicators': ['Lending_Standards', 'CI_Std_Large', 'CI_Std_Small', 'CI_Demand',
                      'CRE_Std_Construction', 'CRE_Std_Office', 'CRE_Std_Multifamily', 'CRE_Demand', 'RealGDP']
    }
}

# Data frequency labels for display
DATA_FREQUENCY = {
    # Daily
    'EFFR': 'æ—¥æ¬¡', 'IORB': 'æ—¥æ¬¡', 'SOFR': 'æ—¥æ¬¡', 'SP500': 'æ—¥æ¬¡', 'VIX': 'æ—¥æ¬¡', 
    'HYG': 'æ—¥æ¬¡', 'DXY': 'æ—¥æ¬¡', 'USDJPY': 'æ—¥æ¬¡', 'EURUSD': 'æ—¥æ¬¡', 'USDCNY': 'æ—¥æ¬¡',
    'Gold': 'æ—¥æ¬¡', 'Silver': 'æ—¥æ¬¡', 'Oil': 'æ—¥æ¬¡', 'Copper': 'æ—¥æ¬¡', 'BTC': 'æ—¥æ¬¡', 'ETH': 'æ—¥æ¬¡',
    'Credit_Spread': 'æ—¥æ¬¡', 'US_TNX': 'æ—¥æ¬¡', 'T10Y2Y': 'æ—¥æ¬¡', 'ON_RRP': 'æ—¥æ¬¡',
    # Weekly
    'Reserves': 'é€±æ¬¡', 'TGA': 'é€±æ¬¡', 'Fed_Assets': 'é€±æ¬¡', 'SOMA_Total': 'é€±æ¬¡', 'SOMA_Bills': 'é€±æ¬¡',
    'SRF': 'é€±æ¬¡', 'FIMA': 'é€±æ¬¡', 'Primary_Credit': 'é€±æ¬¡', 'Total_Loans': 'é€±æ¬¡', 
    'Bank_Cash': 'é€±æ¬¡', 'ICSA': 'é€±æ¬¡', 'Net_Liquidity': 'é€±æ¬¡', 'SomaBillsRatio': 'é€±æ¬¡',
    'FedFundsUpper': 'æ—¥æ¬¡', 'FedFundsLower': 'æ—¥æ¬¡',
    # Monthly
    'M2SL': 'æœˆæ¬¡', 'M2REAL': 'æœˆæ¬¡', 'CPI': 'æœˆæ¬¡', 'CPICore': 'æœˆæ¬¡', 'PPI': 'æœˆæ¬¡', 'Unemployment': 'æœˆæ¬¡', 'UNRATE': 'æœˆæ¬¡',
    'CorePCE': 'æœˆæ¬¡', 'ConsumerSent': 'æœˆæ¬¡', 'CN_M2': 'æœˆæ¬¡', 'JP_M2': 'æœˆæ¬¡', 'EU_M2': 'æœˆæ¬¡',
    'CN_CPI': 'æœˆæ¬¡', 'JP_CPI': 'æœˆæ¬¡', 'EU_CPI': 'æœˆæ¬¡', 'US_Real_M2_Index': 'æœˆæ¬¡',
    'NFP': 'æœˆæ¬¡', 'AvgHourlyEarnings': 'æœˆæ¬¡', 'JOLTS': 'æœˆæ¬¡', 'RetailSales': 'æœˆæ¬¡',
    # Quarterly
    'Lending_Standards': 'å››åŠæœŸ', 'RealGDP': 'å››åŠæœŸ',
    'CI_Std_Large': 'å››åŠæœŸ', 'CI_Std_Small': 'å››åŠæœŸ', 'CI_Demand': 'å››åŠæœŸ',
    'CRE_Std_Construction': 'å››åŠæœŸ', 'CRE_Std_Office': 'å››åŠæœŸ', 'CRE_Std_Multifamily': 'å››åŠæœŸ', 'CRE_Demand': 'å››åŠæœŸ',
    # Monthly (SLOOS Loan Balances)
    'CI_Loans': 'æœˆæ¬¡',
    # Weekly (SLOOS Loan Balances)
    'CRE_Loans': 'é€±æ¬¡',
}

def get_data_freshness_status(last_valid_dates: dict, release_dates: dict = None) -> dict:
    """
    Check data freshness for all indicators.
    Priority: Actual release_dates (provider update) > last_valid_dates (observation date)
    Returns: dict with 'summary' and 'details'
    """
    from datetime import datetime, timedelta
    
    today = datetime.now().date()
    
    results = {
        'fresh': [],    # ğŸŸ¢
        'stale': [],    # ğŸŸ¡
        'critical': [], # ğŸ”´
        'missing': [],  # âš«
        'details': {}   # Full details per indicator
    }
    
    # Build indicator -> category mapping
    indicator_category = {}
    for category, config in DATA_FRESHNESS_RULES.items():
        for ind in config['indicators']:
            indicator_category[ind] = category
    
    for indicator, date_str in last_valid_dates.items():
        if indicator in ['RMP_Alert_Active', 'RMP_Status_Text']:  # Skip non-data columns
            continue
            
        try:
            # Decide which date to use for freshness check
            # Use release_date if available (ACTUAL update), fallback to observation date
            check_date_str = date_str
            is_priority_release = False
            
            if release_dates and indicator in release_dates and release_dates[indicator]:
                check_date_str = release_dates[indicator]
                is_priority_release = True
                
            last_date = datetime.strptime(check_date_str, '%Y-%m-%d').date()
            days_old = (today - last_date).days
            
            # Get freshness rules for this indicator
            category = indicator_category.get(indicator, 'weekly')  # Default to weekly
            rules = DATA_FRESHNESS_RULES[category]
            
            if days_old <= rules['fresh']:
                status = 'fresh'
                results['fresh'].append(indicator)
            elif days_old <= rules['stale']:
                status = 'stale'
                results['stale'].append(indicator)
            else:
                status = 'critical'
                results['critical'].append(indicator)
            
            results['details'][indicator] = {
                'last_date': date_str,
                'release_date': release_dates.get(indicator) if release_dates else None,
                'days_old': days_old,
                'status': status,
                'category': category,
                'is_release_based': is_priority_release,
                'expected_max': rules['fresh']
            }
        except:
            results['missing'].append(indicator)
            results['details'][indicator] = {
                'last_date': None,
                'days_old': None,
                'status': 'missing',
                'category': 'unknown',
                'expected_max': None
            }
    
    # Calculate summary
    total = len(results['fresh']) + len(results['stale']) + len(results['critical']) + len(results['missing'])
    results['summary'] = {
        'total': total,
        'fresh_count': len(results['fresh']),
        'stale_count': len(results['stale']),
        'critical_count': len(results['critical']),
        'missing_count': len(results['missing']),
        'health_score': round(len(results['fresh']) / max(total, 1) * 100, 1)
    }
    
    return results

@st.cache_data(ttl=3600, show_spinner=False)  # Cache for 1 hour
def get_fred_release_dates(fred_ids: list) -> dict:
    """
    Fetch actual release dates (last_updated) from FRED API for each series.
    This shows when the data source actually published the data.
    """
    release_dates = {}
    
    for series_id in fred_ids:
        try:
            url = f"https://api.stlouisfed.org/fred/series?series_id={series_id}&api_key={FRED_API_KEY}&file_type=json"
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                data = response.json()
                if 'seriess' in data and len(data['seriess']) > 0:
                    series_info = data['seriess'][0]
                    # Parse last_updated: "2025-12-29 16:06:49-06"
                    last_updated_str = series_info.get('last_updated', '')
                    if last_updated_str:
                        # Extract just the date part
                        date_part = last_updated_str.split(' ')[0]
                        release_dates[series_id] = {
                            'last_updated': date_part,
                            'title': series_info.get('title', ''),
                            'frequency': series_info.get('frequency', ''),
                            'observation_end': series_info.get('observation_end', '')
                        }
        except:
            pass  # Skip on error
    
    return release_dates

# ========== MONITORED AGENCIES ==========
MONITORED_AGENCIES = {
    "FRB": {"domain": "federalreserve.gov", "rss": "https://www.federalreserve.gov/feeds/press_all.xml", "label": "ğŸ¦ Federal Reserve"},
    "SEC": {"domain": "sec.gov", "rss": None, "label": "ğŸ“Š SEC"},  # SEC doesn't have easy RSS
    "Treasury": {"domain": "treasury.gov", "rss": "https://home.treasury.gov/news/press-releases/rss.xml", "label": "ğŸ’µ Treasury"},
    "CFTC": {"domain": "cftc.gov", "rss": None, "label": "ğŸ“ˆ CFTC"},
    "FDIC": {"domain": "fdic.gov", "rss": None, "label": "ğŸ›ï¸ FDIC"},
    "BIS": {"domain": "bis.org", "rss": "https://www.bis.org/doclist/bis_fsi_publs.rss", "label": "ğŸŒ BIS"},
    "IMF": {"domain": "imf.org", "rss": None, "label": "ğŸŒ IMF"},
    "FSB": {"domain": "fsb.org", "rss": None, "label": "ğŸ”’ FSB"},
}

def check_for_market_alerts():
    """
    Check major financial regulators' RSS feeds for recent updates.
    Returns a list of alerts from the last 24 hours.
    """
    alerts = []
    
    # RSS feeds to check
    rss_sources = {
        "FRB": "https://www.federalreserve.gov/feeds/press_all.xml",
        "Treasury": "https://home.treasury.gov/news/press-releases/rss.xml",
        "BIS": "https://www.bis.org/doclist/bis_fsi_publs.rss",
    }
    
    for source, url in rss_sources.items():
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:3]:  # Check latest 3 entries per source
                pub_date = entry.get('published', '') or entry.get('updated', '')
                title = entry.get('title', 'No title')
                link = entry.get('link', '')
                
                # Check if within 24 hours (simplified check)
                if pub_date:
                    try:
                        from dateutil import parser as date_parser
                        entry_date = date_parser.parse(pub_date)
                        now = datetime.datetime.now(datetime.timezone.utc)
                        if entry_date.tzinfo is None:
                            entry_date = entry_date.replace(tzinfo=datetime.timezone.utc)
                        hours_ago = (now - entry_date).total_seconds() / 3600
                        
                        if hours_ago <= 24:
                            alerts.append({
                                'source': source,
                                'title': title[:80] + ('...' if len(title) > 80 else ''),
                                'link': link,
                                'hours_ago': int(hours_ago),
                                'published': pub_date
                            })
                    except:
                        pass  # Skip if date parsing fails
        except Exception as e:
            pass  # Skip on RSS fetch error
    
    # Sort by hours_ago (most recent first)
    alerts.sort(key=lambda x: x.get('hours_ago', 999))
    
    return alerts[:5]  # Return top 5 most recent


def search_google_news(query, num_results=3, gl='US', mode='general'):
    """Search Google News RSS and return headlines, dates, and URLs for verification
    
    Args:
        mode: 'general' (all news) or 'primary' (government/org reports only)
    """
    try:
        import urllib.request
        # Map region to hl (language)
        hl = 'ja' if gl == 'JP' else 'en-US'
        ceid = 'JP:ja' if gl == 'JP' else 'US:en'
        
        # Enhanced query based on mode
        enhanced_query = query
        if mode == 'primary':
            # Target official domains and report/paper keywords
            # Expanded to include key US regulators: SEC, Treasury, CFTC, FDIC, OCC
            official_domains = (
                "site:sec.gov OR "           # Securities and Exchange Commission
                "site:treasury.gov OR "      # US Treasury
                "site:cftc.gov OR "          # Commodity Futures Trading Commission
                "site:fdic.gov OR "          # Federal Deposit Insurance Corporation
                "site:occ.gov OR "           # Office of the Comptroller of the Currency
                "site:federalreserve.gov OR " # Federal Reserve
                "site:.gov OR "              # Other US government
                "site:.org OR site:.int OR " # International orgs
                "site:bis.org OR "           # Bank for International Settlements
                "site:imf.org OR "           # International Monetary Fund
                "site:fsb.org OR "           # Financial Stability Board
                "site:ecb.europa.eu OR "     # European Central Bank
                "site:bankofengland.co.uk OR " # Bank of England
                "site:isda.org"              # ISDA
            )
            report_keywords = 'filetype:pdf OR "staff report" OR "working paper" OR "bulletin" OR "statement" OR "policy note" OR "press release" OR "enforcement action" OR "proposed rule"'
            enhanced_query = f"({query}) ({official_domains}) ({report_keywords})"
        else:
            # Fallback for general mode if some specific primary keywords are detected
            if any(src in query.lower() for src in ['fed', 'frb', 'ecb', 'bis', 'imf', 'sec', 'treasury', 'cftc']):
                enhanced_query = f"{query} site:.gov OR site:.org OR site:.int"
            
        search_url = f"https://news.google.com/rss/search?q={enhanced_query.replace(' ', '+')}&hl={hl}&gl={gl}&ceid={ceid}"
        req = urllib.request.Request(search_url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req, timeout=10) as response:
            feed_content = response.read()
        feed = feedparser.parse(feed_content)
        
        results = []
        for entry in feed.entries[:num_results]:
            title = entry.get('title', '')
            pub_date = entry.get('published', '')[:20] if entry.get('published') else ''
            link = entry.get('link', '')
            source = entry.get('source', {}).get('title', 'Unknown Source')
            results.append(f"- [{gl}] [{pub_date}] Source: {source} | {title}\n  Link: {link}")
        
        return "\n".join(results) if results else "è©²å½“ã™ã‚‹ä¸€æ¬¡æƒ…å ±è³‡æ–™ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
    except Exception as e:
        return f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}"

def get_time_diff_str(date_str):
    """
    Calculate time difference from now and return a human-readable string.
    Supports various RSS date formats.
    """
    try:
        from dateutil import parser
        from datetime import timezone
        
        now = datetime.datetime.now(timezone.utc)
        target_date = parser.parse(date_str)
        
        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ãŒãªã„å ´åˆã¯çµŒéæ™‚é–“è¨ˆç®—ã‚’è«¦ã‚ã€å…ƒã®æ—¥ä»˜ã‚’è¡¨ç¤º
        if target_date.tzinfo is None:
            # å…ƒã®æ—¥ä»˜æ–‡å­—åˆ—ã‹ã‚‰æ—¥æ™‚éƒ¨åˆ†ã ã‘æŠ½å‡ºã—ã¦è¡¨ç¤º
            return f"âš ï¸ {date_str[:16]}"
            
        diff = now - target_date
        seconds = diff.total_seconds()
        
        # æœªæ¥ã®æ—¥ä»˜ã®å ´åˆï¼ˆã‚µãƒ¼ãƒãƒ¼æ™‚åˆ»ã®ã‚ºãƒ¬ç­‰ï¼‰
        if seconds < 0:
            return "âš ï¸ æ™‚åˆ»ä¸æ˜"
        
        if seconds < 60:
            return "ãŸã£ãŸä»Š"
        elif seconds < 3600:
            return f"{int(seconds // 60)}åˆ†å‰"
        elif seconds < 86400:
            return f"{int(seconds // 3600)}æ™‚é–“å‰"
        elif seconds < 604800:
            return f"{int(seconds // 86400)}æ—¥å‰"
        else:
            return target_date.strftime('%Y/%m/%d')
    except:
        return f"âš ï¸ {date_str[:16] if len(date_str) > 16 else date_str}"


# ========== MANUAL DATA PERSISTENCE ==========
def load_manual_data():
    """Load manual H.4.1 data from CSV file (SOMA_Bills only)"""
    try:
        if os.path.exists(MANUAL_DATA_FILE):
            df_manual = pd.read_csv(MANUAL_DATA_FILE, index_col=0, parse_dates=True)
            # Ensure only SOMA_Bills column exists (migration from old format)
            if 'SOMA_Bills' in df_manual.columns:
                return df_manual[['SOMA_Bills']]
            return df_manual
    except:
        pass
    return pd.DataFrame(columns=['SOMA_Bills'])

def save_manual_data(date, soma_bills):
    """Save manual H.4.1 data to CSV file (SOMA_Bills only)"""
    df_manual = load_manual_data()
    df_manual.loc[date] = [soma_bills]
    df_manual = df_manual.sort_index()
    df_manual.to_csv(MANUAL_DATA_FILE)

def fetch_h41_data():
    """
    Fetch latest H.4.1 data from FRB website
    Returns: (report_date, soma_bills, total_loans, error_msg)
    """
    url = "https://www.federalreserve.gov/releases/h41/current/"
    
    try:
        response = requests.get(url, timeout=15)
        if response.status_code != 200:
            return None, None, None, f"HTTP {response.status_code}"
        
        # Parse tables
        tables = pd.read_html(StringIO(response.text))
        
        # Extract report date (improved pattern)
        report_date = None
        date_patterns = [
            r'Week ended[^>]*>(\w+\s+\d+,\s+\d{4})',  # After "Week ended" tag
            r'(\w+ \d+, \d{4})',  # Any date-like pattern
        ]
        for pattern in date_patterns:
            date_match = re.search(pattern, response.text, re.IGNORECASE)
            if date_match:
                try:
                    report_date = pd.to_datetime(date_match.group(1))
                    break
                except:
                    pass
        
        # If no date found, use today
        if not report_date:
            report_date = pd.Timestamp.now()
        
        # Table 1: Look for "Bills" (NOT "U.S. Treasury securities")
        table1 = tables[1] if len(tables) > 1 else None
        soma_bills = None
        
        if table1 is not None:
            last_col_idx = table1.shape[1] - 1
            for idx, row in table1.iterrows():
                row_text = str(row.iloc[0]).strip().lower()
                # Look for "Bills" specifically, not "Notes" or "Bonds"
                if row_text == 'bills' or (row_text.startswith('bills') and 'note' not in row_text and 'bond' not in row_text):
                    try:
                        soma_bills = float(row.iloc[last_col_idx]) / 1000  # Millions to Billions
                        break
                    except:
                        pass
        
        # Find Total Loans
        total_loans = None
        if table1 is not None:
            for idx, row in table1.iterrows():
                row_text = str(row.iloc[0]).strip().lower()
                if row_text == 'loans':
                    try:
                        val = row.iloc[last_col_idx]
                        if pd.notna(val) and isinstance(val, (int, float)):
                            total_loans = float(val) / 1000
                            break
                    except:
                        pass
        
        # Success if we got at least one value
        if soma_bills or total_loans:
            return report_date, soma_bills, total_loans, None
        else:
            return None, None, None, "No data extracted from tables"
        
    except Exception as e:
        return None, None, None, str(e)

# FREDæŒ‡æ¨™
FRED_INDICATORS = {
    # Plumbing
    'ON_RRP': 'RRPONTSYD',
    'Reserves': 'WRESBAL',
    'TGA': 'WTREGEN',
    'Fed_Assets': 'WALCL',
    'SOMA_Total': 'WALCL',
    'SOMA_Bills': 'TREAST',  # Treasury Securities Held by Fed (includes Bills)
    'EFFR': 'EFFR',
    'IORB': 'IORB',
    
    # Banking Sector
    'Bank_Cash': 'CASACBW027SBOG',
    'Lending_Standards': 'DRTSCILM',
    
    # SLOOS - C&I Lending (å•†å·¥æ¥­èè³‡) - Corrected IDs
    'CI_Std_Large': 'DRTSCILM',       # C&I Standards (Large/Medium) - same as Lending_Standards
    'CI_Std_Small': 'DRTSCIS',        # C&I Standards (Small Firms) - CORRECTED
    'CI_Demand': 'DRTSCLCC',          # C&I Demand (Large/Medium) - CORRECTED
    'CI_Loans': 'BUSLOANS',           # C&I Loan Balance (Monthly)
    
    # SLOOS - CRE Lending (å•†æ¥­ç”¨ä¸å‹•ç”£èè³‡) - Corrected IDs
    'CRE_Std_Construction': 'SUBLPDRCSC',  # Construction & Land Development (works)
    'CRE_Std_Office': 'DRTSSP',            # CRE Standards All Property Types - CORRECTED
    'CRE_Std_Multifamily': 'DRTSSP',       # Using same general CRE standard
    'CRE_Demand': 'DRTSCLCC',              # Using C&I demand as proxy (CRE demand n/a)
    'CRE_Loans': 'CREACBW027SBOG',         # CRE Loan Balance (Weekly)
    
    # Market Plumbing
    'SRF': 'WORAL',
    'FIMA': 'H41RESPPALGTRFNWW',
    'SOFR': 'SOFR',
    'Primary_Credit': 'WLCFLPCL',  # Weekly Discount Window Primary Credit
    'Total_Loans': 'WLCFLL',  # Weekly Total Loans (H.4.1)
    
    # Rates & Bonds
    'Credit_Spread': 'BAMLH0A0HYM2',
    'US_TNX': 'DGS10',
    
    # Macro
    'Unemployment': 'UNRATE',
    'CPI': 'CPIAUCSL',
    'M2SL': 'M2SL',
    'M2REAL': 'M2REAL',  # Real M2 Money Stock (1982-84 base)
    
    # Global M2 (Nominal)
    'CN_M2': 'MYAGM2CNM189N',       # China M2
    'JP_M2': 'MANMM101JPM189S',     # Japan M2
    'EU_M2': 'MABMM301EZM189S',     # Euro Area M2
    
    # Global CPI (for Real M2 calculation)
    'CN_CPI': 'CHNCPIALLMINMEI',
    'JP_CPI': 'JPNCPIALLMINMEI',
    'EU_CPI': 'CP0000EZ19M086NEST',
    
    # China Credit Impulse Data (BIS via FRED)
    'CN_Credit_Stock': 'CRDQCNAPABIS',  # Total credit to private non-financial sector, China (Quarterly, Billions CNY)
    'CN_GDP': 'MKTGDPCNA646NWDB',       # China GDP (Annual, Current USD)
    
    # Economic Indicators
    'T10Y2Y': 'T10Y2Y',             # 2Y-10Y Spread (Yield Curve)
    'ICSA': 'ICSA',                 # Initial Jobless Claims
    
    # Additional Economic Data (User Request)
    'UNRATE': 'UNRATE',             # Unemployment Rate (Sahm Rule)
    'CorePCE': 'PCETRIM12M159SFRBDAL',  # Core PCE YoY % (Trimmed Mean)
    'ConsumerSent': 'UMCSENT',      # Consumer Sentiment (ISM unavailable on FRED)
    
    # ===== NEW: US Economic Data (2026-01 Addition) =====
    # Monetary Policy
    'FedFundsUpper': 'DFEDTARU',    # Federal Funds Target Rate (Upper Bound)
    'FedFundsLower': 'DFEDTAR',     # Federal Funds Target Rate (Lower Bound)
    
    # Employment
    'NFP': 'PAYEMS',                # Non-Farm Payrolls (Thousands of Persons)
    'ADP': 'ADPWNUSNERSA',          # ADP Employment (Persons - NOT Thousands! Divide by 1000 for K)
    'AvgHourlyEarnings': 'CES0500000003',  # Average Hourly Earnings (Dollars per Hour)
    'JOLTS': 'JTSJOL',              # JOLTS Job Openings (Thousands)
    
    # Inflation
    'CPI': 'CPIAUCSL',              # CPI All Items (Index, Seasonally Adjusted)
    'CPICore': 'CPILFESL',          # CPI Core (Excluding Food & Energy)
    'PPI': 'PPIACO',                # PPI All Commodities (Index)
    
    # Economy
    'RetailSales': 'RSAFS',         # Retail Sales (Millions)
    'RealGDP': 'GDPC1',             # Real GDP (Billions, Chained 2017 Dollars)
}

# Yahoo Finance
YAHOO_INDICATORS = {
    'SP500': '^GSPC',
    'VIX': '^VIX',
    'HYG': 'HYG',
    
    # FX
    'DXY': 'DX-Y.NYB',              # Dollar Index
    'USDJPY': 'JPY=X',              # USD/JPY
    'EURUSD': 'EURUSD=X',           # EUR/USD
    'USDCNY': 'CNY=X',              # USD/CNY
    
    # Commodities
    'Gold': 'GC=F',                 # Gold Futures
    'Silver': 'SI=F',               # Silver Futures
    'Oil': 'CL=F',                  # WTI Crude Oil
    'Copper': 'HG=F',               # Copper Futures
    
    # Crypto
    'BTC': 'BTC-USD',               # Bitcoin
    'ETH': 'ETH-USD',               # Ethereum
}

# ========== DATA INTEGRITY SAFEGUARDS ==========
# FRED UNITS: Official unit documentation for each series
# This prevents unit confusion errors (like the ADP Persons vs Thousands issue)
FRED_UNITS = {
    # Liquidity (FRB H.4.1) - All in Millions, converted to Billions by /1000
    'ON_RRP': {'unit': 'Millions', 'convert_to': 'Billions', 'divisor': 1000},
    'Reserves': {'unit': 'Millions', 'convert_to': 'Billions', 'divisor': 1000},
    'TGA': {'unit': 'Millions', 'convert_to': 'Billions', 'divisor': 1000},
    'Fed_Assets': {'unit': 'Millions', 'convert_to': 'Billions', 'divisor': 1000},
    'SOMA_Total': {'unit': 'Millions', 'convert_to': 'Billions', 'divisor': 1000},
    'SOMA_Bills': {'unit': 'Millions', 'convert_to': 'Billions', 'divisor': 1000},

    # Rates - Already in Percent
    'EFFR': {'unit': 'Percent', 'convert_to': None, 'divisor': 1},
    'IORB': {'unit': 'Percent', 'convert_to': None, 'divisor': 1},
    'SOFR': {'unit': 'Percent', 'convert_to': None, 'divisor': 1},
    'FedFundsUpper': {'unit': 'Percent', 'convert_to': None, 'divisor': 1},
    'FedFundsLower': {'unit': 'Percent', 'convert_to': None, 'divisor': 1},
    'Credit_Spread': {'unit': 'Percent', 'convert_to': None, 'divisor': 1},
    'US_TNX': {'unit': 'Percent', 'convert_to': None, 'divisor': 1},
    'T10Y2Y': {'unit': 'Percent', 'convert_to': None, 'divisor': 1},
    'UNRATE': {'unit': 'Percent', 'convert_to': None, 'divisor': 1},
    'CorePCE': {'unit': 'Percent (YoY)', 'convert_to': None, 'divisor': 1},

    # Employment - CRITICAL: Different units!
    'NFP': {'unit': 'Thousands of Persons', 'convert_to': None, 'divisor': 1},  # Direct use
    'ADP': {'unit': 'Persons', 'convert_to': 'Thousands', 'divisor': 1000},  # MUST divide by 1000!
    'JOLTS': {'unit': 'Thousands', 'convert_to': None, 'divisor': 1},
    'ICSA': {'unit': 'Persons', 'convert_to': 'Thousands', 'divisor': 1000},
    'AvgHourlyEarnings': {'unit': 'Dollars per Hour', 'convert_to': None, 'divisor': 1},

    # Prices - Index values (base year varies)
    'CPI': {'unit': 'Index (1982-84=100)', 'convert_to': None, 'divisor': 1},
    'CPICore': {'unit': 'Index (1982-84=100)', 'convert_to': None, 'divisor': 1},
    'PPI': {'unit': 'Index (1982=100)', 'convert_to': None, 'divisor': 1},

    # Money Supply - Various units
    'M2SL': {'unit': 'Billions', 'convert_to': 'Trillions', 'divisor': 1000},
    'M2REAL': {'unit': 'Billions', 'convert_to': 'Trillions', 'divisor': 1000},

    # GDP
    'RealGDP': {'unit': 'Billions of Chained 2017 Dollars', 'convert_to': None, 'divisor': 1},
    'RetailSales': {'unit': 'Millions', 'convert_to': None, 'divisor': 1},

    # Banking/Lending
    'Bank_Cash': {'unit': 'Millions', 'convert_to': 'Billions', 'divisor': 1000},
    'CI_Loans': {'unit': 'Billions', 'convert_to': None, 'divisor': 1},
    'CRE_Loans': {'unit': 'Billions', 'convert_to': None, 'divisor': 1},
    'Lending_Standards': {'unit': 'Net Percent', 'convert_to': None, 'divisor': 1},
}

# VALIDATION RANGES: Sanity check ranges for each indicator
# If value falls outside this range, it indicates a data/unit error
VALIDATION_RANGES = {
    # Rates (should be 0-15% typically)
    'EFFR': (0, 15),
    'IORB': (0, 15),
    'SOFR': (0, 15),
    'FedFundsUpper': (0, 15),
    'UNRATE': (0, 25),  # Unemployment rate
    'CorePCE': (-5, 15),  # YoY inflation
    'Credit_Spread': (0, 30),
    'US_TNX': (0, 20),
    'T10Y2Y': (-5, 5),

    # Employment (in Thousands) - reasonable monthly changes
    'NFP': (100000, 200000),  # Total NFP level (100M-200M)
    'ADP': (100000, 200000),  # After /1000 conversion (same range as NFP)
    'JOLTS': (3000, 15000),  # Job openings
    'ICSA': (100, 1000),  # Weekly initial claims in thousands

    # Prices (Index values)
    'CPI': (200, 400),  # CPI index around 310 in 2025
    'CPICore': (200, 400),
    'PPI': (100, 350),
    'AvgHourlyEarnings': (20, 60),  # Dollars per hour

    # Liquidity (in Billions after conversion)
    'ON_RRP': (0, 3000),
    'Reserves': (0, 5000),
    'TGA': (0, 2000),
    'Fed_Assets': (4000, 12000),
    'SOMA_Total': (4000, 12000),
    'Net_Liquidity': (2000, 8000),

    # Markets
    'VIX': (5, 100),
    'SP500': (2000, 8000),
    'DXY': (70, 130),
    'USDJPY': (80, 200),
    'Gold': (1000, 4000),
    'BTC': (10000, 500000),
}

def get_freshness_badge(last_updated_str: str) -> str:
    """
    Return a badge based on how recently the data was updated.
    ğŸ†• = Updated within 24 hours
    âœ… = Updated within 7 days
    â³ = Updated within 30 days
    âš ï¸ = Not updated in 30+ days
    """
    if not last_updated_str:
        return ""
    
    try:
        from datetime import datetime, timedelta
        last_updated = datetime.strptime(last_updated_str, '%Y-%m-%d')
        now = datetime.now()
        days_ago = (now - last_updated).days
        
        if days_ago <= 1:
            return "ğŸ†•"  # Very fresh (today/yesterday)
        elif days_ago <= 7:
            return "âœ…"  # Fresh (within a week)
        elif days_ago <= 30:
            return "â³"  # Getting stale
        else:
            return "âš ï¸"  # Stale
    except:
        return ""

def validate_data_ranges(df, show_warnings=True) -> dict:
    """
    Validate that data values fall within expected ranges.
    Returns dict of any validation issues found.
    """
    issues = {}
    
    for indicator, (min_val, max_val) in VALIDATION_RANGES.items():
        if indicator in df.columns:
            series = df[indicator].dropna()
            if len(series) > 0:
                latest = series.iloc[-1]
                if latest < min_val or latest > max_val:
                    issues[indicator] = {
                        'value': latest,
                        'expected_range': (min_val, max_val),
                        'status': 'OUT_OF_RANGE'
                    }
    
    return issues

# èª¬æ˜æ–‡
EXPLANATIONS = {
    "Net_Liquidity": "ã€ãƒãƒƒãƒˆãƒªã‚¯ã‚¤ãƒ‡ã‚£ãƒ†ã‚£ã€‘\nå¸‚å ´ã«å‡ºå›ã‚‹ã€ŒçœŸã®è³‡é‡‘é‡ã€ã€‚(FRBç·è³‡ç”£ - TGA - RRP) ã§è¨ˆç®—ã•ã‚Œã¾ã™ã€‚",
    "Reserves": "ã€éŠ€è¡Œæº–å‚™é é‡‘ã€‘\næ°‘é–“éŠ€è¡ŒãŒFRBã«é ã‘ã¦ã„ã‚‹ãŠé‡‘ã€‚ã“ã‚ŒãŒæ¸›ã‚Šã™ãã‚‹ã¨ã‚·ãƒ§ãƒƒã‚¯ãŒèµ·ãã‚„ã™ããªã‚Šã¾ã™ã€‚",
    "TGA": "ã€TGA (è²¡å‹™çœä¸€èˆ¬å£åº§)ã€‘\næ”¿åºœã®éŠ€è¡Œå£åº§ã€‚ã“ã“ãŒå¢—ãˆã‚‹ã¨å¸‚å ´ã‹ã‚‰è³‡é‡‘ãŒå¸ã„ä¸Šã’ã‚‰ã‚Œã¾ã™ã€‚",
    "ON_RRP": "ã€ON RRPã€‘\nMMFãªã©ãŒFRBã«ãŠé‡‘ã‚’é ã‘ã‚‹å ´æ‰€ã€‚ä½™å‰°è³‡é‡‘ã®æ»ç•™ã‚’ç¤ºã—ã¾ã™ã€‚",
    "VIX": "ã€VIXæŒ‡æ•°ã€‘\nææ€–æŒ‡æ•°ã€‚20ä»¥ä¸Šã§å¸‚å ´ã®ä¸å®‰ãŒé«˜ã¾ã£ã¦ã„ã‚‹çŠ¶æ…‹ã§ã™ã€‚",
    "Bank_Cash": "ã€éŠ€è¡Œã®ç¾é‡‘ä¿æœ‰ã€‘\nå…¨ç±³ã®éŠ€è¡ŒãŒä¿æœ‰ã™ã‚‹ç¾é‡‘è³‡ç”£ã®æ¨ç§»ã€‚éŠ€è¡ŒãŒä¸å®‰ã‚’æ„Ÿã˜ã¦ç¾é‡‘ã‚’æŠ±ãˆè¾¼ã¿å§‹ã‚ã‚‹ã¨å¸‚å ´ã®æµå‹•æ€§ãŒä½ä¸‹ã—ã¾ã™ã€‚",
    "Lending_Standards": "ã€C&I Lending Tightening / å•†å·¥æ¥­èè³‡åŸºæº–ã®å³æ ¼åŒ–ã€‘\néŠ€è¡Œã®èè³‡æ…‹åº¦ã‚’ç¤ºã™ç´”å‰²åˆï¼ˆNet %ï¼‰ã€‚0ãŒä¸­ç«‹ã€+ã¯å¼•ãç· ã‚ï¼ˆèè³‡åŸºæº–ã‚’å³ã—ãã™ã‚‹éŠ€è¡ŒãŒå¤šã„ï¼‰ã€âˆ’ã¯ç·©å’Œã€‚æ•°å€¤ä¸Šæ˜‡ã¯ä¿¡ç”¨åç¸®ã‚’ç¤ºã—ã€æ™¯æ°—å¾Œé€€ã®å…ˆè¡ŒæŒ‡æ¨™ã¨ã—ã¦é‡è¦ã€‚",
    "M2_Nominal": "ã€é€šè²¨ä¾›çµ¦é‡ M2ï¼ˆåç›®ï¼‰ã€‘\nä¸–ã®ä¸­ã«æµé€šã—ã¦ã„ãƒãƒãƒ¼ã®ç·é‡ã€‚",
    "M2_Real": "ã€é€šè²¨ä¾›çµ¦é‡ M2ï¼ˆå®Ÿè³ªï¼‰ã€‘\nã‚¤ãƒ³ãƒ•ãƒ¬èª¿æ•´å¾Œã®å®Ÿè³ªçš„ãªè³¼è²·åŠ›ã€‚",
    "SRF": "ã€Standing Repo Facilityã€‘\nå›½å†…ã®é‡‘èæ©Ÿé–¢ãŒå›½å‚µã‚’æ‹…ä¿ã«ç¾é‡‘ã‚’å€Ÿã‚Šã‚‹å¸¸è¨­çª“å£ã€‚ãƒªãƒå¸‚å ´ã®ç›®è©°ã¾ã‚Šã‚’æ¤œçŸ¥ã—ã¾ã™ã€‚",
    "FIMA": "ã€FIMA Repo Facilityã€‘\næµ·å¤–ã®ä¸­å¤®éŠ€è¡Œå‘ã‘èè³‡ã€‚ä¸–ç•Œçš„ãªãƒ‰ãƒ«ä¸è¶³ãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã‹ã‚’æ¸¬ã‚‹æŒ‡æ¨™ã§ã™ã€‚",
    "SOFR": "ã€SOFRã€‘\nå›½å‚µã‚’æ‹…ä¿ã«ã—ãŸè³‡é‡‘èª¿é”ã‚³ã‚¹ãƒˆã€‚æ€¥é¨°ã¯ç¾é‡‘ä¸è¶³ã‚’ç¤ºã—ã¾ã™ã€‚",
    "Primary": "ã€Primary Creditã€‘\nå¥å…¨ãªéŠ€è¡Œå‘ã‘ã®ç·Šæ€¥èè³‡ã€‚æ€¥å¢—æ™‚ã¯éŠ€è¡ŒãŒå¸‚å ´ã§ç¾é‡‘ã‚’èª¿é”ã§ããªããªã£ã¦ã„ã‚‹å±é™ºä¿¡å·ã§ã™ã€‚",
    "Window": "ã€Total Loansã€‘\nFRBã«ã‚ˆã‚‹é‡‘èæ©Ÿé–¢ã¸ã®è²¸å‡ºç·é¡ã€‚å¸‚å ´ã®ç·Šæ€¥äº‹æ…‹ã‚’æ¸¬ã‚‹ç·åˆæŒ‡æ¨™ã§ã™ã€‚",
    "SOMA_Total": "ã€SOMAç·è³‡ç”£ã€‘\nFRBãŒä¿æœ‰ã™ã‚‹å›½å‚µã‚„MBSã®ç·é¡ã€‚ã“ã‚ŒãŒå¢—ãˆã‚‹=QEã€æ¸›ã‚‹=QTã§ã™ã€‚",
    "SOMA_Bills": "ã€SOMA Bills (çŸ­æœŸå›½å‚µ)ã€‘\nFRBãŒä¿æœ‰ã™ã‚‹çŸ­æœŸå›½å‚µï¼ˆT-Billsï¼‰ã€‚2025å¹´12æœˆ12æ—¥ã‹ã‚‰RMPï¼ˆReserve Management Purchasesï¼‰ã¨ã—ã¦æœˆé¡400å„„ãƒ‰ãƒ«ãƒšãƒ¼ã‚¹ã§è²·ã„å…¥ã‚Œä¸­ã€‚QTçµ‚äº†å¾Œã®æº–å‚™é‡‘ç¶­æŒãŒç›®çš„ã ãŒã€å®Ÿè³ªçš„ãªè³‡é‡‘ä¾›çµ¦ã¨ãªã‚‹ã€‚",
    "SomaBillsRatio": "ã€SOMA Billsæ¯”ç‡ã€‘\nFRBã®ç·è³‡ç”£ã«å ã‚ã‚‹çŸ­æœŸå›½å‚µã®å‰²åˆã€‚RMPå®Ÿè¡Œã«ã‚ˆã‚Šä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ã¨ãªã‚‹ã€‚FRBã¯ã€ŒæŠ€è¡“çš„æªç½®ã€ã¨ä¸»å¼µã™ã‚‹ãŒã€å¸‚å ´ã¸ã®æµå‹•æ€§ä¾›çµ¦åŠ¹æœã¯QEã«é¡ä¼¼ã€‚",
    "M2SL": "ã€é€šè²¨ä¾›çµ¦é‡ M2ã€‘\nä¸–ã®ä¸­ã«æµé€šã—ã¦ã„ã‚‹ãƒãƒãƒ¼(ç¾é‡‘ãƒ»é é‡‘ç­‰)ã®ç·é‡ã€‚",
    "RMP": "ã€RMP (Reserve Management Purchases)ã€‘\n2025å¹´12æœˆ12æ—¥é–‹å§‹ã€‚QTçµ‚äº†å¾Œã€éŠ€è¡Œæº–å‚™é‡‘ã‚’ã€Œæ½¤æ²¢ï¼ˆampleï¼‰ã€ãƒ¬ãƒ™ãƒ«ã«ç¶­æŒã™ã‚‹ãŸã‚ã€æœˆé¡400å„„ãƒ‰ãƒ«è¦æ¨¡ã§çŸ­æœŸå›½å‚µã‚’è²·ã„å…¥ã‚Œã‚‹æ”¿ç­–ã€‚FRBã¯æ™¯æ°—åˆºæ¿€ç­–ï¼ˆQEï¼‰ã§ã¯ãªã„ã¨å¼·èª¿ã™ã‚‹ãŒã€å¸‚å ´ã¸ã®è³‡é‡‘ä¾›çµ¦åŠ¹æœã¯å®Ÿè³ªçš„ã«QEã¨åŒç­‰ã¨ã®æŒ‡æ‘˜ã‚‚ã‚ã‚‹ã€‚",
    
    # SLOOS - C&I Lending
    "CI_Std_Large": "ã€C&Ièè³‡åŸºæº–ï¼ˆå¤§ãƒ»ä¸­å …ä¼æ¥­ï¼‰ã€‘\n0ã‚’è¶…ãˆã‚‹ã¨è²¸ã—æ¸‹ã‚Šã€‚40%è¶…ã§å¼·åŠ›ãªãƒªã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚°ãƒŠãƒ«ã€‚ãƒªã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å…ˆè¡ŒæŒ‡æ¨™ï¼ˆ20%è¶…ã§è­¦æˆ’ï¼‰ã€‚",
    "CI_Std_Small": "ã€C&Ièè³‡åŸºæº–ï¼ˆå°ä¼æ¥­ï¼‰ã€‘\nä¸­å°ä¼æ¥­ã®è³‡é‡‘ç¹°ã‚Šã¨é›‡ç”¨ã®å…ˆè¡ŒæŒ‡æ¨™ã€‚å°ä¼æ¥­å‘ã‘ãŒå…ˆã«æ‚ªåŒ–ã™ã‚‹å ´åˆã¯é›‡ç”¨æ‚ªåŒ–ã«æ³¨æ„ã€‚",
    "CI_Demand": "ã€C&Ièè³‡éœ€è¦ï¼ˆå¤§ãƒ»ä¸­å …ä¼æ¥­ï¼‰ã€‘\nä¼æ¥­ã®è¨­å‚™æŠ•è³‡æ„æ¬²ã‚’æ¸¬å®šã€‚åŸºæº–ãŒç·©ã‚“ã§ã‚‚éœ€è¦ãŒä½ã„å ´åˆã¯ä¼æ¥­ãŒå°†æ¥ã‚’æ‚²è¦³ã€‚åŸºæº–ã¨éœ€è¦ã®ã€Œä¹–é›¢ã€ãŒæœ€å¤§ã®æ³¨ç›®ç‚¹ã€‚",
    "CI_Loans": "ã€C&Ièè³‡æ®‹é«˜ã€‘\nå•†å·¥æ¥­å‘ã‘èè³‡ã®ç·é¡ã€‚èè³‡åŸºæº–å³æ ¼åŒ–å¾Œã«ã“ã®æ®‹é«˜ãŒæ¸›å°‘ã™ã‚‹ã¨ã€Œã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚¯ãƒ©ãƒ³ãƒï¼ˆä¿¡ç”¨åç¸®ï¼‰ã€é–‹å§‹ã®ã‚µã‚¤ãƒ³ã€‚",
    
    # SLOOS - CRE Lending
    "CRE_Std_Construction": "ã€CREèè³‡åŸºæº–ï¼ˆå»ºè¨­ãƒ»åœŸåœ°é–‹ç™ºï¼‰ã€‘\nä¸å‹•ç”£é–‹ç™ºã®è›‡å£ã€‚ã“ã“ãŒé–‰ã¾ã‚‹ã¨æ•°å¹´å¾Œã®æ–°è¦ä¾›çµ¦ã¨å»ºè¨­æŠ•è³‡ãŒæ­¢ã¾ã‚‹ã€‚",
    "CRE_Std_Office": "ã€CREèè³‡åŸºæº–ï¼ˆã‚ªãƒ•ã‚£ã‚¹ç­‰ï¼‰ã€‘\næ—¢å­˜ç‰©ä»¶ã®å€Ÿã‚Šæ›ãˆé›£æ˜“åº¦ã‚’ç¤ºã™ã€‚å³æ ¼åŒ–ã¯ç‰©ä»¶ä¾¡æ ¼æš´è½ã®ãƒˆãƒªã‚¬ãƒ¼ã¨ãªã‚‹ã€‚ã‚ªãƒ•ã‚£ã‚¹ã‚¯ãƒ©ã‚¤ã‚·ã‚¹ãƒ»å€Ÿã‚Šæ›ãˆãƒªã‚¹ã‚¯ã®æ¸¬å®šã€‚",
    "CRE_Std_Multifamily": "ã€CREèè³‡åŸºæº–ï¼ˆé›†åˆä½å®…ï¼‰ã€‘\nå±…ä½ç”¨ä¸å‹•ç”£å¸‚å ´ã®æµå‹•æ€§ã‚’ç¢ºèªã€‚ä½å®…ä¾›çµ¦ã«å½±éŸ¿ã€‚",
    "CRE_Demand": "ã€CREèè³‡éœ€è¦ã€‘\næŠ•è³‡å®¶ãŒä¸å‹•ç”£ã‹ã‚‰è³‡é‡‘ã‚’å¼•ãæšã’ã‚‹å‹•ãã‚’å¯ŸçŸ¥ã™ã‚‹æŒ‡æ¨™ã€‚ä¸å‹•ç”£æŠ•è³‡æ„æ¬²ã®æ¸›é€€ç¢ºèªã€‚",
    "CRE_Loans": "ã€CREèè³‡æ®‹é«˜ï¼ˆé€±æ¬¡ï¼‰ã€‘\né€±æ¬¡ã§è¿½ãˆã‚‹æœ€é€Ÿã®ãƒ‡ãƒ¼ã‚¿ã€‚å››åŠæœŸçµ±è¨ˆã‚’å¾…ãŸãšã«éŠ€è¡Œã®èè³‡å§¿å‹¢ã®å¤‰åŒ–ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å¯ŸçŸ¥ã€‚",
}

# ========== VALUATION & LEVERAGE INDICATORS ==========
@st.cache_data(ttl=3600, show_spinner=False)  # Cache for 1 hour
def get_pe_ratios():
    """
    Fetch S&P 500 and NASDAQ P/E ratios by scraping multpl.com
    Returns: dict with pe_sp500, pe_nasdaq, historical average
    """
    try:
        result = {
            'sp500_pe': None,
            'sp500_pe_avg': 19.5,  # Historical average
            'nasdaq_pe': None,
            'timestamp': datetime.datetime.now().isoformat()
        }
        
        # Fetch S&P 500 P/E from multpl.com
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            url = "https://www.multpl.com/s-p-500-pe-ratio"
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                # Parse the current P/E value
                import re
                match = re.search(r'Current S&P 500 PE Ratio is\s*([\d.]+)', response.text)
                if match:
                    result['sp500_pe'] = float(match.group(1))
        except:
            pass
        
        # Try to get NASDAQ P/E from Yahoo Finance (QQQ as proxy)
        try:
            qqq = yf.Ticker("QQQ")
            info = qqq.info
            result['nasdaq_pe'] = info.get('trailingPE')
        except:
            pass
        
        return result
    except Exception as e:
        return None


@st.cache_data(ttl=300, show_spinner=False)  # Cache for 5 minutes (more dynamic)
def get_crypto_leverage_data():
    """
    Fetch crypto leverage indicators: Funding Rate, Open Interest
    from CoinGlass API (free tier)
    Returns: dict with funding rates and open interest data
    """
    try:
        result = {
            'btc_funding_rate': None,
            'eth_funding_rate': None,
            'btc_open_interest': None,
            'eth_open_interest': None,
            'btc_long_short_ratio': None,
            'timestamp': datetime.datetime.now().isoformat()
        }
        
        headers = {'User-Agent': 'Mozilla/5.0'}
        
        # Try CoinGlass public endpoint for funding rates
        try:
            # BTC Funding Rate (weighted average across exchanges)
            url = "https://open-api.coinglass.com/public/v2/funding"
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if data.get('success') and data.get('data'):
                    for item in data['data']:
                        if item.get('symbol') == 'BTC':
                            result['btc_funding_rate'] = item.get('uMarginRateAvg')
                        elif item.get('symbol') == 'ETH':
                            result['eth_funding_rate'] = item.get('uMarginRateAvg')
        except:
            pass
        
        # Try alternative: Binance Futures API (free, no key needed)
        if result['btc_funding_rate'] is None:
            try:
                url = "https://fapi.binance.com/fapi/v1/fundingRate?symbol=BTCUSDT&limit=1"
                response = requests.get(url, headers=headers, timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    if data and len(data) > 0:
                        result['btc_funding_rate'] = float(data[0].get('fundingRate', 0)) * 100  # Convert to %
            except:
                pass
        
        if result['eth_funding_rate'] is None:
            try:
                url = "https://fapi.binance.com/fapi/v1/fundingRate?symbol=ETHUSDT&limit=1"
                response = requests.get(url, headers=headers, timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    if data and len(data) > 0:
                        result['eth_funding_rate'] = float(data[0].get('fundingRate', 0)) * 100
            except:
                pass
        
        # Current Open Interest from Binance
        try:
            url = "https://fapi.binance.com/fapi/v1/openInterest?symbol=BTCUSDT"
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                result['btc_open_interest'] = float(data.get('openInterest', 0))
        except:
            pass
        
        try:
            url = "https://fapi.binance.com/fapi/v1/openInterest?symbol=ETHUSDT"
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                result['eth_open_interest'] = float(data.get('openInterest', 0))
        except:
            pass
        
        # Historical Open Interest (30 days, 4-hour intervals = 180 data points)
        try:
            url = "https://fapi.binance.com/futures/data/openInterestHist?symbol=BTCUSDT&period=4h&limit=180"
            response = requests.get(url, headers=headers, timeout=15)
            if response.status_code == 200:
                data = response.json()
                if data and len(data) > 0:
                    oi_values = [float(d.get('sumOpenInterest', 0)) for d in data]
                    timestamps = [datetime.datetime.fromtimestamp(d.get('timestamp', 0) / 1000) for d in data]
                    result['btc_oi_history'] = {'values': oi_values, 'timestamps': timestamps}
                    result['btc_oi_avg_30d'] = sum(oi_values) / len(oi_values) if oi_values else None
                    result['btc_oi_ath'] = max(oi_values) if oi_values else None
                    result['btc_oi_atl'] = min(oi_values) if oi_values else None
        except:
            pass
        
        try:
            url = "https://fapi.binance.com/futures/data/openInterestHist?symbol=ETHUSDT&period=4h&limit=180"
            response = requests.get(url, headers=headers, timeout=15)
            if response.status_code == 200:
                data = response.json()
                if data and len(data) > 0:
                    oi_values = [float(d.get('sumOpenInterest', 0)) for d in data]
                    timestamps = [datetime.datetime.fromtimestamp(d.get('timestamp', 0) / 1000) for d in data]
                    result['eth_oi_history'] = {'values': oi_values, 'timestamps': timestamps}
                    result['eth_oi_avg_30d'] = sum(oi_values) / len(oi_values) if oi_values else None
                    result['eth_oi_ath'] = max(oi_values) if oi_values else None
                    result['eth_oi_atl'] = min(oi_values) if oi_values else None
        except:
            pass
        
        # Long/Short Ratio from Binance
        try:
            url = "https://fapi.binance.com/futures/data/globalLongShortAccountRatio?symbol=BTCUSDT&period=1h&limit=1"
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if data and len(data) > 0:
                    result['btc_long_short_ratio'] = float(data[0].get('longShortRatio', 1.0))
        except:
            pass
        
        return result
    except Exception as e:
        return None


# ========== DEFILLAMA API FUNCTIONS (Crypto Liquidity) ==========

@st.cache_data(ttl=3600, show_spinner=False)  # Cache for 1 hour
def get_stablecoin_data():
    """
    Fetch stablecoin supply data from DeFiLlama API.
    Returns: dict with total supply and top stablecoins
    """
    try:
        url = "https://stablecoins.llama.fi/stablecoins?includePrices=true"
        response = requests.get(url, timeout=15)
        if response.status_code != 200:
            return None
        
        data = response.json()
        stablecoins = data.get('peggedAssets', [])
        
        # Top stablecoins by market cap
        top_coins = []
        total_supply = 0
        
        # Store IDs for historical data
        coin_ids = {}
        
        for coin in stablecoins:
            if coin.get('pegType') == 'peggedUSD':
                circulating = coin.get('circulating', {}).get('peggedUSD', 0)
                if circulating and circulating > 1000000:  # > $1M
                    total_supply += circulating
                    coin_data = {
                        'id': coin.get('id', ''),
                        'name': coin.get('name', ''),
                        'symbol': coin.get('symbol', ''),
                        'circulating': circulating / 1e9,  # Convert to billions
                        'mechanism': coin.get('pegMechanism', ''),
                        'price': coin.get('price', 1.0),
                        'prev_day': coin.get('circulatingPrevDay', {}).get('peggedUSD', 0) / 1e9,
                        'prev_week': coin.get('circulatingPrevWeek', {}).get('peggedUSD', 0) / 1e9,
                        'prev_month': coin.get('circulatingPrevMonth', {}).get('peggedUSD', 0) / 1e9,
                    }
                    top_coins.append(coin_data)
                    coin_ids[coin.get('symbol', '')] = coin.get('id', '')
        
        # Sort by market cap
        top_coins.sort(key=lambda x: x['circulating'], reverse=True)
        
        return {
            'total_supply': total_supply / 1e9,  # Billions
            'top_coins': top_coins[:15],  # Top 15
            'coin_ids': coin_ids,
            'timestamp': datetime.datetime.now().isoformat()
        }
    except Exception as e:
        return None

@st.cache_data(ttl=3600, show_spinner=False)  # Cache for 1 hour
def get_stablecoin_historical():
    """
    Fetch historical stablecoin supply data from DeFiLlama API.
    Returns: DataFrame with date index and stablecoin supplies
    """
    try:
        url = "https://stablecoins.llama.fi/stablecoincharts/all?stablecoin=1"
        response = requests.get(url, timeout=15)
        if response.status_code != 200:
            return None
        
        data = response.json()
        
        # Parse historical data - handle different response formats
        records = []
        
        if isinstance(data, list):
            for point in data:
                try:
                    # Date can be string or int - convert to int first
                    date_val = point.get('date', 0)
                    if isinstance(date_val, str):
                        date_val = int(date_val)
                    date = datetime.datetime.fromtimestamp(date_val)
                    
                    # Try different keys for the total
                    total = 0
                    if 'totalCirculating' in point and isinstance(point['totalCirculating'], dict):
                        total = point['totalCirculating'].get('peggedUSD', 0) / 1e9
                    elif 'totalCirculatingUSD' in point and isinstance(point['totalCirculatingUSD'], dict):
                        total = point['totalCirculatingUSD'].get('peggedUSD', 0) / 1e9
                    
                    if total > 0:
                        records.append({'date': date, 'Total': total})
                except:
                    continue
        
        df = pd.DataFrame(records)
        if not df.empty and len(df) > 0:
            df = df.set_index('date')
            df = df.sort_index()
            return df
        
        return None
    except Exception as e:
        return None


@st.cache_data(ttl=3600, show_spinner=False)  # Cache for 1 hour
def get_tokenized_treasury_data():
    """
    Fetch tokenized US Treasury data from DeFiLlama API.
    Separates: Treasuries (å›½å‚µ), Gold (é‡‘), Other RWA
    Returns: dict with categorized RWA protocols
    """
    try:
        # Get protocol list
        url = "https://api.llama.fi/protocols"
        response = requests.get(url, timeout=15)
        if response.status_code != 200:
            return None
        
        protocols = response.json()
        
        # Keywords for categorization
        treasury_keywords = ['treasury', 'tbill', 't-bill', 'buidl', 'usdy', 'usdm', 'usyc', 'ondo', 'openeden', 'hashnote', 'mountain', 'backed']
        gold_keywords = ['gold', 'xaut', 'paxg', 'gld', 'xau']
        
        treasury_data = []
        gold_data = []
        other_rwa_data = []
        
        treasury_tvl = 0
        gold_tvl = 0
        other_rwa_tvl = 0
        
        for protocol in protocols:
            name = protocol.get('name', '').lower()
            slug = protocol.get('slug', '').lower()
            symbol = protocol.get('symbol', '').lower()
            category = protocol.get('category', '').lower()
            
            # Check if it's an RWA protocol
            is_rwa = 'rwa' in category or 'real world' in category
            
            if not is_rwa:
                continue
            
            tvl = protocol.get('tvl', 0)
            if not tvl or tvl < 1000000:  # < $1M
                continue
            
            protocol_info = {
                'name': protocol.get('name', ''),
                'symbol': protocol.get('symbol', '-'),
                'slug': protocol.get('slug', ''),
                'tvl': tvl / 1e9,  # Billions
                'category': protocol.get('category', 'RWA'),
                'change_1d': protocol.get('change_1d', 0),
                'change_7d': protocol.get('change_7d', 0),
            }
            
            # Categorize by type
            is_gold = any(kw in name or kw in symbol or kw in slug for kw in gold_keywords)
            is_treasury = any(kw in name or kw in symbol or kw in slug for kw in treasury_keywords)
            
            if is_gold:
                gold_data.append(protocol_info)
                gold_tvl += tvl
            elif is_treasury:
                treasury_data.append(protocol_info)
                treasury_tvl += tvl
            else:
                other_rwa_data.append(protocol_info)
                other_rwa_tvl += tvl
        
        # Sort each category by TVL
        treasury_data.sort(key=lambda x: x['tvl'], reverse=True)
        gold_data.sort(key=lambda x: x['tvl'], reverse=True)
        other_rwa_data.sort(key=lambda x: x['tvl'], reverse=True)
        
        return {
            'treasury': {
                'total_tvl': treasury_tvl / 1e9,
                'protocols': treasury_data[:10],
            },
            'gold': {
                'total_tvl': gold_tvl / 1e9,
                'protocols': gold_data[:5],
            },
            'other_rwa': {
                'total_tvl': other_rwa_tvl / 1e9,
                'protocols': other_rwa_data[:10],
            },
            'total_rwa_tvl': (treasury_tvl + gold_tvl + other_rwa_tvl) / 1e9,
            'timestamp': datetime.datetime.now().isoformat()
        }
    except Exception as e:
        return None

@st.cache_data(ttl=3600, show_spinner=False)
def get_protocol_historical(slug: str):
    """
    Fetch historical TVL data for a specific protocol from DeFiLlama API.
    Returns: DataFrame with date index and TVL
    """
    try:
        url = f"https://api.llama.fi/protocol/{slug}"
        response = requests.get(url, timeout=15)
        if response.status_code != 200:
            return None
        
        data = response.json()
        tvl_history = data.get('tvl', [])
        
        records = []
        for point in tvl_history:
            date = datetime.datetime.fromtimestamp(point.get('date', 0))
            tvl = point.get('totalLiquidityUSD', 0) / 1e9
            records.append({'date': date, 'TVL': tvl})
        
        df = pd.DataFrame(records)
        if not df.empty:
            df = df.set_index('date')
            df = df.sort_index()
        
        return df
    except Exception as e:
        return None

# ========== DATA FUNCTIONS ==========
# Disk cache settings for fast startup
CACHE_FILE = os.path.join(os.path.dirname(__file__), '.market_data_cache.pkl')
CACHE_TTL_SECONDS = 600  # 10 minutes

def _load_from_disk_cache():
    """Load cached data from disk if fresh enough"""
    try:
        if os.path.exists(CACHE_FILE):
            cache_age = time.time() - os.path.getmtime(CACHE_FILE)
            if cache_age < CACHE_TTL_SECONDS:
                with open(CACHE_FILE, 'rb') as f:
                    data = pickle.load(f)
                    return data.get('df'), data.get('df_original')
    except Exception:
        pass
    return None, None

def _save_to_disk_cache(df, df_original):
    """Save data to disk cache"""
    try:
        with open(CACHE_FILE, 'wb') as f:
            pickle.dump({'df': df, 'df_original': df_original, 'timestamp': time.time()}, f)
    except Exception:
        pass

# ============================================
# SENTIMENT INDICATORS DATA FUNCTIONS
# ============================================

@st.cache_data(ttl=3600, show_spinner=False)
def get_crypto_fear_greed():
    """Fetch Crypto Fear & Greed Index from Alternative.me API"""
    try:
        # Get current value and historical data
        url = "https://api.alternative.me/fng/?limit=30"
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if 'data' in data:
                current = data['data'][0]
                history = []
                for item in data['data']:
                    history.append({
                        'date': datetime.datetime.fromtimestamp(int(item['timestamp'])),
                        'value': int(item['value']),
                        'classification': item['value_classification']
                    })
                return {
                    'current': int(current['value']),
                    'classification': current['value_classification'],
                    'history': pd.DataFrame(history).set_index('date').sort_index()
                }
    except Exception as e:
        st.warning(f"Crypto Fear & Greedå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    return None

@st.cache_data(ttl=3600, show_spinner=False)
def get_cnn_fear_greed():
    """Fetch CNN Fear & Greed Index via web scraping"""
    try:
        # CNN Fear & Greed is typically scraped from CNN website
        # Using a backup approach with static placeholder for now
        # In production, use RapidAPI or web scraping
        url = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if 'fear_and_greed' in data:
                fg = data['fear_and_greed']
                # Build history from graph data
                history = []
                if 'fear_and_greed_historical' in data:
                    for point in data['fear_and_greed_historical'].get('data', []):
                        history.append({
                            'date': datetime.datetime.fromtimestamp(point['x'] / 1000),
                            'value': point['y']
                        })
                return {
                    'current': fg.get('score', None),
                    'classification': fg.get('rating', ''),
                    'previous_close': fg.get('previous_close', None),
                    'history': pd.DataFrame(history).set_index('date').sort_index() if history else None
                }
    except Exception as e:
        pass  # Silently fail, will show N/A
    
    # Fallback: return None to indicate data unavailable
    return None

@st.cache_data(ttl=3600, show_spinner=False)
def get_put_call_ratio():
    """Fetch Put/Call Ratio from CBOE"""
    try:
        # CBOE provides daily P/C ratios
        url = "https://www.cboe.com/us/options/market_statistics/daily/"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            # Parse the page for P/C data (simplified)
            # For now, use FRED data as backup
            pass
    except:
        pass
    
    # Fallback: Try FRED for equity put/call ratio
    try:
        from pandas_datareader import data as pdr
        # CBOE Equity Put/Call Ratio is available via some data providers
        # Using VIX as proxy for now - will enhance later
        return None
    except:
        return None

@st.cache_data(ttl=86400, show_spinner=False)  # 24 hour cache for weekly data
def get_aaii_sentiment():
    """Fetch AAII Investor Sentiment Survey"""
    try:
        # AAII data is often available via Quandl/NASDAQ Data Link
        # For demo, using placeholder with actual typical values
        # In production, integrate with Quandl API
        
        # Try to fetch from a public source
        url = "https://www.aaii.com/sentimentsurvey"
        # Note: AAII requires parsing their website or API access
        
        # Return placeholder data for now
        # TODO: Integrate with Quandl API when API key is available
        return {
            'bullish': 38.5,
            'neutral': 31.2,
            'bearish': 30.3,
            'bull_bear_spread': 8.2,
            'date': datetime.datetime.now().strftime('%Y-%m-%d'),
            'note': 'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æº–å‚™ä¸­'
        }
    except Exception as e:
        return None


@st.cache_data(ttl=86400, show_spinner=False)  # 24 hour cache (FOMC meets ~8 times/year)
def get_fomc_sep_projections():
    """Fetch FOMC Summary of Economic Projections (SEP) from FRED
    
    Returns median projections for:
    - Federal Funds Rate
    - Real GDP Growth
    - Unemployment Rate
    - Core PCE Inflation
    """
    try:
        from pandas_datareader import data as pdr
        
        # FRED Series IDs for FOMC SEP Medians
        # Annual frequency - projections for current year, next year, and longer run
        sep_series = {
            'ff_rate': 'FEDTARMD',      # Fed Funds Rate Median
            'gdp_growth': 'GDPC1CTM',   # Real GDP Growth Central Tendency Median
            'unemployment': 'UNRATECTM', # Unemployment Rate Central Tendency Median
            'core_pce': 'PCECTPICTM',   # Core PCE Central Tendency Median
        }
        
        projections = {}
        for key, series_id in sep_series.items():
            try:
                data = pdr.get_data_fred(series_id, start='2020-01-01')
                if data is not None and len(data) > 0:
                    # Get the most recent projections
                    recent = data.dropna().tail(5)
                    projections[key] = {
                        'series': recent,
                        'latest': recent.iloc[-1].values[0] if len(recent) > 0 else None,
                        'previous': recent.iloc[-2].values[0] if len(recent) > 1 else None,
                        'date': recent.index[-1].strftime('%Y-%m-%d') if len(recent) > 0 else None
                    }
            except Exception:
                projections[key] = None
        
        return projections if projections else None
    except Exception as e:
        return None


@st.cache_data(ttl=3600, show_spinner=False)  # 1 hour cache
def get_cme_fedwatch():
    """Fetch CME FedWatch Tool probabilities for next FOMC meeting
    
    Returns probability of rate cut, hold, or hike
    """
    try:
        # CME FedWatch data is typically from CME website
        # Using a simplified approach - in production, use CME API or scraping
        
        # Try to get from CME website (public data)
        url = "https://www.cmegroup.com/markets/interest-rates/cme-fedwatch-tool.html"
        headers = {'User-Agent': 'Mozilla/5.0'}
        
        # For now, return placeholder based on current market expectations
        # TODO: Implement actual CME FedWatch scraping or API
        
        # Current FF rate is around 4.25-4.50%
        # Market is pricing in cuts for 2026
        return {
            'next_meeting': '2026-01-29',
            'current_rate': '4.25-4.50%',
            'probabilities': {
                'cut_50bp': 5.0,
                'cut_25bp': 65.0,
                'hold': 28.0,
                'hike_25bp': 2.0,
            },
            'expected_rate': '4.00-4.25%',
            'note': 'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æº–å‚™ä¸­ï¼ˆå®Ÿéš›ã®CME FedWatché€£æºäºˆå®šï¼‰'
        }
    except Exception as e:
        return None


@st.cache_data(ttl=600, show_spinner=False)
def get_market_data(_csv_mtime=None, _force_refresh=False):
    # Try disk cache first for fast startup
    if not _force_refresh:
        cached_df, cached_original = _load_from_disk_cache()
        if cached_df is not None and cached_original is not None:
            return cached_df, cached_original
    
    # Fetch from API (slow path)
    end = datetime.datetime.now()
    start = end - datetime.timedelta(days=730)
    
    fred_series = []
    credit_stock_data = None  # Store separately to avoid affecting main data join
    
    for name, ticker in FRED_INDICATORS.items():
        try:
            # Skip CN_Credit_Stock here - fetch separately with longer period
            if name == 'CN_Credit_Stock':
                credit_start = end - datetime.timedelta(days=365*5)  # 5 years for YoY calc
                credit_stock_data = web.DataReader(ticker, 'fred', credit_start, end, api_key=FRED_API_KEY)
                credit_stock_data.columns = [name]
                continue  # Don't add to main series
            else:
                s = web.DataReader(ticker, 'fred', start, end, api_key=FRED_API_KEY)
            s.columns = [name]
            fred_series.append(s)
        except:
            pass
    
    # Yahoo Data
    try:
        y_tickers = list(YAHOO_INDICATORS.values())
        y_data = yf.download(y_tickers, start=start, end=end, progress=False)['Close']
        inv_yahoo = {v: k for k, v in YAHOO_INDICATORS.items()}
        y_data = y_data.rename(columns=inv_yahoo)
    except:
        y_data = pd.DataFrame()
    
    # Global M2 Data (Latest values from central banks - Dec 2024)
    # Sources: BOJ, PBOC, ECB via web search
    global_m2_data = {
        'JP_M2': 1260,    # 1,260 Trillion JPY (December 2024, Bank of Japan)
        'CN_M2': 313.53,  # 313.53 Trillion CNY (December 2024, People's Bank of China)
        'EU_M2': 15.58,   # 15.58 Trillion EUR (December 2024, ECB)
    }
    
    # CPI Annual Rates (Latest: Nov 2025) - for Real M2 calculation
    # Sources: Trading Economics, Statistics bureaus
    global_cpi_rates = {
        'JP_CPI': 2.9,    # Japan: 2.9% YoY (Nov 2025)
        'CN_CPI': 0.7,    # China: 0.7% YoY (Nov 2025)
        'EU_CPI': 2.1,    # Euro Area: 2.1% YoY (Nov 2025)
    }
    
    # Calculate Real M2 (simplified: Nominal / (1 + CPI/100))
    global_real_m2 = {
        'JP_M2_Real': global_m2_data['JP_M2'] / (1 + global_cpi_rates['JP_CPI']/100),
        'CN_M2_Real': global_m2_data['CN_M2'] / (1 + global_cpi_rates['CN_CPI']/100),
        'EU_M2_Real': global_m2_data['EU_M2'] / (1 + global_cpi_rates['EU_CPI']/100),
    }
    
    # Join All
    df = pd.concat(fred_series + ([y_data] if not y_data.empty else []), axis=1).sort_index()
    
    # Add Global M2 data (latest value applied to recent dates)
    for col_name, value in global_m2_data.items():
        df[col_name] = value
    
    # Add Global CPI and Real M2 data
    for col_name, value in global_cpi_rates.items():
        df[col_name] = value
    for col_name, value in global_real_m2.items():
        df[col_name] = value
    
    # Unit Normalization (Million to Billion)
    mil_to_bil = ['Fed_Assets', 'TGA', 'Reserves', 'SOMA_Total', 'Bank_Cash', 'SRF', 'FIMA', 'Primary_Credit', 'Total_Loans', 'SOMA_Bills', 'M2SL', 'M2REAL', 'CI_Loans', 'CRE_Loans']
    for col in mil_to_bil:
        if col in df.columns:
            df[col] = df[col] / 1000
    
    # Calculate Net Liquidity
    if all(c in df.columns for c in ['Fed_Assets', 'TGA', 'ON_RRP']):
        df['Net_Liquidity'] = df['Fed_Assets'] - df['TGA'] - df['ON_RRP']
    
    # Calculate Real M2 (M2 adjusted for CPI)
    if all(c in df.columns for c in ['M2SL', 'CPI']):
        # Forward fill CPI to handle NaN values before calculation
        cpi_filled = df['CPI'].ffill()
        # Normalize CPI to base at earliest date
        cpi_base = cpi_filled.dropna().iloc[0] if not cpi_filled.dropna().empty else 1
        df['US_Real_M2_Index'] = (df['M2SL'] / cpi_filled) * cpi_base
    
    # Calculate SOMA Bills Ratio
    if all(c in df.columns for c in ['SOMA_Bills', 'SOMA_Total']):
        df['SomaBillsRatio'] = (df['SOMA_Bills'] / df['SOMA_Total']) * 100
    
    # RMP Detection Logic (Updated for Dec 2025 Policy)
    # RMP: Reserve Management Purchases - Started Dec 12, 2025
    # Target: $40B/month T-Bills purchases (~$1.33B/day assuming 30-day month)
    if all(c in df.columns for c in ['SOMA_Bills']):
        df['RMP_Alert_Active'] = False
        df['RMP_Status_Text'] = "ğŸ“Š RMPç›£è¦–ä¸­ï¼ˆ2025å¹´12æœˆ12æ—¥é–‹å§‹ï¼‰"
        
        bills_recent = df['SOMA_Bills'].tail(30)  # Last 30 days
        
        if len(bills_recent) >= 7:  # Need at least 1 week of data
            # Calculate weekly change rate
            bills_7d_ago = bills_recent.iloc[-7] if len(bills_recent) >= 7 else bills_recent.iloc[0]
            bills_now = bills_recent.iloc[-1]
            weekly_change = bills_now - bills_7d_ago
            
            # Expected weekly change: ~$9.3B (40B/month * 7days/30days)
            # Allow 50% tolerance
            expected_weekly_min = 4.5  # Billions
            expected_weekly_max = 15.0  # Billions
            
            if weekly_change >= expected_weekly_min:
                if weekly_change <= expected_weekly_max:
                    df.loc[df.index[-1], 'RMP_Alert_Active'] = True
                    df.loc[df.index[-1], 'RMP_Status_Text'] = f"âœ… RMPå®Ÿè¡Œä¸­: +${weekly_change:.1f}B/é€±ï¼ˆç›®æ¨™ãƒšãƒ¼ã‚¹ï¼‰"
                else:
                    df.loc[df.index[-1], 'RMP_Alert_Active'] = True
                    df.loc[df.index[-1], 'RMP_Status_Text'] = f"âš ï¸ RMPåŠ é€Ÿ: +${weekly_change:.1f}B/é€±ï¼ˆé€šå¸¸ãƒšãƒ¼ã‚¹è¶…éï¼ï¼‰"
            elif weekly_change >= 0:
                df.loc[df.index[-1], 'RMP_Status_Text'] = f"ğŸ”„ RMPç¸®å°: +${weekly_change:.1f}B/é€±ï¼ˆãƒšãƒ¼ã‚¹æ¸›é€Ÿï¼‰"
            else:
                df.loc[df.index[-1], 'RMP_Status_Text'] = f"â›” Billså£²å´: ${weekly_change:.1f}B/é€±ï¼ˆRMPåœæ­¢ï¼Ÿï¼‰"
    
    # Calculate China Credit Impulse (Proxy using BIS credit data)
    # Formula: Credit Impulse = (Credit Flow[t] - Credit Flow[t-4]) / GDP
    # where Credit Flow = Credit Stock[t] - Credit Stock[t-1]
    # Note: This is a PROXY using FRED quarterly data, not actual PBoC TSF data
    if credit_stock_data is not None and len(credit_stock_data) >= 5:
        try:
            credit = credit_stock_data['CN_Credit_Stock'].dropna()
            
            # Calculate credit flow (change in credit stock, Billions CNY)
            credit_flow = credit.diff()
            
            # Calculate credit flow change (YoY, 4 quarters)
            credit_flow_change = credit_flow - credit_flow.shift(4)
            
            # China GDP in Billions CNY
            # 2024 GDP â‰ˆ 18.7 trillion USD â‰ˆ 136 trillion CNY = 136,000 Billion CNY
            annual_gdp_bln_cny = 136000  # Fallback value
            
            quarterly_gdp = annual_gdp_bln_cny / 4
            
            # Credit Impulse = Credit Flow Change / GDP (as percentage)
            credit_impulse = (credit_flow_change / quarterly_gdp) * 100
            
            # Add Credit Impulse to main DataFrame (will join on index)
            df['CN_Credit_Impulse'] = credit_impulse
        except Exception as e:
            pass  # Silently fail if calculation fails
    
    # Store actual last data date for each column BEFORE forward fill
    # This preserves the true "data source update date"
    last_valid_dates = {}
    for col in df.columns:
        valid_data = df[col].dropna()
        if len(valid_data) > 0:
            # Store as string to avoid type issues
            last_valid_dates[col] = valid_data.index[-1].strftime('%Y-%m-%d')
    
    # NEW: Fetch actual FRED release info (last_updated) for precise freshness tracking
    # This shows when the provider (BLS, FRB, etc.) actually pushed the data
    fred_ids = list(set(FRED_INDICATORS.values())) # Use set to avoid redundant API calls
    fred_release_info = get_fred_release_dates(fred_ids)
    
    # Map back to our column names (supporting multiple indicators per series_id)
    col_release_dates = {}
    for indicator, series_id in FRED_INDICATORS.items():
        if series_id in fred_release_info:
            col_release_dates[indicator] = fred_release_info[series_id]['last_updated']

    # IMPORTANT: Store original data BEFORE forward fill for accurate monthly change calculations
    # This is needed because ffill makes all dates have data, so dropna() won't return just monthly points
    df_original = df.copy()
    
    # Forward fill missing data (for display continuity)
    df = df.ffill()
    
    # Store metadata as a DataFrame attribute (accessible in display functions)
    # Note: We store strings/dicts only - NOT DataFrames (causes JSON serialization error)
    df.attrs['last_valid_dates'] = last_valid_dates
    df.attrs['fred_release_dates'] = col_release_dates # SOURCE update date
    
    # Copy attrs to original_df for consistent access
    df_original.attrs = df.attrs.copy()
    
    # Note: All data (including SOMA_Bills via WHTLSBL) is now fetched from FRED API
    # Manual data override has been removed
    
    # Save to disk cache for fast startup next time
    _save_to_disk_cache(df, df_original)
    
    return df, df_original  # Return tuple: (ffillç‰ˆ, ã‚ªãƒªã‚¸ãƒŠãƒ«ç‰ˆ)

def show_metric(label, series, unit="", explanation_key="", notes="", alert_func=None):
    """ãƒ¡ãƒˆãƒªãƒƒã‚¯è¡¨ç¤ºãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆæ›´æ–°ãƒãƒ¼ã‚¯å¯¾å¿œï¼‰"""
    if series is None or (hasattr(series, 'isna') and series.isna().all()):
        val = None
        delta = None
        latest_date = None
        release_date = None
    else:
        val = series.iloc[-1] if hasattr(series, 'iloc') else series
        if hasattr(series, 'iloc') and len(series) > 1:
            delta = val - series.iloc[-2]
        else:
            delta = None
        
        # Get actual last data date from DataFrame metadata
        latest_date = None
        release_date = None
        if hasattr(df, 'attrs'):
            col_name = series.name if hasattr(series, 'name') else explanation_key
            if 'last_valid_dates' in df.attrs and col_name in df.attrs['last_valid_dates']:
                latest_date = df.attrs['last_valid_dates'][col_name]
            if 'fred_release_dates' in df.attrs and col_name in df.attrs['fred_release_dates']:
                release_date = df.attrs['fred_release_dates'][col_name]
    
    help_text = EXPLANATIONS.get(explanation_key, "")
    
    # Get freshness badge for label
    freshness_badge = get_freshness_badge(release_date or latest_date) if (release_date or latest_date) else ""
    display_label = f"{freshness_badge} {label}" if freshness_badge else label
    
    if alert_func and val is not None and alert_func(val):
        st.metric(display_label, f"{val:.1f} {unit}" if val is not None else "N/A", 
                 delta=f"{delta:+.1f}" if delta is not None else None,
                 help=help_text, delta_color="inverse")
    else:
        st.metric(display_label, f"{val:.1f} {unit}" if val is not None else "N/A",
                 delta=f"{delta:+.1f}" if delta is not None else None,
                 help=help_text)
    
    # Display data dates
    if latest_date:
        freq_label = DATA_FREQUENCY.get(explanation_key, '')
        st.caption(f"ğŸ“… å¯¾è±¡æœŸé–“: {latest_date} ({freq_label})" if freq_label else f"ğŸ“… å¯¾è±¡æ—¥: {latest_date}")
    
    if release_date:
        st.caption(f"ğŸ”„ æä¾›å…ƒæ›´æ–°æ—¥: {release_date}")
    
    if notes:
        st.caption(notes)

def show_metric_with_sparkline(label, series, df_column, unit="", explanation_key="", notes="", alert_func=None, decimal_places=1):
    """ãƒ¡ãƒˆãƒªãƒƒã‚¯ + ã‚¹ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ³ï¼ˆãƒŸãƒ‹ãƒˆãƒ¬ãƒ³ãƒ‰ãƒãƒ£ãƒ¼ãƒˆï¼‰ã‚’è¡¨ç¤ºï¼ˆæ›´æ–°ãƒãƒ¼ã‚¯å¯¾å¿œï¼‰
    
    Args:
        decimal_places: å°æ•°ç‚¹ä»¥ä¸‹ã®æ¡æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ1ã€ç‚ºæ›¿ãƒ»é‡‘åˆ©ã¯3æ¨å¥¨ï¼‰
    """
    if series is None or (hasattr(series, 'isna') and series.isna().all()):
        val = None
        delta = None
        latest_date = None
        release_date = None
    else:
        val = series.iloc[-1] if hasattr(series, 'iloc') else series
        if hasattr(series, 'iloc') and len(series) > 1:
            delta = val - series.iloc[-2]
        else:
            delta = None
        
        # Get actual last data date from DataFrame metadata
        latest_date = None
        release_date = None
        if hasattr(df, 'attrs'):
            if 'last_valid_dates' in df.attrs and df_column in df.attrs['last_valid_dates']:
                latest_date = df.attrs['last_valid_dates'][df_column]
            if 'fred_release_dates' in df.attrs and df_column in df.attrs['fred_release_dates']:
                release_date = df.attrs['fred_release_dates'][df_column]
    
    help_text = EXPLANATIONS.get(explanation_key, "")
    
    # Get freshness badge for label
    freshness_badge = get_freshness_badge(release_date or latest_date) if (release_date or latest_date) else ""
    display_label = f"{freshness_badge} {label}" if freshness_badge else label
    
    # Dynamic format string based on decimal_places
    val_format = f"{{:.{decimal_places}f}}"
    delta_format = f"{{:+.{decimal_places}f}}"
    
    # ãƒ¡ãƒˆãƒªãƒƒã‚¯è¡¨ç¤º
    if alert_func and val is not None and alert_func(val):
        st.metric(display_label, f"{val_format.format(val)} {unit}" if val is not None else "N/A", 
                 delta=delta_format.format(delta) if delta is not None else None,
                 help=help_text, delta_color="inverse")
    else:
        st.metric(display_label, f"{val_format.format(val)} {unit}" if val is not None else "N/A",
                 delta=delta_format.format(delta) if delta is not None else None,
                 help=help_text)

    
    # Display data dates
    if latest_date:
        freq_label = DATA_FREQUENCY.get(df_column, '')
        st.caption(f"ğŸ“… å¯¾è±¡æœŸé–“: {latest_date} ({freq_label})" if freq_label else f"ğŸ“… å¯¾è±¡æ—¥: {latest_date}")
    
    if release_date:
        st.caption(f"ğŸ”„ æä¾›å…ƒæ›´æ–°æ—¥: {release_date}")
    
    if notes:
        st.caption(notes)
    
    # ã‚¹ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ³ï¼ˆå°ã•ãªãƒˆãƒ¬ãƒ³ãƒ‰ãƒãƒ£ãƒ¼ãƒˆï¼‰
    if df_column in df.columns and not df.get(df_column, pd.Series()).isna().all():
        recent_data = df[df_column].tail(60)  # ç›´è¿‘60æ—¥åˆ†
        
        st.caption("ğŸ“Š éå»60æ—¥é–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰")
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=recent_data.index,
            y=recent_data.values,
            mode='lines',
            line=dict(color='cyan', width=1),
            fill='tozeroy',
            fillcolor='rgba(0,255,255,0.1)',
            showlegend=False
        ))
        
        fig.update_layout(
            height=100,
            margin=dict(l=0, r=0, t=0, b=0),
            xaxis=dict(visible=False),
            yaxis=dict(visible=False),
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            hovermode=False
        )
        
        st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False}, key=f"spark_{uuid.uuid4().hex[:8]}")

def plot_dual_axis(df, left_col, right_col, left_name, right_name):
    """2è»¸ãƒãƒ£ãƒ¼ãƒˆ"""
    fig = make_subplots(specs=[[{"secondary_y": True}]])
    
    if left_col in df.columns:
        fig.add_trace(
            go.Scatter(x=df.index, y=df[left_col], name=left_name, line=dict(color='cyan')),
            secondary_y=False
        )
    
    if right_col in df.columns:
        fig.add_trace(
            go.Scatter(x=df.index, y=df[right_col], name=right_name, line=dict(color='orange')),
            secondary_y=True
        )
    
    fig.update_layout(
        template='plotly_dark',
        height=400,
        hovermode='x unified',
        showlegend=True
    )
    fig.update_yaxes(title_text=left_name, secondary_y=False)
    fig.update_yaxes(title_text=right_name, secondary_y=True)
    
    st.plotly_chart(fig, use_container_width=True, key="pc_2")

def plot_soma_composition(df):
    """SOMAæ§‹æˆãƒãƒ£ãƒ¼ãƒˆï¼ˆSOMA Total + Bills Ratioï¼‰"""
    fig = make_subplots(specs=[[{"secondary_y": True}]])
    
    if 'SOMA_Total' in df.columns:
        soma_resampled = df['SOMA_Total'].resample('W').last()
        fig.add_trace(
            go.Bar(x=soma_resampled.index, y=soma_resampled, name='SOMA Total (Billions)', marker_color='steelblue'),
            secondary_y=False
        )
    
    if 'SomaBillsRatio' in df.columns:
        ratio_resampled = df['SomaBillsRatio'].resample('W').last()
        fig.add_trace(
            go.Scatter(x=ratio_resampled.index, y=ratio_resampled, name='Bills Ratio (%)', 
                      line=dict(color='orange', width=2)),
            secondary_y=True
        )
    
    fig.update_layout(
        template='plotly_dark',
        height=400,
        hovermode='x unified',
        showlegend=True
    )
    fig.update_yaxes(title_text="SOMA Total (B)", secondary_y=False)
    fig.update_yaxes(title_text="Bills Ratio (%)", secondary_y=True, tickformat='.1f')
    
    st.plotly_chart(fig, use_container_width=True, key="pc_3")

# ========== MAIN APP ==========
st.title(f"ğŸ“Š {PAGE_TITLE}")
st.caption("æ›´æ–°é–“éš”: 10åˆ† | ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: FRED, Yahoo Finance")

# Sidebar
with st.sidebar:
    st.header("ğŸ›ï¸ Control")
    if st.button("Force Update", type="primary"):
        st.cache_data.clear()
        st.rerun()
    
    # Check CSV modification time for cache invalidation
    csv_mtime = None
    if os.path.exists(MANUAL_DATA_FILE):
        csv_mtime = os.path.getmtime(MANUAL_DATA_FILE)
    
    st.markdown("---")
    # Direct download button (single step)
    df_for_download, _ = get_market_data(csv_mtime)
    csv_data = df_for_download.to_csv()
    st.download_button(
        "ğŸ“¥ Download CSV",
        csv_data,
        "market_cockpit_data.csv",
        "text/csv",
        key="download_csv_main"
    )
    
    # === Market Alerts Section ===
    st.markdown("---")
    st.subheader("ğŸ”” Market Alerts")
    st.caption("ä¸»è¦æ©Ÿé–¢ï¼ˆFRB, Treasury, BISï¼‰ã®ç›´è¿‘24hç™ºè¡¨")
    
    # Check for alerts button
    if st.button("ğŸ” ä»Šã™ããƒã‚§ãƒƒã‚¯", key="check_alerts_btn"):
        with st.spinner("RSSå–å¾—ä¸­..."):
            alerts = check_for_market_alerts()
            st.session_state['market_alerts'] = alerts
            st.session_state['alerts_checked_at'] = datetime.datetime.now().strftime('%H:%M')
    
    # Display alerts
    if 'market_alerts' in st.session_state and st.session_state['market_alerts']:
        checked_at = st.session_state.get('alerts_checked_at', '')
        st.caption(f"ğŸ“¡ {checked_at} ãƒã‚§ãƒƒã‚¯æ¸ˆã¿")
        
        for alert in st.session_state['market_alerts']:
            hours = alert.get('hours_ago', 0)
            icon = "ğŸ”´" if hours < 6 else "ğŸŸ¡" if hours < 12 else "ğŸŸ¢"
            st.markdown(f"{icon} **[{alert['source']}]** {alert['title']}")
            st.caption(f"  â†³ {hours}æ™‚é–“å‰ | [è©³ç´°]({alert['link']})")
    else:
        if 'alerts_checked_at' in st.session_state:
            st.info("ğŸ“­ ç›´è¿‘24æ™‚é–“ã®æ–°ç€ã‚¢ãƒ©ãƒ¼ãƒˆãªã—")
        else:
            st.caption("ãƒœã‚¿ãƒ³ã§ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯")


# Load Data (returns tuple: ffillç‰ˆ, ã‚ªãƒªã‚¸ãƒŠãƒ«ç‰ˆ)
df, df_original = get_market_data(csv_mtime)

# Data Health Check
with st.sidebar:
    # === AI Analysis Focus Settings (MOVED TO TOP for visibility) ===
    st.markdown("---")
    st.subheader("ğŸ¯ AI Analysis Focus")
    st.caption("AIã«ç‰¹ã«æ³¨ç›®ã•ã›ãŸã„é ˜åŸŸã‚’é¸æŠ")
    
    ai_focus_options = [
        "ğŸ’§ æµå‹•æ€§ (Liquidity)",
        "ğŸ‘· é›‡ç”¨ (Employment)",
        "ğŸ“ˆ ã‚¤ãƒ³ãƒ•ãƒ¬ (Inflation)",
        "ğŸ¦ éŠ€è¡Œãƒ»ä¿¡ç”¨ (Banking)",
        "â‚¿ ã‚¯ãƒªãƒ—ãƒˆ (Crypto)",
        "ğŸ’µ ç‚ºæ›¿ (FX)",
        "ğŸ“Š ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ (Valuation)",
        "ğŸŒ ã‚°ãƒ­ãƒ¼ãƒãƒ«M2 (Global M2)"
    ]
    
    ai_focus_selection = st.multiselect(
        "æ³¨ç›®é ˜åŸŸ",
        ai_focus_options,
        default=[],
        key="ai_focus_categories",
        help="é¸æŠã—ãŸé ˜åŸŸãŒAIåˆ†æã®å…ˆé ­ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚æœªé¸æŠã®å ´åˆã¯å…¨æŒ‡æ¨™ã‚’å¹³ç­‰ã«åˆ†æ"
    )
    
    if ai_focus_selection:
        st.success(f"âœ… {len(ai_focus_selection)} é ˜åŸŸã‚’ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ä¸­")
    else:
        st.caption("ğŸ“Š å…¨æŒ‡æ¨™ã‚’å¹³ç­‰ã«åˆ†æ")
    
    st.markdown("---")
    
    # === Data Health Monitor (Collapsible) ===
    with st.expander("ğŸ“¡ Data Health Monitor", expanded=False):
        # Current time display
        import datetime
        current_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        st.caption(f"ğŸ• ç¾åœ¨æ™‚åˆ»: {current_time}")
        
        # Data freshness check
        if hasattr(df, 'attrs') and 'last_valid_dates' in df.attrs:
            release_dates = df.attrs.get('fred_release_dates', {})
            freshness = get_data_freshness_status(df.attrs['last_valid_dates'], release_dates)
            summary = freshness['summary']
            
            # Health Score (visual meter)
            health_score = summary['health_score']
            if health_score >= 80:
                health_color = "ğŸŸ¢"
                health_status = "Healthy"
            elif health_score >= 50:
                health_color = "ğŸŸ¡"
                health_status = "Warning"
            else:
                health_color = "ğŸ”´"
                health_status = "Critical"
            
            st.metric(
                "Data Health Score",
                f"{health_color} {health_score}%",
                delta=f"{health_status}"
            )
            
            # Summary counts in compact layout
            col1, col2 = st.columns(2)
            with col1:
                st.caption(f"ğŸŸ¢ Fresh: {summary['fresh_count']}")
                st.caption(f"ğŸ”´ Critical: {summary['critical_count']}")
            with col2:
                st.caption(f"ğŸŸ¡ Stale: {summary['stale_count']}")
                st.caption(f"âš« Missing: {summary['missing_count']}")
            
            # Detailed view in expander
            with st.expander("ğŸ“‹ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ", expanded=False):
                st.markdown("##### ğŸ”´ è¦ç¢ºèª (Critical)")
                if freshness['critical']:
                    for ind in freshness['critical']:
                        detail = freshness['details'][ind]
                        if detail.get('is_release_based'):
                            st.markdown(f"- **{ind}**: {detail['days_old']}æ—¥å‰ (å…¬è¡¨: {detail['release_date']}, å¯¾è±¡: {detail['last_date']})")
                        else:
                            st.markdown(f"- **{ind}**: {detail['days_old']}æ—¥å‰ (å¯¾è±¡: {detail['last_date']})")
                else:
                    st.caption("ãªã— âœ…")
                
                st.markdown("##### ğŸŸ¡ çµŒéæ³¨æ„ (Stale)")
                if freshness['stale']:
                    for ind in freshness['stale']:
                        detail = freshness['details'][ind]
                        if detail.get('is_release_based'):
                            st.markdown(f"- **{ind}**: {detail['days_old']}æ—¥å‰ (å…¬è¡¨: {detail['release_date']}, å¯¾è±¡: {detail['last_date']})")
                        else:
                            st.markdown(f"- **{ind}**: {detail['days_old']}æ—¥å‰ (å¯¾è±¡: {detail['last_date']})")
                else:
                    st.caption("ãªã— âœ…")
                
                st.markdown("##### ğŸŸ¢ æœ€æ–° (Fresh)")
                st.caption(f"{len(freshness['fresh'])} é …ç›®ãŒæœ€æ–°ãƒ‡ãƒ¼ã‚¿")
            
            # Warning for AI Analysis
            if summary['critical_count'] > 0 or summary['stale_count'] > 3:
                st.warning(f"âš ï¸ {summary['critical_count'] + summary['stale_count']} é …ç›®ãŒå¤ã„å¯èƒ½æ€§")
        else:
            total_cols = len(df.columns)
            valid_cols = sum(1 for c in df.columns if not df[c].isna().all())
            st.metric("Valid Series", f"{valid_cols}/{total_cols}")
    
    st.caption("ğŸ’¡ å…¨ãƒ‡ãƒ¼ã‚¿ã¯FRED APIã‹ã‚‰è‡ªå‹•å–å¾—")



# Tabs
tabs = st.tabs(["ğŸ“Š Liquidity & Rates", "ğŸŒ Global Money & FX", "ğŸ“ˆ US Economic Data", "ğŸª™ Crypto Liquidity", "ğŸ¤– AI Analysis", "ğŸ² Monte Carlo", "ğŸ“° Market Voices", "ğŸ­ Market Sentiment"])

# Tab 1: Liquidity & Rates
with tabs[0]:
    st.subheader("ğŸ¦ Liquidity & The Fed")
    
    # === VALUATION & LEVERAGE SECTION (NEW) ===
    st.markdown("#### ğŸ“Š ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ & ãƒ¬ãƒãƒ¬ãƒƒã‚¸æŒ‡æ¨™")
    st.caption("å¸‚å ´ã®éç†±åº¦ã¨ãƒ¬ãƒãƒ¬ãƒƒã‚¸çŠ¶æ³ã‚’ä¸€ç›®ã§ç¢ºèª")
    
    # Fetch data
    pe_data = get_pe_ratios()
    leverage_data = get_crypto_leverage_data()
    
    col_val1, col_val2, col_val3, col_val4 = st.columns(4)
    
    with col_val1:
        if pe_data and pe_data.get('sp500_pe'):
            pe = pe_data['sp500_pe']
            avg = pe_data['sp500_pe_avg']
            delta = pe - avg
            delta_pct = (delta / avg) * 100
            # Color coding: >25 = overvalued, <15 = undervalued
            color = "ğŸ”´" if pe > 25 else "ğŸŸ¡" if pe > 20 else "ğŸŸ¢"
            st.metric(
                f"{color} S&P 500 P/E",
                f"{pe:.1f}",
                delta=f"{delta:+.1f} vs avg ({avg:.1f})",
                help="æ­´å²çš„å¹³å‡ã¯ç´„19.5ã€‚25ä»¥ä¸Šã¯éç†±ã€15ä»¥ä¸‹ã¯å‰²å®‰"
            )
        else:
            st.metric("S&P 500 P/E", "å–å¾—ä¸­...")
    
    with col_val2:
        if pe_data and pe_data.get('nasdaq_pe'):
            pe = pe_data['nasdaq_pe']
            color = "ğŸ”´" if pe > 35 else "ğŸŸ¡" if pe > 28 else "ğŸŸ¢"
            st.metric(
                f"{color} NASDAQ P/E (QQQ)",
                f"{pe:.1f}",
                help="ãƒã‚¤ãƒ†ã‚¯æ ªã®ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡æ¨™"
            )
        else:
            st.metric("NASDAQ P/E", "å–å¾—ä¸­...")
    
    with col_val3:
        if leverage_data and leverage_data.get('btc_funding_rate') is not None:
            fr = leverage_data['btc_funding_rate']
            # Funding rate interpretation: >0.1% = bullish crowded, <-0.1% = bearish crowded
            if fr > 0.05:
                color = "ğŸ”´"
                status = "ãƒ­ãƒ³ã‚°éå¤š"
            elif fr < -0.05:
                color = "ğŸ”µ"
                status = "ã‚·ãƒ§ãƒ¼ãƒˆéå¤š"
            else:
                color = "ğŸŸ¢"
                status = "ä¸­ç«‹"
            st.metric(
                f"{color} BTC Funding Rate",
                f"{fr:.4f}%",
                delta=status,
                help="Funding Rate > 0.1% ã¯ãƒ­ãƒ³ã‚°ãƒã‚¸ã‚·ãƒ§ãƒ³éå¤šï¼ˆéç†±ï¼‰ã€‚< -0.1% ã¯ã‚·ãƒ§ãƒ¼ãƒˆéå¤š"
            )
        else:
            st.metric("BTC Funding Rate", "å–å¾—ä¸­...")
    
    with col_val4:
        if leverage_data and leverage_data.get('btc_long_short_ratio'):
            ratio = leverage_data['btc_long_short_ratio']
            if ratio > 1.5:
                color = "ğŸ”´"
                status = "ãƒ­ãƒ³ã‚°åã‚Š"
            elif ratio < 0.7:
                color = "ğŸ”µ"
                status = "ã‚·ãƒ§ãƒ¼ãƒˆåã‚Š"
            else:
                color = "ğŸŸ¢" 
                status = "å‡è¡¡"
            st.metric(
                f"{color} BTC Long/Short Ratio",
                f"{ratio:.2f}",
                delta=status,
                help="ãƒ­ãƒ³ã‚°å£åº§/ã‚·ãƒ§ãƒ¼ãƒˆå£åº§ã®æ¯”ç‡ã€‚1.0ãŒå‡è¡¡"
            )
        else:
            st.metric("BTC L/S Ratio", "å–å¾—ä¸­...")
    
    # === Open Interest with Historical Comparison ===
    if leverage_data:
        st.markdown("#### ğŸ“ˆ Open Interest (ãƒ¬ãƒãƒ¬ãƒƒã‚¸ç©ã¿ä¸ŠãŒã‚Š)")
        
        col_btc, col_eth = st.columns(2)
        
        with col_btc:
            oi = leverage_data.get('btc_open_interest', 0)
            avg = leverage_data.get('btc_oi_avg_30d')
            ath = leverage_data.get('btc_oi_ath')
            
            if oi and avg:
                pct_vs_avg = ((oi - avg) / avg) * 100
                pct_vs_ath = (oi / ath * 100) if ath else 0
                
                # Color coding based on position vs average
                if pct_vs_avg > 20:
                    color = "ğŸ”´"
                    status = "å±é™ºã‚¾ãƒ¼ãƒ³"
                elif pct_vs_avg > 5:
                    color = "ğŸŸ¡"
                    status = "é«˜ã‚"
                elif pct_vs_avg < -20:
                    color = "ğŸ”µ"
                    status = "ä½ã‚"
                else:
                    color = "ğŸŸ¢"
                    status = "æ­£å¸¸"
                
                st.metric(
                    f"{color} BTC Open Interest",
                    f"{oi:,.0f} BTC",
                    delta=f"{pct_vs_avg:+.1f}% vs 30æ—¥å¹³å‡",
                    help=f"30æ—¥å¹³å‡: {avg:,.0f} BTC | ATH: {ath:,.0f} BTC ({pct_vs_ath:.0f}%)"
                )
                st.caption(f"ğŸ“Š ATHæ¯”: **{pct_vs_ath:.0f}%** | çŠ¶æ…‹: **{status}**")
            else:
                st.metric("BTC Open Interest", f"{oi:,.0f} BTC" if oi else "å–å¾—ä¸­...")
            
            # Trend chart
            if leverage_data.get('btc_oi_history'):
                hist = leverage_data['btc_oi_history']
                oi_df = pd.DataFrame({
                    'date': hist['timestamps'],
                    'BTC OI': hist['values']
                }).set_index('date')
                st.line_chart(oi_df, height=150)
        
        with col_eth:
            oi = leverage_data.get('eth_open_interest', 0)
            avg = leverage_data.get('eth_oi_avg_30d')
            ath = leverage_data.get('eth_oi_ath')
            
            if oi and avg:
                pct_vs_avg = ((oi - avg) / avg) * 100
                pct_vs_ath = (oi / ath * 100) if ath else 0
                
                # Color coding
                if pct_vs_avg > 20:
                    color = "ğŸ”´"
                    status = "å±é™ºã‚¾ãƒ¼ãƒ³"
                elif pct_vs_avg > 5:
                    color = "ğŸŸ¡"
                    status = "é«˜ã‚"
                elif pct_vs_avg < -20:
                    color = "ğŸ”µ"
                    status = "ä½ã‚"
                else:
                    color = "ğŸŸ¢"
                    status = "æ­£å¸¸"
                
                st.metric(
                    f"{color} ETH Open Interest",
                    f"{oi:,.0f} ETH",
                    delta=f"{pct_vs_avg:+.1f}% vs 30æ—¥å¹³å‡",
                    help=f"30æ—¥å¹³å‡: {avg:,.0f} ETH | ATH: {ath:,.0f} ETH ({pct_vs_ath:.0f}%)"
                )
                st.caption(f"ğŸ“Š ATHæ¯”: **{pct_vs_ath:.0f}%** | çŠ¶æ…‹: **{status}**")
            else:
                st.metric("ETH Open Interest", f"{oi:,.0f} ETH" if oi else "å–å¾—ä¸­...")
            
            # Trend chart
            if leverage_data.get('eth_oi_history'):
                hist = leverage_data['eth_oi_history']
                oi_df = pd.DataFrame({
                    'date': hist['timestamps'],
                    'ETH OI': hist['values']
                }).set_index('date')
                st.line_chart(oi_df, height=150)
        
        st.caption("""
        ğŸ’¡ **Open Interest ã®è¦‹æ–¹**
        - **30æ—¥å¹³å‡æ¯” +20%ä»¥ä¸Š** ğŸ”´: ãƒ¬ãƒãƒ¬ãƒƒã‚¸éå¤š â†’ æ¸…ç®—é€£é–ãƒªã‚¹ã‚¯é«˜
        - **30æ—¥å¹³å‡æ¯” Â±5%** ğŸŸ¢: æ­£å¸¸ãƒ¬ãƒ³ã‚¸
        - **ATHæ¯”**: éå»30æ—¥ã®æœ€é«˜å€¤ã«å¯¾ã™ã‚‹ç¾åœ¨ä½ç½®
        """)
    
    st.markdown("---")
    

    # Net Liquidity - Special treatment with SP500 comparison
    st.markdown("#### Net Liquidity")

    col1, col2 = st.columns([1, 3])
    with col1:
        show_metric_with_sparkline("Net Liquidity", df.get('Net_Liquidity'), 'Net_Liquidity', "B", "Net_Liquidity", notes="å¸‚å ´ã®çœŸã®ç‡ƒæ–™")
    with col2:
        st.markdown("##### Net Liquidity vs S&P 500 (éå»2å¹´é–“)")
        plot_dual_axis(df, 'Net_Liquidity', 'SP500', 'Net Liquidity (L)', 'S&P 500 (R)')
    
    st.markdown("---")
    
    # ON RRP, Reserves, TGA - Integrated view
    col1, col2 = st.columns(2)
    
    with col1:
        # ON RRP
        st.markdown("#### ON RRP")
        show_metric_with_sparkline("ON RRP", df.get('ON_RRP'), 'ON_RRP', "B", "ON_RRP", notes="ä½™å‰°è³‡é‡‘")
        if 'ON_RRP' in df.columns and not df.get('ON_RRP', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['ON_RRP']], height=250)
        
        st.markdown("")  # Spacing
        
        # TGA
        st.markdown("#### TGA")
        show_metric_with_sparkline("TGA", df.get('TGA'), 'TGA', "B", "TGA", notes="æ”¿åºœå£åº§")
        if 'TGA' in df.columns and not df.get('TGA', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['TGA']], height=250)
    
    with col2:
        # Reserves
        st.markdown("#### Reserves")
        show_metric_with_sparkline("Reserves", df.get('Reserves'), 'Reserves', "B", "Reserves", notes="éŠ€è¡Œæº–å‚™é é‡‘")
        if 'Reserves' in df.columns and not df.get('Reserves', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['Reserves']], height=250)
    
    st.markdown("---")
    st.subheader("ğŸ”§ Market Plumbing (Repo & Liquidity)")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # SRF
        st.markdown("#### SRF")
        show_metric_with_sparkline("SRF", df.get('SRF'), 'SRF', "B", "SRF", notes="å›½å†…ãƒªãƒå¸‚å ´")
        if 'SRF' in df.columns and not df.get('SRF', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['SRF']], height=200)
        
        st.markdown("")
        
        # SOFR
        st.markdown("#### SOFR")
        show_metric_with_sparkline("SOFR", df.get('SOFR'), 'SOFR', "%", "SOFR", notes="æ‹…ä¿ä»˜é‡‘åˆ©", decimal_places=3)
        if 'SOFR' in df.columns and not df.get('SOFR', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['SOFR']], height=200)
    
    with col2:
        # FIMA
        st.markdown("#### FIMA")
        show_metric_with_sparkline("FIMA", df.get('FIMA'), 'FIMA', "B", "FIMA", notes="æµ·å¤–ãƒ‰ãƒ«æµå‹•æ€§")
        if 'FIMA' in df.columns and not df.get('FIMA', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['FIMA']], height=200)
        
        st.markdown("")
        
        # EFFR - IORB
        st.markdown("#### EFFR - IORB")
        diff = None
        diff_date = None
        if 'EFFR' in df.columns and 'IORB' in df.columns:
            diff = (df['EFFR'] - df['IORB']) * 100  # Convert to basis points
            # Get date from EFFR data
            if hasattr(df, 'attrs') and 'last_valid_dates' in df.attrs and 'EFFR' in df.attrs['last_valid_dates']:
                diff_date = df.attrs['last_valid_dates']['EFFR']
        
        show_metric("EFFR - IORB", diff, "bps", notes="é€£éŠ€æº–å‚™é‡‘çŠ¶æ³")
        if diff_date:
            st.caption(f"ğŸ“… {diff_date}")
        
        # EFFR and IORB combined long-term chart
        rate_cols = ['EFFR', 'IORB']
        valid_rates = [c for c in rate_cols if c in df.columns and not df.get(c, pd.Series()).isna().all()]
        if valid_rates:
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[valid_rates], height=200)
    
    st.markdown("---")
    st.subheader("ğŸ›ï¸ Fed Balance Sheet (SOMA)")
    
    # RMP Status Display
    rmp_status_series = df.get('RMP_Status_Text')
    rmp_status = rmp_status_series.iloc[-1] if hasattr(rmp_status_series, 'iloc') else "ãƒ‡ãƒ¼ã‚¿ collectä¸­..."
    rmp_active_series = df.get('RMP_Alert_Active', pd.Series([False]))
    rmp_active = rmp_active_series.iloc[-1] if hasattr(rmp_active_series, 'iloc') else False
    
    if rmp_active:
        st.info(f"ğŸ“Š **RMPçŠ¶æ³**: {rmp_status}")
    else:
        st.warning(f"â„¹ï¸ **RMPçŠ¶æ³**: {rmp_status}")
    
    # SOMA Composition Chart (Overview)
    st.markdown("##### SOMA Composition (Total & Bills Ratio)")
    plot_soma_composition(df)
    
    st.markdown("")
    
    # Individual metrics with integrated views
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### SOMA Total")
        show_metric_with_sparkline("SOMA Total", df.get('SOMA_Total'), 'SOMA_Total', "B", "SOMA_Total", notes="ä¿æœ‰è³‡ç”£ç·é¡")
    
    with col2:
        st.markdown("#### SOMA Bills")
        show_metric_with_sparkline("SOMA Bills", df.get('SOMA_Bills'), 'SOMA_Bills', "B", "SOMA_Bills", notes="çŸ­æœŸå›½å‚µä¿æœ‰é«˜")
        if 'SOMA_Bills' in df.columns and not df.get('SOMA_Bills', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['SOMA_Bills']], height=200)
    
    with col3:
        st.markdown("#### Bills Ratio")
        show_metric_with_sparkline("Bills Ratio", df.get('SomaBillsRatio'), 'SomaBillsRatio', "%", "SomaBillsRatio", notes="çŸ­æœŸå›½å‚µæ§‹æˆæ¯”")
    
    st.markdown("---")
    st.subheader("ğŸš¨ Emergency Loans (Discount Window)")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### Total Loans")
        show_metric_with_sparkline("Total Loans", df.get('Total_Loans'), 'Total_Loans', "B", "Window", notes="ç·Šæ€¥è²¸å‡ºç·é¡")
        if 'Total_Loans' in df.columns and not df.get('Total_Loans', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['Total_Loans']], height=250)
    
    with col2:
        st.markdown("#### Primary Credit")
        show_metric_with_sparkline("Primary Credit", df.get('Primary_Credit'), 'Primary_Credit', "B", "Primary", notes="å¥å…¨è¡Œå‘ã‘", alert_func=lambda x: x>1)
        if 'Primary_Credit' in df.columns and not df.get('Primary_Credit', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['Primary_Credit']], height=250)
    
    st.markdown("---")
    st.subheader("ğŸ¦ Private Banking Sector")
    st.caption("ğŸ’¡ FRBã®æ”¿ç­–ã¨éŠ€è¡Œã®å®Ÿéš›ã®è¡Œå‹•ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’ç›£è¦–")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Bank Cash
        st.markdown("#### Bank Cash Holdings")
        show_metric_with_sparkline("Bank Cash", df.get('Bank_Cash'), 'Bank_Cash', "B", "Bank_Cash", notes="éŠ€è¡Œã®ç¾é‡‘é€€è”µ")
        if 'Bank_Cash' in df.columns and not df.get('Bank_Cash', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['Bank_Cash']], height=200)
    
    with col2:
        # C&I Lending Tightening (formerly Lending Standards)
        st.markdown("#### C&I Lending Tightening")
        st.caption("å•†å·¥æ¥­èè³‡åŸºæº–ã®å³æ ¼åŒ–ï¼ˆç´”å‰²åˆï¼‰")
        # Custom display with +/- sign for Net %
        lending_val = df.get('Lending_Standards')
        if lending_val is not None and not lending_val.isna().all():
            val = lending_val.iloc[-1]
            delta = val - lending_val.iloc[-2] if len(lending_val) > 1 else None
            # Format with explicit sign
            val_str = f"+{val:.1f}" if val >= 0 else f"{val:.1f}"
            st.metric(
                "Net %", 
                f"{val_str} pts",
                delta=f"{delta:+.1f}" if delta is not None else None,
                help=EXPLANATIONS.get('Lending_Standards', '')
            )
            # Show frequency and date
            if hasattr(df, 'attrs') and 'last_valid_dates' in df.attrs:
                if 'Lending_Standards' in df.attrs['last_valid_dates']:
                    latest_date = df.attrs['last_valid_dates']['Lending_Standards']
                    st.caption(f"ğŸ“… {latest_date} (å››åŠæœŸ)")
            
            # Sparkline (60 day trend)
            if 'Lending_Standards' in df.columns:
                recent_data = df['Lending_Standards'].tail(60)
                st.caption("ğŸ“Š éå»60æ—¥é–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰")
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=recent_data.index,
                    y=recent_data.values,
                    mode='lines',
                    line=dict(color='cyan', width=1),
                    fill='tozeroy',
                    fillcolor='rgba(0,255,255,0.1)',
                    showlegend=False
                ))
                fig.update_layout(
                    height=80,
                    margin=dict(l=0, r=0, t=0, b=0),
                    xaxis=dict(visible=False),
                    yaxis=dict(visible=False),
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)',
                    hovermode=False
                )
                st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False}, key=f"spark_lending_{uuid.uuid4().hex[:8]}")
        else:
            st.metric("Net %", "N/A")
        if 'Lending_Standards' in df.columns and not df.get('Lending_Standards', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['Lending_Standards']], height=200)
    
    # ========== SLOOS: C&I Lending Section ==========
    st.markdown("---")
    with st.expander("ğŸ’° C&I Lending (å•†å·¥æ¥­èè³‡) - SLOOS", expanded=False):
        st.caption("ğŸ’¡ èè³‡åŸºæº–ã®å³æ ¼åŒ–ã¨éœ€è¦ã®ä¹–é›¢ã€æ®‹é«˜æ¸›å°‘ã¯ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚¯ãƒ©ãƒ³ãƒã®å‰å…†")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # C&I Standards - Large/Medium Firms
            st.markdown("#### èè³‡åŸºæº–ï¼ˆå¤§ãƒ»ä¸­å …ä¼æ¥­ï¼‰")
            show_metric_with_sparkline("Large/Mid Firms", df.get('CI_Std_Large'), 'CI_Std_Large', "pts", "CI_Std_Large", notes="0è¶…ã§è²¸ã—æ¸‹ã‚Šã€20%è¶…ã§è­¦æˆ’")
            if 'CI_Std_Large' in df.columns and not df.get('CI_Std_Large', pd.Series()).isna().all():
                st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
                st.line_chart(df[['CI_Std_Large']], height=200)
            
            st.markdown("")
            
            # C&I Demand
            st.markdown("#### èè³‡éœ€è¦ï¼ˆå¤§ãƒ»ä¸­å …ä¼æ¥­ï¼‰")
            show_metric_with_sparkline("Demand", df.get('CI_Demand'), 'CI_Demand', "pts", "CI_Demand", notes="åŸºæº–ã¨ã®ä¹–é›¢ã«æ³¨ç›®")
            if 'CI_Demand' in df.columns and not df.get('CI_Demand', pd.Series()).isna().all():
                st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
                st.line_chart(df[['CI_Demand']], height=200)
        
        with col2:
            # C&I Standards - Small Firms
            st.markdown("#### èè³‡åŸºæº–ï¼ˆå°ä¼æ¥­ï¼‰")
            show_metric_with_sparkline("Small Firms", df.get('CI_Std_Small'), 'CI_Std_Small', "pts", "CI_Std_Small", notes="é›‡ç”¨æ‚ªåŒ–ã®å…ˆè¡ŒæŒ‡æ¨™")
            if 'CI_Std_Small' in df.columns and not df.get('CI_Std_Small', pd.Series()).isna().all():
                st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
                st.line_chart(df[['CI_Std_Small']], height=200)
            
            st.markdown("")
            
            # C&I Loan Balance
            st.markdown("#### èè³‡æ®‹é«˜ï¼ˆç·é¡ï¼‰")
            show_metric_with_sparkline("C&I Loans", df.get('CI_Loans'), 'CI_Loans', "B", "CI_Loans", notes="æ®‹é«˜æ¸›å°‘ã§ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚¯ãƒ©ãƒ³ãƒ")
            if 'CI_Loans' in df.columns and not df.get('CI_Loans', pd.Series()).isna().all():
                st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
                st.line_chart(df[['CI_Loans']], height=200)

    
    # ========== SLOOS: CRE Lending Section ==========
    st.markdown("---")
    with st.expander("ğŸ¢ CRE Lending (å•†æ¥­ç”¨ä¸å‹•ç”£èè³‡) - SLOOS", expanded=False):
        st.caption("ğŸ’¡ ä¸å‹•ç”£é–‹ç™ºãƒ»ã‚ªãƒ•ã‚£ã‚¹ã‚¯ãƒ©ã‚¤ã‚·ã‚¹ãƒ»å€Ÿã‚Šæ›ãˆãƒªã‚¹ã‚¯ã‚’ç›£è¦–")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # CRE Standards - Construction
            st.markdown("#### èè³‡åŸºæº–ï¼ˆå»ºè¨­ãƒ»åœŸåœ°é–‹ç™ºï¼‰")
            show_metric_with_sparkline("Construction", df.get('CRE_Std_Construction'), 'CRE_Std_Construction', "pts", "CRE_Std_Construction", notes="ä¸å‹•ç”£é–‹ç™ºã®è›‡å£")
            if 'CRE_Std_Construction' in df.columns and not df.get('CRE_Std_Construction', pd.Series()).isna().all():
                st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
                st.line_chart(df[['CRE_Std_Construction']], height=200)
            
            st.markdown("")
            
            # CRE Standards - Multifamily
            st.markdown("#### èè³‡åŸºæº–ï¼ˆé›†åˆä½å®…ï¼‰")
            show_metric_with_sparkline("Multifamily", df.get('CRE_Std_Multifamily'), 'CRE_Std_Multifamily', "pts", "CRE_Std_Multifamily", notes="ä½å®…ä¾›çµ¦ã«å½±éŸ¿")
            if 'CRE_Std_Multifamily' in df.columns and not df.get('CRE_Std_Multifamily', pd.Series()).isna().all():
                st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
                st.line_chart(df[['CRE_Std_Multifamily']], height=200)
            
            st.markdown("")
            
            # CRE Demand
            st.markdown("#### èè³‡éœ€è¦")
            show_metric_with_sparkline("CRE Demand", df.get('CRE_Demand'), 'CRE_Demand', "pts", "CRE_Demand", notes="ä¸å‹•ç”£æŠ•è³‡æ„æ¬²")
            if 'CRE_Demand' in df.columns and not df.get('CRE_Demand', pd.Series()).isna().all():
                st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
                st.line_chart(df[['CRE_Demand']], height=200)
        
        with col2:
            # CRE Standards - Office
            st.markdown("#### èè³‡åŸºæº–ï¼ˆã‚ªãƒ•ã‚£ã‚¹ç­‰ï¼‰")
            show_metric_with_sparkline("Office/NonRes", df.get('CRE_Std_Office'), 'CRE_Std_Office', "pts", "CRE_Std_Office", notes="ã‚ªãƒ•ã‚£ã‚¹ã‚¯ãƒ©ã‚¤ã‚·ã‚¹è­¦æˆ’")
            if 'CRE_Std_Office' in df.columns and not df.get('CRE_Std_Office', pd.Series()).isna().all():
                st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
                st.line_chart(df[['CRE_Std_Office']], height=200)
            
            st.markdown("")
            
            # CRE Loan Balance (Weekly)
            st.markdown("#### èè³‡æ®‹é«˜ï¼ˆé€±æ¬¡ï¼‰")
            show_metric_with_sparkline("CRE Loans", df.get('CRE_Loans'), 'CRE_Loans', "B", "CRE_Loans", notes="é€±æ¬¡ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–")
            if 'CRE_Loans' in df.columns and not df.get('CRE_Loans', pd.Series()).isna().all():
                st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
                st.line_chart(df[['CRE_Loans']], height=200)
        
        # Loan Balance Comparison Chart
        st.markdown("###### èè³‡æ®‹é«˜ã®æ¨ç§»æ¯”è¼ƒï¼ˆC&I vs CREï¼‰")
        loan_cols = [c for c in ['CI_Loans', 'CRE_Loans'] if c in df.columns and not df[c].isna().all()]
        if loan_cols:
            st.line_chart(df[loan_cols].tail(520), height=200)  # ~2 years
    
    st.markdown("---")
    st.subheader("âš ï¸ Risk & Bonds")
    st.caption("ğŸ’¡ å¸‚å ´ã®ãƒªã‚¹ã‚¯çŠ¶æ…‹ã¨å‚µåˆ¸å¸‚å ´ã®å‹•å‘ã‚’ç›£è¦–")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # VIX Index
        st.markdown("#### VIX Index")
        show_metric_with_sparkline("VIX Index", df.get('VIX'), 'VIX', "pt", "VIX", notes="ææ€–æŒ‡æ•°", alert_func=lambda x: x>20)
        if 'VIX' in df.columns and not df.get('VIX', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['VIX']], height=200)
    
    with col2:
        # Credit Spread
        st.markdown("#### Credit Spread")
        show_metric_with_sparkline("Credit Spread", df.get('Credit_Spread'), 'Credit_Spread', "%", notes="ã‚¸ãƒ£ãƒ³ã‚¯å‚µã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰", decimal_places=3)
        if 'Credit_Spread' in df.columns and not df.get('Credit_Spread', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['Credit_Spread']], height=200)
    
    with col3:
        # US 10Y Yield
        st.markdown("#### US 10Y Yield")
        show_metric_with_sparkline("US 10Y Yield", df.get('US_TNX'), 'US_TNX', "%", notes="é•·æœŸé‡‘åˆ©", decimal_places=3)
        if 'US_TNX' in df.columns and not df.get('US_TNX', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['US_TNX']], height=200)

# Tab 2: Global Money & FX
with tabs[1]:
    st.subheader("ğŸŒ Global Money & FX")
    st.caption("ğŸ’¡ ã‚°ãƒ­ãƒ¼ãƒãƒ«æµå‹•æ€§ã€ç‚ºæ›¿ã€ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£ã€ä»®æƒ³é€šè²¨ã®å‹•å‘")
    
    # --- Global M2 Section ---
    st.markdown("---")
    st.markdown("### ğŸ’µ Global M2 Money Supply")
    st.caption("ğŸ’¡ ä¸–ç•Œã®ä¸»è¦å›½ãƒãƒãƒ¼ã‚µãƒ—ãƒ©ã‚¤å‹•å‘")
    
    # Get exchange rates for USD conversion
    usdjpy = df.get('USDJPY').iloc[-1] if df.get('USDJPY') is not None and len(df.get('USDJPY', pd.Series()).dropna()) > 0 else 157.0
    eurusd = df.get('EURUSD').iloc[-1] if df.get('EURUSD') is not None and len(df.get('EURUSD', pd.Series()).dropna()) > 0 else 1.04
    usdcny = df.get('USDCNY').iloc[-1] if df.get('USDCNY') is not None and len(df.get('USDCNY', pd.Series()).dropna()) > 0 else 7.30
    
    # US & China
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ‡ºğŸ‡¸ US M2")
        show_metric_with_sparkline("US M2 (Nominal)", df.get('M2SL'), 'M2SL', "T", notes="åç›®")
        show_metric_with_sparkline("US M2 (Real)", df.get('M2REAL'), 'M2REAL', "T", notes="å®Ÿè³ª(1982-84åŸºæº–)")
        if 'M2SL' in df.columns and not df.get('M2SL', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['M2SL']].dropna(), height=150)
    
    with col2:
        st.markdown("#### ğŸ‡¨ğŸ‡³ China M2")
        cn_m2_val = df.get('CN_M2').iloc[-1] if df.get('CN_M2') is not None else 313.5
        cn_m2_usd = cn_m2_val / usdcny  # Trillion CNY to Trillion USD
        show_metric_with_sparkline("CN M2 (Nominal)", df.get('CN_M2'), 'CN_M2', "T CNY", notes="åç›®")
        st.markdown(f"**ğŸ’µ â‰ˆ ${cn_m2_usd:.1f}T USD** (1 USD = {usdcny:.2f} CNY)")
        cn_cpi = df.get('CN_CPI').iloc[-1] if df.get('CN_CPI') is not None and len(df.get('CN_CPI', pd.Series()).dropna()) > 0 else 0.7
        cn_m2_real_val = df.get('CN_M2_Real').iloc[-1] if df.get('CN_M2_Real') is not None else cn_m2_val / (1 + cn_cpi/100)
        cn_m2_real_usd = cn_m2_real_val / usdcny
        show_metric_with_sparkline("CN M2 (Real)", df.get('CN_M2_Real'), 'CN_M2_Real', "T CNY", notes=f"CPI {cn_cpi}%èª¿æ•´")
        st.markdown(f"**ğŸ’µ â‰ˆ ${cn_m2_real_usd:.1f}T USD**")
        if 'CN_M2' in df.columns and not df.get('CN_M2', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['CN_M2']].dropna(), height=150)
        
        # China Credit Impulse (Proxy)
        st.markdown("---")
        st.markdown("##### ğŸ“Š Credit Impulseï¼ˆä¿¡ç”¨åˆºæ¿€æŒ‡æ•°ï¼‰")
        st.caption("âš ï¸ ä»£ç”¨è¨ˆç®—: BISçµŒç”±FREDå››åŠæœŸä¿¡ç”¨æ®‹é«˜ãƒ‡ãƒ¼ã‚¿(CRDQCNAPABIS)ä½¿ç”¨")
        
        show_metric_with_sparkline(
            "Credit Impulse", 
            df.get('CN_Credit_Impulse'), 
            'CN_Credit_Impulse', 
            "%", 
            notes="(ä¿¡ç”¨ãƒ•ãƒ­ãƒ¼å¤‰åŒ–/GDP)"
        )
        if 'CN_Credit_Impulse' in df.columns and not df.get('CN_Credit_Impulse', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»5å¹´é–“)")
            st.line_chart(df[['CN_Credit_Impulse']].dropna(), height=150)
    
    # Japan & Euro
    col3, col4 = st.columns(2)
    
    with col3:
        st.markdown("#### ğŸ‡¯ğŸ‡µ Japan M2")
        jp_m2_val = df.get('JP_M2').iloc[-1] if df.get('JP_M2') is not None else 1260.0
        jp_m2_usd = jp_m2_val / usdjpy * 1000  # Trillion JPY to Billion USD (1T JPY = 1000B JPY / USDJPY)
        show_metric_with_sparkline("JP M2 (Nominal)", df.get('JP_M2'), 'JP_M2', "T JPY", notes="åç›®")
        st.markdown(f"**ğŸ’µ â‰ˆ ${jp_m2_usd/1000:.1f}T USD** (1 USD = {usdjpy:.1f} JPY)")
        jp_cpi = df.get('JP_CPI').iloc[-1] if df.get('JP_CPI') is not None and len(df.get('JP_CPI', pd.Series()).dropna()) > 0 else 2.9
        jp_m2_real_val = df.get('JP_M2_Real').iloc[-1] if df.get('JP_M2_Real') is not None else jp_m2_val / (1 + jp_cpi/100)
        jp_m2_real_usd = jp_m2_real_val / usdjpy * 1000
        show_metric_with_sparkline("JP M2 (Real)", df.get('JP_M2_Real'), 'JP_M2_Real', "T JPY", notes=f"CPI {jp_cpi}%èª¿æ•´")
        st.markdown(f"**ğŸ’µ â‰ˆ ${jp_m2_real_usd/1000:.1f}T USD**")
        if 'JP_M2' in df.columns and not df.get('JP_M2', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['JP_M2']].dropna(), height=150)
    
    with col4:
        st.markdown("#### ğŸ‡ªğŸ‡º Euro M2")
        eu_m2_val = df.get('EU_M2').iloc[-1] if df.get('EU_M2') is not None else 15.6
        eu_m2_usd = eu_m2_val * eurusd  # Trillion EUR to Trillion USD
        show_metric_with_sparkline("EU M2 (Nominal)", df.get('EU_M2'), 'EU_M2', "T EUR", notes="åç›®")
        st.markdown(f"**ğŸ’µ â‰ˆ ${eu_m2_usd:.1f}T USD** (1 EUR = {eurusd:.2f} USD)")
        eu_cpi = df.get('EU_CPI').iloc[-1] if df.get('EU_CPI') is not None and len(df.get('EU_CPI', pd.Series()).dropna()) > 0 else 2.1
        eu_m2_real_val = df.get('EU_M2_Real').iloc[-1] if df.get('EU_M2_Real') is not None else eu_m2_val / (1 + eu_cpi/100)
        eu_m2_real_usd = eu_m2_real_val * eurusd
        show_metric_with_sparkline("EU M2 (Real)", df.get('EU_M2_Real'), 'EU_M2_Real', "T EUR", notes=f"CPI {eu_cpi}%èª¿æ•´")
        st.markdown(f"**ğŸ’µ â‰ˆ ${eu_m2_real_usd:.1f}T USD**")
        if 'EU_M2' in df.columns and not df.get('EU_M2', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['EU_M2']].dropna(), height=150)
    
    # --- FX Section ---
    st.markdown("---")
    st.markdown("### ğŸ’± Foreign Exchange")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("#### DXY")
        show_metric_with_sparkline("Dollar Index", df.get('DXY'), 'DXY', "pt", notes="ãƒ‰ãƒ«å¼·å¼±æŒ‡æ•°", decimal_places=3)
        if 'DXY' in df.columns and not df.get('DXY', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend")
            st.line_chart(df[['DXY']], height=150)
    
    with col2:
        st.markdown("#### USD/JPY")
        show_metric_with_sparkline("USD/JPY", df.get('USDJPY'), 'USDJPY', "Â¥", notes="å††ã‚­ãƒ£ãƒªãƒ¼", decimal_places=3)
        if 'USDJPY' in df.columns and not df.get('USDJPY', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend")
            st.line_chart(df[['USDJPY']], height=150)
    
    with col3:
        st.markdown("#### EUR/USD")
        show_metric_with_sparkline("EUR/USD", df.get('EURUSD'), 'EURUSD', "$", notes="ãƒ¦ãƒ¼ãƒ­ãƒ‰ãƒ«", decimal_places=3)
        if 'EURUSD' in df.columns and not df.get('EURUSD', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend")
            st.line_chart(df[['EURUSD']], height=150)
    
    with col4:
        st.markdown("#### USD/CNY")
        show_metric_with_sparkline("USD/CNY", df.get('USDCNY'), 'USDCNY', "CNY", notes="äººæ°‘å…ƒ", decimal_places=3)
        if 'USDCNY' in df.columns and not df.get('USDCNY', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend")
            st.line_chart(df[['USDCNY']], height=150)
    
    # --- Commodities Section ---
    st.markdown("---")
    st.markdown("### ğŸ›¢ï¸ Commodities")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("#### Gold")
        show_metric_with_sparkline("Gold", df.get('Gold'), 'Gold', "$", notes="é‡‘å…ˆç‰©", decimal_places=3)
        if 'Gold' in df.columns and not df.get('Gold', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend")
            st.line_chart(df[['Gold']], height=150)
    
    with col2:
        st.markdown("#### Silver")
        show_metric_with_sparkline("Silver", df.get('Silver'), 'Silver', "$", notes="éŠ€å…ˆç‰©", decimal_places=3)
        if 'Silver' in df.columns and not df.get('Silver', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend")
            st.line_chart(df[['Silver']], height=150)
    
    with col3:
        st.markdown("#### Oil (WTI)")
        show_metric_with_sparkline("Oil", df.get('Oil'), 'Oil', "$", notes="åŸæ²¹å…ˆç‰©", decimal_places=3)
        if 'Oil' in df.columns and not df.get('Oil', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend")
            st.line_chart(df[['Oil']], height=150)
    
    with col4:
        st.markdown("#### Copper")
        show_metric_with_sparkline("Copper", df.get('Copper'), 'Copper', "$", notes="éŠ…å…ˆç‰©ï¼ˆæ™¯æ°—å…ˆè¡ŒæŒ‡æ¨™ï¼‰", decimal_places=3)
        if 'Copper' in df.columns and not df.get('Copper', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend")
            st.line_chart(df[['Copper']], height=150)
    
    # --- Crypto Section ---
    st.markdown("---")
    st.markdown("### ğŸª™ Cryptocurrency")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### Bitcoin (BTC)")
        show_metric_with_sparkline("BTC", df.get('BTC'), 'BTC', "$", notes="ãƒªã‚¹ã‚¯ã‚ªãƒ³æŒ‡æ¨™", decimal_places=3)
        if 'BTC' in df.columns and not df.get('BTC', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['BTC']], height=200)
    
    with col2:
        st.markdown("#### Ethereum (ETH)")
        show_metric_with_sparkline("ETH", df.get('ETH'), 'ETH', "$", notes="DeFiåŸºç›¤", decimal_places=3)
        if 'ETH' in df.columns and not df.get('ETH', pd.Series()).isna().all():
            st.markdown("###### Long-term Trend (éå»2å¹´é–“)")
            st.line_chart(df[['ETH']], height=200)

# Tab 3: US Economic Data
with tabs[2]:
    st.subheader("ğŸ‡ºğŸ‡¸ US Economic Data")
    st.caption("ğŸ’¡ æ™¯æ°—å¾ªç’°ã€ç‰©ä¾¡ã€é›‡ç”¨ã®å¤šè§’çš„ãªåˆ†æ")
    
    # === FOMC SEP (Dot Plot) Section ===
    st.markdown("### ğŸ›ï¸ FOMC Economic Projections (SEP)")
    st.caption("ğŸ“Š FOMCãƒ¡ãƒ³ãƒãƒ¼ã«ã‚ˆã‚‹çµŒæ¸ˆè¦‹é€šã—ï¼ˆãƒ‰ãƒƒãƒˆãƒ—ãƒ­ãƒƒãƒˆï¼‰ - å››åŠæœŸæ›´æ–°")
    
    # Fetch FOMC data
    fomc_sep = get_fomc_sep_projections()
    fedwatch = get_cme_fedwatch()
    
    col_fomc1, col_fomc2 = st.columns([2, 1])
    
    with col_fomc1:
        if fomc_sep:
            # Display cards for each projection
            proj_cols = st.columns(4)
            
            with proj_cols[0]:
                if fomc_sep.get('ff_rate'):
                    ff = fomc_sep['ff_rate']
                    change = ff['latest'] - ff['previous'] if ff['previous'] else 0
                    st.metric("FFé‡‘åˆ©äºˆæ¸¬ (ä¸­å¤®å€¤)", f"{ff['latest']:.2f}%", 
                             delta=f"{change:+.2f}%", delta_color="inverse")
                    st.caption(f"ğŸ”„ æ›´æ–°: {ff['date']}")
                else:
                    st.metric("FFé‡‘åˆ©äºˆæ¸¬", "N/A")
            
            with proj_cols[1]:
                if fomc_sep.get('gdp_growth'):
                    gdp = fomc_sep['gdp_growth']
                    st.metric("GDPæˆé•·ç‡äºˆæ¸¬", f"{gdp['latest']:.1f}%")
                else:
                    st.metric("GDPæˆé•·ç‡äºˆæ¸¬", "N/A")
            
            with proj_cols[2]:
                if fomc_sep.get('unemployment'):
                    unemp = fomc_sep['unemployment']
                    st.metric("å¤±æ¥­ç‡äºˆæ¸¬", f"{unemp['latest']:.1f}%")
                else:
                    st.metric("å¤±æ¥­ç‡äºˆæ¸¬", "N/A")
            
            with proj_cols[3]:
                if fomc_sep.get('core_pce'):
                    pce = fomc_sep['core_pce']
                    st.metric("Core PCEäºˆæ¸¬", f"{pce['latest']:.1f}%")
                else:
                    st.metric("Core PCEäºˆæ¸¬", "N/A")
        else:
            st.info("ğŸ“ FOMC SEPãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    
    with col_fomc2:
        st.markdown("#### ğŸ“ˆ CME FedWatch")
        if fedwatch:
            probs = fedwatch['probabilities']
            
            # Main probability (cut)
            cut_prob = probs.get('cut_25bp', 0) + probs.get('cut_50bp', 0)
            if cut_prob >= 50:
                prob_emoji = "ğŸ“‰"
                prob_label = "åˆ©ä¸‹ã’å„ªå‹¢"
            elif probs.get('hold', 0) >= 50:
                prob_emoji = "â¡ï¸"
                prob_label = "æ®ãˆç½®ãå„ªå‹¢"
            else:
                prob_emoji = "ğŸ“ˆ"
                prob_label = "åˆ©ä¸Šã’å„ªå‹¢"
            
            st.metric(f"{prob_emoji} æ¬¡å›ä¼šåˆäºˆæƒ³", prob_label)
            st.caption(f"ğŸ“… {fedwatch['next_meeting']}")
            
            # Probability breakdown
            st.markdown("**ç¢ºç‡åˆ†å¸ƒ:**")
            st.caption(f"ğŸ”» åˆ©ä¸‹ã’: {cut_prob:.0f}%")
            st.caption(f"â¡ï¸ æ®ç½®: {probs.get('hold', 0):.0f}%")
            st.caption(f"ğŸ”º åˆ©ä¸Šã’: {probs.get('hike_25bp', 0):.0f}%")
            
            if fedwatch.get('note'):
                st.caption(f"ğŸ“ {fedwatch['note']}")
        else:
            st.info("ğŸ“ CME FedWatchãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­...")
    
    st.markdown("---")
    
    # helper for MoM/YoY - IMPORTANT: Use df_original for accurate calculations!
    def get_mom_yoy(df_column, freq='M'):
        """Calculate MoM% and YoY% using ORIGINAL (pre-ffill) data for accuracy"""
        # Use df_original (global) which has actual monthly data points, not ffill data
        series = df_original.get(df_column)
        if series is None or len(series.dropna()) < 2:
            return None, None
        s = series.dropna()
        curr = s.iloc[-1]
        prev = s.iloc[-2]
        mom = (curr / prev - 1) * 100 if prev != 0 else 0
        
        # YoY: Monthly=12, Quarterly=4
        offset = 12 if freq == 'M' else 4
        yoy = None
        if len(s) > offset:
            prev_yr = s.iloc[-(offset+1)]
            yoy = (curr / prev_yr - 1) * 100 if prev_yr != 0 else 0
        return mom, yoy

    # helper to wrap indicators for better organization and consistency across the tab
    def display_macro_card(title, series, df_column, unit="", notes="", freq='M', show_level=True):
        """Display macro indicator card with MoM, YoY, sparkline and long-term chart
        
        Args:
            show_level: If False, skip the sparkline/level display (for NFP where only change matters)
        """
        st.markdown(f"#### {title}")
        mom, yoy = get_mom_yoy(df_column, freq=freq)  # Use df_column, not series
        
        # 1. Metrics Row (MoM, YoY)
        m_col1, m_col2 = st.columns(2)
        if mom is not None:
            m_col1.metric("å‰æœˆæ¯”", f"{mom:+.1f}%")
        if yoy is not None:
            m_col2.metric("å‰å¹´æ¯”", f"{yoy:+.1f}%")
        
        # 2. Main Metric with Sparkline & Update Date (optional)
        if show_level:
            show_metric_with_sparkline(title, series, df_column, unit, notes=notes)
        
        # 3. YoY% Trend Chart (NEW - easier to see changes over time)
        # Use original data for accurate YoY calculation
        original_series = df_original.get(df_column)
        if original_series is not None and len(original_series.dropna()) > 12:
            data = original_series.dropna()
            yoy_series = (data / data.shift(12) - 1) * 100
            yoy_series = yoy_series.dropna()
            if len(yoy_series) > 0:
                st.markdown(f"###### {title} YoY% (å‰å¹´æ¯”å¤‰åŒ–ç‡)")
                st.line_chart(yoy_series, height=120)
        
        # 4. Dedicated Long-term Chart (Level)
        if series is not None and not series.isna().all():
            st.markdown(f"###### {title} Long-term Trend (Level)")
            st.line_chart(series, height=150)


    # --- 1ï¸âƒ£ Monetary Policy (é‡‘èæ”¿ç­–) ---
    st.markdown("---")
    st.markdown("### ğŸ›ï¸ 1. Monetary Policy (é‡‘èæ”¿ç­–)")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### FF Target Rate (Upper)")
        show_metric_with_sparkline("FF Upper", df.get('FedFundsUpper'), 'FedFundsUpper', "%", notes="æ”¿ç­–é‡‘åˆ©ä¸Šé™", decimal_places=3)
        if 'FedFundsUpper' in df.columns:
            st.line_chart(df[['FedFundsUpper']], height=120)
            
    with col2:
        st.markdown("#### EFFR")
        show_metric_with_sparkline("EFFR", df.get('EFFR'), 'EFFR', "%", notes="å®ŸåŠ¹FFé‡‘åˆ©", decimal_places=3)
        if 'EFFR' in df.columns:
            st.line_chart(df[['EFFR']], height=120)
            
    with col3:
        st.markdown("#### SOFR")
        show_metric_with_sparkline("SOFR", df.get('SOFR'), 'SOFR', "%", notes="æ‹…ä¿ä»˜é‡‘åˆ©(ãƒ¬ãƒå¸‚å ´)", decimal_places=3)
        if 'SOFR' in df.columns:
            st.line_chart(df[['SOFR']], height=120)

    # --- 2ï¸âƒ£ Employment (é›‡ç”¨é–¢é€£) ---
    st.markdown("---")
    st.markdown("### ğŸ‘· 2. Employment (é›‡ç”¨é–¢é€£)")
    col1, col2 = st.columns(2)
    
    with col1:
        # NFP: éè¾²æ¥­éƒ¨é–€é›‡ç”¨è€…æ•°ãƒ»å‰æœˆæ¯” + çŸ­æœŸ/é•·æœŸãƒãƒ£ãƒ¼ãƒˆï¼ˆLevelè¡¨ç¤ºã¯ä¸è¦ï¼‰
        st.markdown("#### éè¾²æ¥­éƒ¨é–€é›‡ç”¨è€…æ•°ï¼ˆNFPï¼‰å‰æœˆæ¯”")
        # Get original data for change calculation (df_original is global from get_market_data)
        nfp_original = df_original.get('NFP')
        nfp_series = df.get('NFP')  # ffilled series for display
        
        if nfp_original is not None and len(nfp_original.dropna()) >= 2:
            nfp_data = nfp_original.dropna()
            nfp_curr = nfp_data.iloc[-1]
            nfp_prev = nfp_data.iloc[-2]
            nfp_change = nfp_curr - nfp_prev  # Absolute change in thousands
            # Display the monthly change as the main metric (no delta)
            st.metric("çµæœ", f"{nfp_change:+,.0f}Kï¼ˆ{nfp_change/10:+,.1f}ä¸‡äººï¼‰")
            # æä¾›å…ƒæ›´æ–°æ—¥ã‚’è¡¨ç¤º
            if hasattr(df, 'attrs'):
                if 'last_valid_dates' in df.attrs and 'NFP' in df.attrs['last_valid_dates']:
                    st.caption(f"ğŸ“… å¯¾è±¡æœŸé–“: {df.attrs['last_valid_dates']['NFP']} (æœˆæ¬¡)")
                if 'fred_release_dates' in df.attrs and 'NFP' in df.attrs['fred_release_dates']:
                    st.caption(f"ğŸ”„ æä¾›å…ƒæ›´æ–°æ—¥: {df.attrs['fred_release_dates']['NFP']}")
        
        # Long-term trend chart - show MONTHLY CHANGES, not total level
        if nfp_original is not None and len(nfp_original.dropna()) >= 2:
            nfp_changes = nfp_original.dropna().diff().dropna()  # Calculate monthly changes
            if len(nfp_changes) > 0:
                st.markdown("###### NFP æœˆæ¬¡å¢—æ¸›ã®æ¨ç§»")
                st.line_chart(nfp_changes, height=150)
        
        # ADP Employment (å…ˆè¡ŒæŒ‡æ¨™)
        # æ³¨æ„: ADPWNUSNERSA ã¯ã€ŒPersonsã€å˜ä½ã®ãŸã‚ã€1000ã§å‰²ã£ã¦ã€ŒKã€å˜ä½ã«å¤‰æ›
        st.markdown("---")
        st.markdown("#### ADP Employment (æ°‘é–“é›‡ç”¨)")
        # Get original data for change calculation (df_original is global)
        adp_original = df_original.get('ADP')
        adp_series_raw = df.get('ADP')  # ffilled series for display
        
        if adp_original is not None and len(adp_original.dropna()) >= 2:
            # Use original data for change calculation, convert Persons to Thousands
            adp_data = adp_original.dropna() / 1000
            adp_series = adp_series_raw / 1000  # for display
            adp_curr = adp_data.iloc[-1]
            adp_prev = adp_data.iloc[-2]
            adp_change = adp_curr - adp_prev
            if abs(adp_change) >= 1:
                st.metric("æœˆæ¬¡å¢—æ¸› (æ°‘é–“)", f"{adp_change:+,.0f}K", delta=f"åˆè¨ˆ: {adp_curr:,.0f}K", delta_color="off")
            else:
                st.metric("æœˆæ¬¡å¢—æ¸› (æ°‘é–“)", f"{adp_change:+,.1f}K", delta=f"åˆè¨ˆ: {adp_curr:,.0f}K", delta_color="off")
            # ADPã«sparklineã¨é•·æœŸãƒãƒ£ãƒ¼ãƒˆã‚’è¿½åŠ 
            show_metric_with_sparkline("ADP Level", adp_series, 'ADP', "K", notes="æ°‘é–“é›‡ç”¨è€…æ•°åˆè¨ˆ")
            
            # ADP Monthly Change Chart (similar to NFP)
            adp_changes = adp_data.diff().dropna()  # Calculate monthly changes
            if len(adp_changes) > 0:
                st.markdown("###### ADP æœˆæ¬¡å¢—æ¸›ã®æ¨ç§»")
                st.line_chart(adp_changes, height=150)
            
            st.markdown("###### ADP Long-term Trend")
            st.line_chart(adp_series, height=150)
        elif adp_original is not None and len(adp_original.dropna()) >= 1:
            adp_series = adp_series_raw / 1000
            st.caption("âš ï¸ ADPãƒ‡ãƒ¼ã‚¿ãŒ1ä»¶ã®ã¿ã§ã™")
            show_metric_with_sparkline("ADP Level", adp_series, 'ADP', "K", notes="æ°‘é–“é›‡ç”¨è€…æ•°åˆè¨ˆ")
        else:
            st.caption("âš ï¸ ADPãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        st.caption("ğŸ“Š NFPã®2æ—¥å‰ã«ç™ºè¡¨ã•ã‚Œã‚‹å…ˆè¡ŒæŒ‡æ¨™")
        st.markdown("---")
        # Unemployment Rate: Use original data for change calculation
        st.markdown("#### Unemployment Rate")
        unemp_original = df_original.get('UNRATE')  # df_original is global
        unemp_series = df.get('UNRATE')
        
        if unemp_original is not None and len(unemp_original.dropna()) >= 2:
            unemp_data = unemp_original.dropna()
            unemp_curr = unemp_data.iloc[-1]
            unemp_prev = unemp_data.iloc[-2]
            unemp_change = unemp_curr - unemp_prev  # Point change
            st.metric("å¤±æ¥­ç‡", f"{unemp_curr:.1f}%", delta=f"{unemp_change:+.1f}pp vså…ˆæœˆ")
            # æ—¥ä»˜æƒ…å ±ã¨æä¾›å…ƒæ›´æ–°æ—¥ã‚’è¡¨ç¤º
            if hasattr(df, 'attrs'):
                if 'last_valid_dates' in df.attrs and 'UNRATE' in df.attrs['last_valid_dates']:
                    st.caption(f"ğŸ“… å¯¾è±¡æœŸé–“: {df.attrs['last_valid_dates']['UNRATE']} (æœˆæ¬¡)")
                if 'fred_release_dates' in df.attrs and 'UNRATE' in df.attrs['fred_release_dates']:
                    st.caption(f"ğŸ”„ æä¾›å…ƒæ›´æ–°æ—¥: {df.attrs['fred_release_dates']['UNRATE']}")
            # Only show sparkline (not duplicate metric)
            if 'UNRATE' in df.columns:
                recent_data = df['UNRATE'].tail(60)
                st.caption("ğŸ“Š éå»60æ—¥é–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰")
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=recent_data.index,
                    y=recent_data.values,
                    mode='lines',
                    line=dict(color='cyan', width=1),
                    fill='tozeroy',
                    fillcolor='rgba(0,255,255,0.1)',
                    showlegend=False
                ))
                fig.update_layout(
                    height=80,
                    margin=dict(l=0, r=0, t=0, b=0),
                    xaxis=dict(visible=False),
                    yaxis=dict(visible=False),
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)',
                    hovermode=False
                )
                st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False}, key=f"spark_unemp_{uuid.uuid4().hex[:8]}")
            st.caption("ã‚µãƒ¼ãƒ ãƒ»ãƒ«ãƒ¼ãƒ«æ³¨è¦–æŒ‡æ¨™")
        if unemp_series is not None and not unemp_series.isna().all():
            st.markdown("###### Unemployment Long-term Trend")
            st.line_chart(unemp_series, height=150)
        
    with col2:
        # Average Hourly Earnings - show MoM/YoY results and YoY% trend chart
        st.markdown("#### å¹³å‡æ™‚çµ¦")
        ahe_original = df_original.get('AvgHourlyEarnings')
        ahe_series = df.get('AvgHourlyEarnings')
        
        if ahe_original is not None and len(ahe_original.dropna()) >= 2:
            ahe_data = ahe_original.dropna()
            ahe_curr = ahe_data.iloc[-1]
            ahe_prev = ahe_data.iloc[-2]
            mom = (ahe_curr / ahe_prev - 1) * 100
            
            # YoY calculation (12 months back)
            yoy = None
            if len(ahe_data) > 12:
                ahe_prev_yr = ahe_data.iloc[-13]
                yoy = (ahe_curr / ahe_prev_yr - 1) * 100
            
            # Display MoM and YoY results
            m_col1, m_col2 = st.columns(2)
            m_col1.metric("å‰æœˆæ¯”", f"{mom:+.1f}%")
            if yoy is not None:
                m_col2.metric("å‰å¹´æ¯”", f"{yoy:+.1f}%")
            
            # æä¾›å…ƒæ›´æ–°æ—¥ã‚’è¡¨ç¤º
            if hasattr(df, 'attrs'):
                if 'last_valid_dates' in df.attrs and 'AvgHourlyEarnings' in df.attrs['last_valid_dates']:
                    st.caption(f"ğŸ“… å¯¾è±¡æœŸé–“: {df.attrs['last_valid_dates']['AvgHourlyEarnings']} (æœˆæ¬¡)")
                if 'fred_release_dates' in df.attrs and 'AvgHourlyEarnings' in df.attrs['fred_release_dates']:
                    st.caption(f"ğŸ”„ æä¾›å…ƒæ›´æ–°æ—¥: {df.attrs['fred_release_dates']['AvgHourlyEarnings']}")
            
            # Chart 1: MoM% trend (calculate rolling MoM for each month)
            mom_series = (ahe_data / ahe_data.shift(1) - 1) * 100
            mom_series = mom_series.dropna()
            if len(mom_series) > 0:
                st.markdown("###### å‰æœˆæ¯”%ã®æ¨ç§»")
                st.line_chart(mom_series, height=120)
            
            # Chart 2: YoY% trend (calculate rolling YoY for each month)
            if len(ahe_data) > 12:
                yoy_series = (ahe_data / ahe_data.shift(12) - 1) * 100
                yoy_series = yoy_series.dropna()
                if len(yoy_series) > 0:
                    st.markdown("###### å‰å¹´æ¯”%ã®æ¨ç§»")
                    st.line_chart(yoy_series, height=120)
            
            # Chart 3: Level ($/hr) trend
            st.markdown("###### å¹³å‡æ™‚çµ¦ï¼ˆ$/hrï¼‰ã®æ¨ç§»")
            st.line_chart(ahe_data, height=120)
        
        st.markdown("---")
        # JOLTS: Removed monthly change per user request
        st.markdown("#### JOLTS Job Openings")
        jolts_series = df.get('JOLTS')
        show_metric_with_sparkline("JOLTS Level", jolts_series, 'JOLTS', "K", notes="åŠ´åƒéœ€è¦ã®å…ˆè¡ŒæŒ‡æ¨™")
        if jolts_series is not None and not jolts_series.isna().all():
            st.markdown("###### JOLTS Long-term Trend")
            st.line_chart(jolts_series, height=150)
        
        # --- ICSA: Initial Jobless Claims (æ–°è¦å¤±æ¥­ä¿é™ºç”³è«‹ä»¶æ•°) ---
        st.markdown("---")
        st.markdown("#### æ–°è¦å¤±æ¥­ä¿é™ºç”³è«‹ä»¶æ•° (ICSA)")
        icsa_series = df.get('ICSA')
        if icsa_series is not None and len(icsa_series.dropna()) >= 2:
            # ICSA is in Persons, convert to Thousands for display
            icsa_data = icsa_series.dropna() / 1000  # Persons -> Thousands
            icsa_curr = icsa_data.iloc[-1]
            icsa_prev = icsa_data.iloc[-2]
            icsa_change = icsa_curr - icsa_prev
            
            # Display current value and weekly change
            st.metric("æœ€æ–°é€±", f"{icsa_curr:,.0f}K", delta=f"{icsa_change:+,.0f}K vså‰é€±", delta_color="inverse")
            
            # æä¾›å…ƒæ›´æ–°æ—¥ã‚’è¡¨ç¤º
            if hasattr(df, 'attrs'):
                if 'last_valid_dates' in df.attrs and 'ICSA' in df.attrs['last_valid_dates']:
                    st.caption(f"ğŸ“… å¯¾è±¡æœŸé–“: {df.attrs['last_valid_dates']['ICSA']} (é€±æ¬¡)")
                if 'fred_release_dates' in df.attrs and 'ICSA' in df.attrs['fred_release_dates']:
                    st.caption(f"ğŸ”„ æä¾›å…ƒæ›´æ–°æ—¥: {df.attrs['fred_release_dates']['ICSA']}")
            
            # Sparkline (past 60 data points)
            st.caption("ğŸ“Š éå»60é€±ã®ãƒˆãƒ¬ãƒ³ãƒ‰")
            recent_icsa = icsa_data.tail(60)
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=recent_icsa.index,
                y=recent_icsa.values,
                mode='lines',
                line=dict(color='orange', width=1),
                fill='tozeroy',
                fillcolor='rgba(255,165,0,0.1)',
                showlegend=False
            ))
            fig.update_layout(
                height=80,
                margin=dict(l=0, r=0, t=0, b=0),
                xaxis=dict(visible=False),
                yaxis=dict(visible=False),
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                hovermode=False
            )
            st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False}, key=f"spark_icsa_{uuid.uuid4().hex[:8]}")
            st.caption("ğŸ“‹ é€±æ¬¡ç™ºè¡¨ï¼ˆæ¯é€±æœ¨æ›œï¼‰ã€‚å¢—åŠ ã¯è§£é›‡å¢—ã€æ¸›å°‘ã¯é›‡ç”¨å®‰å®šã€‚")
        elif icsa_series is not None and len(icsa_series.dropna()) >= 1:
            icsa_data = icsa_series.dropna() / 1000
            st.metric("æœ€æ–°é€±", f"{icsa_data.iloc[-1]:,.0f}K")
            st.caption("âš ï¸ å‰é€±ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        else:
            st.caption("âš ï¸ ICSAãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        
        # Long-term chart
        if icsa_series is not None and not icsa_series.isna().all():
            icsa_display = icsa_series / 1000  # Convert to Thousands for chart
            st.markdown("###### ICSA Long-term Trend (K)")
            st.line_chart(icsa_display, height=150)

    # --- 3ï¸âƒ£ Inflation (ç‰©ä¾¡ãƒ»ã‚¤ãƒ³ãƒ•ãƒ¬) ---
    st.markdown("---")
    st.markdown("### âš–ï¸ 3. Inflation (ç‰©ä¾¡ãƒ»ã‚¤ãƒ³ãƒ•ãƒ¬)")
    col1, col2 = st.columns(2)
    
    with col1:
        display_macro_card("Consumer Price Index (CPI)", df.get('CPI'), 'CPI', notes="æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•°")
        st.markdown("---")
        # Core PCE: Already YoY% - don't calculate MoM/YoY again
        st.markdown("#### Core PCE Inflation (YoY)")
        pce_series = df.get('CorePCE')
        if pce_series is not None and len(pce_series.dropna()) >= 2:
            pce_curr = pce_series.dropna().iloc[-1]
            pce_prev = pce_series.dropna().iloc[-2]
            pce_change = pce_curr - pce_prev  # Change in percentage points
            st.metric("ç¾åœ¨ã®ã‚¤ãƒ³ãƒ•ãƒ¬ç‡", f"{pce_curr:.2f}%", delta=f"{pce_change:+.2f}pp vså…ˆæœˆ")
        show_metric_with_sparkline("Core PCE", pce_series, 'CorePCE', "%", notes="FRBæœ€é‡è¦è¦–æŒ‡æ¨™ï¼ˆãƒ€ãƒ©ã‚¹é€£éŠ€ãƒˆãƒªãƒ å¹³å‡ï¼‰")
        if pce_series is not None and not pce_series.isna().all():
            st.markdown("###### Core PCE Long-term Trend")
            st.line_chart(pce_series, height=150)
            
    with col2:
        display_macro_card("Core CPI", df.get('CPICore'), 'CPICore', notes="é£Ÿå“ãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼é™¤ã")
        st.markdown("---")
        display_macro_card("Producer Price Index (PPI)", df.get('PPI'), 'PPI', notes="å¸å£²ç‰©ä¾¡æŒ‡æ•°")

    # --- 4ï¸âƒ£ Economy (æ™¯æ°—ãƒ»å…ˆè¡ŒæŒ‡æ¨™) ---
    st.markdown("---")
    st.markdown("### ğŸ“ˆ 4. Economy (æ™¯æ°—ãƒ»å…ˆè¡ŒæŒ‡æ¨™)")
    col1, col2 = st.columns(2)
    
    with col1:
        display_macro_card("Retail Sales", df.get('RetailSales'), 'RetailSales', unit="$M", notes="å€‹äººæ¶ˆè²»ã®å‹•å‘")
        st.markdown("---")
        display_macro_card("Consumer Sentiment", df.get('ConsumerSent'), 'ConsumerSent', unit="pt", notes="ãƒŸã‚·ã‚¬ãƒ³å¤§å­¦èª¿æŸ»")

    with col2:
        # Real GDP: Show annualized growth rate (not just level or simple %)
        st.markdown("#### Real GDP (Annualized Growth)")
        gdp_series = df.get('RealGDP')
        if gdp_series is not None and len(gdp_series.dropna()) >= 2:
            gdp_data = gdp_series.dropna()
            gdp_curr = gdp_data.iloc[-1]
            gdp_prev = gdp_data.iloc[-2]
            qoq_pct = (gdp_curr / gdp_prev - 1)  # Quarterly growth rate (decimal)
            annualized = ((1 + qoq_pct) ** 4 - 1) * 100  # Annualized (%)
            st.metric("å‰æœŸæ¯”å¹´ç‡", f"{annualized:+.1f}%", delta=f"æ°´æº–: ${gdp_curr:,.0f}B", delta_color="off")
        show_metric_with_sparkline("GDP Level", gdp_series, 'RealGDP', "$B", notes="å®Ÿè³ªGDP (2017å¹´åŸºæº–)")
        if gdp_series is not None and not gdp_series.isna().all():
            st.markdown("###### Real GDP Long-term Trend")
            st.line_chart(gdp_series, height=150)
        st.markdown("---")
        st.markdown("#### ğŸ”— Yield Curve (2Y-10Y)")
        show_metric_with_sparkline("2Y-10Y Spread", df.get('T10Y2Y'), 'T10Y2Y', "%", notes="æ™¯æ°—å¾Œé€€ã®å…ˆè¡ŒæŒ‡æ¨™")
        if 'T10Y2Y' in df.columns:
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=df.index, y=df['T10Y2Y'], name='2Y-10Y Spread', line=dict(color='cyan')))
            fig.add_hline(y=0, line_dash='dash', line_color='red', annotation_text="é€†ã‚¤ãƒ¼ãƒ«ãƒ‰å¢ƒç•Œ")
            st.plotly_chart(fig, use_container_width=True, key="macro_yield_chart")


# Tab 4: Crypto Liquidity (NEW)
with tabs[3]:
    st.subheader("ğŸª™ Crypto Liquidity")
    st.caption("ğŸ’¡ ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚³ã‚¤ãƒ³ä¾›çµ¦é‡ & ãƒˆãƒ¼ã‚¯ãƒ³åŒ–è³‡ç”£ (å›½å‚µ/é‡‘) - DeFiLlama APIçµŒç”±")
    
    # Fetch data from DeFiLlama
    stablecoin_data = get_stablecoin_data()
    stablecoin_hist = get_stablecoin_historical()
    treasury_data = get_tokenized_treasury_data()
    
    # Cache crypto summary for AI Analysis tab (non-blocking)
    if stablecoin_data or treasury_data:
        crypto_cache = []
        if stablecoin_data:
            crypto_cache.append(f"Total Stablecoin Supply: ${stablecoin_data['total_supply']:.1f}B")
            for coin in stablecoin_data.get('top_coins', [])[:3]:
                delta_1d = coin['circulating'] - coin['prev_day'] if coin.get('prev_day') else 0
                crypto_cache.append(f"  {coin['symbol']}: ${coin['circulating']:.1f}B (24h: {delta_1d:+.2f}B)")
        if treasury_data:
            crypto_cache.append(f"Tokenized Treasuries TVL: ${treasury_data['treasury']['total_tvl']:.2f}B")
            crypto_cache.append(f"Tokenized Gold TVL: ${treasury_data['gold']['total_tvl']:.2f}B")
            crypto_cache.append(f"Other RWA TVL: ${treasury_data['other_rwa']['total_tvl']:.2f}B")
        st.session_state['crypto_summary_cache'] = crypto_cache
    
    # --- Stablecoin Supply Section ---
    st.markdown("### ğŸ’µ Stablecoin Supply")
    st.caption("ã‚¯ãƒªãƒ—ãƒˆå¸‚å ´ã®ã€Œè¡€æ¶²ã€- å¢—åŠ  = è³‡é‡‘æµå…¥")
    
    if stablecoin_data:

        # Total Supply Metric
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            total_supply = stablecoin_data['total_supply']
            st.metric(
                "Total Stablecoin Supply",
                f"${total_supply:.1f} B",
                help="å…¨ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚³ã‚¤ãƒ³ï¼ˆUSDãƒšãƒƒã‚°ï¼‰ã®ç·ä¾›çµ¦é‡"
            )
            # Show data freshness
            if 'timestamp' in stablecoin_data:
                st.caption(f"ğŸ”„ æä¾›å…ƒæ›´æ–°: {stablecoin_data['timestamp'][:16].replace('T', ' ')} (DeFiLlama)")
        with col2:
            top_coins = stablecoin_data['top_coins']
            if top_coins and len(top_coins) > 0:
                usdt = next((c for c in top_coins if c['symbol'] == 'USDT'), None)
                if usdt:
                    delta_1d = usdt['circulating'] - usdt['prev_day'] if usdt['prev_day'] else 0
                    st.metric("USDT Supply", f"${usdt['circulating']:.1f} B", delta=f"{delta_1d:+.2f} B (24h)")
        with col3:
            if top_coins and len(top_coins) > 0:
                usdc = next((c for c in top_coins if c['symbol'] == 'USDC'), None)
                if usdc:
                    delta_1d = usdc['circulating'] - usdc['prev_day'] if usdc['prev_day'] else 0
                    st.metric("USDC Supply", f"${usdc['circulating']:.1f} B", delta=f"{delta_1d:+.2f} B (24h)")
        
        # Historical Chart - Total Stablecoin Supply
        st.markdown("#### ğŸ“ˆ Stablecoin Supply History")
        if stablecoin_hist is not None and not stablecoin_hist.empty:
            col_short, col_long = st.columns(2)
            with col_short:
                st.markdown("##### çŸ­æœŸ (90æ—¥)")
                recent_90d = stablecoin_hist.tail(90)
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=recent_90d.index, y=recent_90d['Total'], 
                                        mode='lines', fill='tozeroy', 
                                        line=dict(color='#26a69a'), name='Total'))
                fig.update_layout(template='plotly_dark', height=250, 
                                 title='Total Stablecoin Supply (90d)',
                                 yaxis_title='Supply ($B)', showlegend=False)
                st.plotly_chart(fig, use_container_width=True, key="stbl_short")
            with col_long:
                st.markdown("##### é•·æœŸ (å…¨æœŸé–“)")
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=stablecoin_hist.index, y=stablecoin_hist['Total'], 
                                        mode='lines', fill='tozeroy', 
                                        line=dict(color='#42a5f5'), name='Total'))
                fig.update_layout(template='plotly_dark', height=250, 
                                 title='Total Stablecoin Supply (All Time)',
                                 yaxis_title='Supply ($B)', showlegend=False)
                st.plotly_chart(fig, use_container_width=True, key="stbl_long")
        else:
            st.caption("ğŸ“Š å±¥æ­´ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
        
        # Top Stablecoins Table
        st.markdown("#### Top 10 Stablecoins by Supply")
        top_10 = stablecoin_data['top_coins'][:10]
        
        stablecoin_df = pd.DataFrame([
            {
                'Symbol': coin['symbol'],
                'Name': coin['name'],
                'Supply ($B)': round(coin['circulating'], 2),
                'Mechanism': coin['mechanism'],
                '24h Î”': round(coin['circulating'] - coin['prev_day'], 3) if coin['prev_day'] else 0,
                '7d Î”': round(coin['circulating'] - coin['prev_week'], 3) if coin['prev_week'] else 0,
            }
            for coin in top_10
        ])
        st.dataframe(stablecoin_df, use_container_width=True, hide_index=True)
        
        # Supply Distribution Chart
        st.markdown("#### Supply Distribution")
        fig = go.Figure(data=[
            go.Pie(
                labels=[c['symbol'] for c in top_10[:6]] + ['Others'],
                values=[c['circulating'] for c in top_10[:6]] + [sum(c['circulating'] for c in top_10[6:])],
                hole=0.4,
                marker=dict(colors=['#26a69a', '#42a5f5', '#7e57c2', '#ff7043', '#78909c', '#ab47bc', '#bdbdbd'])
            )
        ])
        fig.update_layout(
            template='plotly_dark',
            height=350,
            showlegend=True,
            legend=dict(orientation='h', y=-0.1)
        )
        st.plotly_chart(fig, use_container_width=True, key="stablecoin_pie")
        
        st.caption(f"ğŸ“… æœ€çµ‚æ›´æ–°: {stablecoin_data['timestamp'][:19]}")
    else:
        st.warning("âš ï¸ ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚³ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚Force Updateã‚’è©¦ã—ã¦ãã ã•ã„ã€‚")
    
    st.markdown("---")
    
    # --- Tokenized Treasury Section (Separated Categories) ---
    if treasury_data:
        # Summary metrics
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown("### ğŸ“œ Tokenized Treasuries")
            st.metric(
                "Treasury TVL",
                f"${treasury_data['treasury']['total_tvl']:.2f} B",
                help="ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ç±³å›½å‚µï¼ˆBUIDL, USDYç­‰ï¼‰"
            )
        with col2:
            st.markdown("### ğŸª™ Tokenized Gold")
            st.metric(
                "Gold TVL",
                f"${treasury_data['gold']['total_tvl']:.2f} B",
                help="ãƒˆãƒ¼ã‚¯ãƒ³åŒ–é‡‘ï¼ˆXAUT, PAXGç­‰ï¼‰"
            )
        with col3:
            st.markdown("### ğŸ¢ Other RWA")
            st.metric(
                "Other RWA TVL",
                f"${treasury_data['other_rwa']['total_tvl']:.2f} B",
                help="ãã®ä»–ã®å®Ÿä¸–ç•Œè³‡ç”£"
            )
        
        # Show data freshness for RWA section
        if 'timestamp' in treasury_data:
            st.caption(f"ğŸ”„ æä¾›å…ƒæ›´æ–°: {treasury_data['timestamp'][:16].replace('T', ' ')} (DeFiLlama)")
        
        # Treasury Protocols
        st.markdown("---")
        st.markdown("#### ğŸ“œ Tokenized US Treasuries")
        st.caption("æ©Ÿé–¢æŠ•è³‡å®¶ã®ã‚¯ãƒªãƒ—ãƒˆå‚å…¥æŒ‡æ¨™ - TradFi â†’ DeFiã®æ¶ã‘æ©‹")
        
        treasury_protocols = treasury_data['treasury']['protocols']
        if treasury_protocols:
            treasury_df = pd.DataFrame([
                {
                    'Protocol': p['name'],
                    'Symbol': p.get('symbol', '-'),
                    'TVL ($B)': round(p['tvl'], 3),
                    '24h Î” (%)': round(p.get('change_1d', 0), 2) if p.get('change_1d') else 0,
                    '7d Î” (%)': round(p.get('change_7d', 0), 2) if p.get('change_7d') else 0,
                }
                for p in treasury_protocols
            ])
            st.dataframe(treasury_df, use_container_width=True, hide_index=True)
            
            # Treasury Bar Chart
            fig = go.Figure(data=[
                go.Bar(
                    x=[p['name'][:15] for p in treasury_protocols[:8]],
                    y=[p['tvl'] for p in treasury_protocols[:8]],
                    marker_color='steelblue'
                )
            ])
            fig.update_layout(
                template='plotly_dark',
                height=250,
                xaxis_title="Protocol",
                yaxis_title="TVL ($B)"
            )
            st.plotly_chart(fig, use_container_width=True, key="treasury_bar")
        else:
            st.caption("ãƒˆãƒ¼ã‚¯ãƒ³åŒ–å›½å‚µãƒ—ãƒ­ãƒˆã‚³ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # Gold Protocols
        st.markdown("---")
        st.markdown("#### ğŸª™ Tokenized Gold")
        st.caption("é‡‘ã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ– - ä¼çµ±çš„å®‰å…¨è³‡ç”£ã®ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–")
        
        gold_protocols = treasury_data['gold']['protocols']
        if gold_protocols:
            gold_df = pd.DataFrame([
                {
                    'Protocol': p['name'],
                    'Symbol': p.get('symbol', '-'),
                    'TVL ($B)': round(p['tvl'], 3),
                    '24h Î” (%)': round(p.get('change_1d', 0), 2) if p.get('change_1d') else 0,
                    '7d Î” (%)': round(p.get('change_7d', 0), 2) if p.get('change_7d') else 0,
                }
                for p in gold_protocols
            ])
            st.dataframe(gold_df, use_container_width=True, hide_index=True)
            
            # Gold Bar Chart
            fig = go.Figure(data=[
                go.Bar(
                    x=[p['name'][:15] for p in gold_protocols],
                    y=[p['tvl'] for p in gold_protocols],
                    marker_color='gold'
                )
            ])
            fig.update_layout(
                template='plotly_dark',
                height=200,
                xaxis_title="Protocol",
                yaxis_title="TVL ($B)"
            )
            st.plotly_chart(fig, use_container_width=True, key="gold_bar")
        else:
            st.caption("ãƒˆãƒ¼ã‚¯ãƒ³åŒ–é‡‘ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # Other RWA Protocols (collapsed by default)
        with st.expander("ğŸ¢ Other RWA Protocols"):
            other_protocols = treasury_data['other_rwa']['protocols']
            if other_protocols:
                other_df = pd.DataFrame([
                    {
                        'Protocol': p['name'],
                        'Symbol': p.get('symbol', '-'),
                        'TVL ($B)': round(p['tvl'], 3),
                        'Category': p.get('category', 'RWA'),
                        '24h Î” (%)': round(p.get('change_1d', 0), 2) if p.get('change_1d') else 0,
                    }
                    for p in other_protocols
                ])
                st.dataframe(other_df, use_container_width=True, hide_index=True)
            else:
                st.caption("ãã®ä»–ã®RWAãƒ—ãƒ­ãƒˆã‚³ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        st.caption(f"ğŸ“… æœ€çµ‚æ›´æ–°: {treasury_data['timestamp'][:19]}")
    else:
        st.warning("âš ï¸ RWAãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚Force Updateã‚’è©¦ã—ã¦ãã ã•ã„ã€‚")
    
    st.markdown("---")
    st.info("""
    ğŸ’¡ **ãªãœã“ã‚ŒãŒé‡è¦ï¼Ÿ**
    - **ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚³ã‚¤ãƒ³**: ã‚¯ãƒªãƒ—ãƒˆå¸‚å ´ã¸ã®è³‡é‡‘æµå…¥/æµå‡ºã‚’æ¸¬å®šã€‚å¢—åŠ ãƒˆãƒ¬ãƒ³ãƒ‰ = ãƒªã‚¹ã‚¯ã‚ªãƒ³
    - **ãƒˆãƒ¼ã‚¯ãƒ³åŒ–å›½å‚µ**: æ©Ÿé–¢æŠ•è³‡å®¶ã®å‚å…¥åº¦åˆã„ã€‚TradFiï¼ˆä¼çµ±é‡‘èï¼‰ã‹ã‚‰DeFiã¸ã®è³‡æœ¬ç§»å‹•ã‚’ç¤ºã™
    - **ãƒˆãƒ¼ã‚¯ãƒ³åŒ–é‡‘**: ä¼çµ±çš„å®‰å…¨è³‡ç”£ã®ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–ã€‚XAUTã¯å›½å‚µã¨ã¯åˆ¥ã‚«ãƒ†ã‚´ãƒª
    - **ä»Šå¾Œã®å±•é–‹**: Bitgetç­‰ãŒæ ªå¼ã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–é–‹å§‹ã€‚é‡‘èå•†å“ã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã¯åŠ é€Ÿã™ã‚‹è¦‹è¾¼ã¿
    """)

# Tab 5: AI Analysis (updated index)
with tabs[4]:
    st.subheader("ğŸ¤– AI Market Analysis")
    st.caption("Gemini 3 Flash & Claude Opus 4.5 ã«ã‚ˆã‚‹ãƒ‡ãƒ¥ã‚¢ãƒ«AIå¸‚å ´åˆ†æ")
    
    # Check API keys
    gemini_available = gemini_client is not None
    claude_available = claude_client is not None
    
    if not gemini_available and not claude_available:
        st.error("âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã« `GEMINI_API_KEY` ã¾ãŸã¯ `ANTHROPIC_API_KEY` ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    else:
        # Prepare market data summary for AI
        def get_market_summary():
            """Generate a comprehensive summary of ALL monitored market conditions for AI analysis"""
            summary_parts = []
            
            def add_metric(name, col_name, unit="", with_change=False, change_days=7, show_date=False, is_level=False):
                """Helper to add a metric to summary with strict labeling (Level vs Change)"""
                if col_name in df.columns:
                    data = df[col_name].dropna()
                    if len(data) > 0:
                        current = data.iloc[-1]
                        last_date = data.index[-1].strftime('%Y/%m/%d') if hasattr(data.index[-1], 'strftime') else str(data.index[-1])[:10]
                        
                        type_tag = "[Level/ç·æ•°]" if is_level else "[Change/å¤‰åŒ–é‡ãƒ»æŒ‡æ•°]"
                        
                        if with_change and len(data) >= change_days:
                            change = current - data.iloc[-change_days]
                            label = f"{name} {type_tag}: {current:.2f}{unit}"
                            change_label = f"({change_days}æ—¥å¤‰åŒ–: {change:+.2f}{unit})"
                            date_label = f" [æ›´æ–°: {last_date}]" if show_date else ""
                            summary_parts.append(f"{label} {change_label}{date_label}")
                        else:
                            label = f"{name} {type_tag}: {current:.2f}{unit}"
                            date_label = f" [æ›´æ–°: {last_date}]" if show_date else ""
                            summary_parts.append(f"{label}{date_label}")
            
            # Add data freshness header
            summary_parts.append("ã€ãƒ‡ãƒ¼ã‚¿é®®åº¦æƒ…å ±ã€‘")
            today = datetime.datetime.now().strftime('%Y/%m/%d %H:%M')
            summary_parts.append(f"åˆ†æå®Ÿè¡Œæ—¥æ™‚: {today}")
            summary_parts.append("")
            
            # â˜… Add focus areas at the top (if user selected any)
            focus_selection = st.session_state.get('ai_focus_categories', [])
            if focus_selection:
                summary_parts.insert(0, "")  # Blank line after focus section
                for i, category in enumerate(reversed(focus_selection)):
                    summary_parts.insert(0, f"  â†’ {category}")
                summary_parts.insert(0, "ã€â˜…â˜…â˜… ãƒ¦ãƒ¼ã‚¶ãƒ¼æ³¨ç›®é ˜åŸŸï¼ˆAIã¯ã“ã‚Œã‚‰ã‚’ç‰¹ã«é‡è¦–ã—ã¦åˆ†æã—ã¦ãã ã•ã„ï¼‰â˜…â˜…â˜…ã€‘")

            

            # === Fed Liquidity ===
            summary_parts.append("ã€FRBæµå‹•æ€§ã€‘")
            add_metric("Net Liquidity", "Net_Liquidity", "B", True, show_date=True, is_level=True)
            add_metric("ON RRP", "ON_RRP", "B", show_date=True, is_level=True)
            add_metric("Bank Reserves", "Reserves", "B", show_date=True, is_level=True)
            add_metric("TGA", "TGA", "B", show_date=True, is_level=True)
            add_metric("Fed Assets (WALCL)", "Fed_Assets", "B", show_date=True, is_level=True)
            add_metric("SOMA Total", "SOMA_Total", "B", is_level=True)
            add_metric("SOMA Bills", "SOMA_Bills", "B", True, is_level=True)
            

            # === Economic Indicators (US Economic Data) ===
            summary_parts.append("\nã€ç±³çµŒæ¸ˆæŒ‡æ¨™ã€‘")
            
            # 1. Monetary Policy
            summary_parts.append("[é‡‘èæ”¿ç­–]")
            add_metric("FF Rate Upper", "FedFundsUpper", "%", is_level=True)
            add_metric("EFFR", "EFFR", "%", is_level=True)
            add_metric("IORB", "IORB", "%", is_level=True)
            add_metric("SOFR", "SOFR", "%", is_level=True)
            
            # 2. Employment
            summary_parts.append("[é›‡ç”¨é–¢é€£]")
            add_metric("Unemployment Rate", "UNRATE", "%", is_level=True)
            add_metric("NFP Total (Level)", "NFP", "K", is_level=True)
            add_metric("Avg Hourly Earnings", "AvgHourlyEarnings", "$", is_level=True)
            add_metric("JOLTS Job Openings (Level)", "JOLTS", "K", is_level=True)
            add_metric("Initial Claims (Change)", "ICSA", "K")
            
            # 3. Inflation
            summary_parts.append("[ç‰©ä¾¡ãƒ»ã‚¤ãƒ³ãƒ•ãƒ¬]")
            add_metric("CPI Index (Level)", "CPI", "", is_level=True)
            add_metric("CPI Core Index (Level)", "CPICore", "", is_level=True)
            add_metric("Core PCE YoY%", "CorePCE", "%")
            add_metric("PPI Index (Level)", "PPI", "", is_level=True)
            
            # 4. Economy
            summary_parts.append("[æ™¯æ°—ãƒ»è£½é€ æ¥­]")
            add_metric("Retail Sales", "RetailSales", "M", is_level=True)
            add_metric("Consumer Sentiment", "ConsumerSent", "pt", is_level=True)
            add_metric("Real GDP (Level)", "RealGDP", "B", is_level=True)
            add_metric("2Y-10Y Spread", "T10Y2Y", "%", is_level=True)
            
            # === Global M2 ===
            summary_parts.append("\nã€ãƒãƒãƒ¼ã‚µãƒ—ãƒ©ã‚¤ã€‘")
            add_metric("US M2 (Nominal)", "M2SL", "B", is_level=True)
            add_metric("US M2 (Real)", "M2REAL", "B", is_level=True)
            add_metric("US Real M2 Index", "US_Real_M2_Index", "", is_level=True)
            add_metric("China M2", "CN_M2", "T CNY", is_level=True)
            add_metric("China Credit Impulse", "CN_Credit_Impulse", "%")
            add_metric("Japan M2", "JP_M2", "T JPY", is_level=True)
            add_metric("EU M2", "EU_M2", "T EUR", is_level=True)

            # === Banking Sector ===
            summary_parts.append("\nã€éŠ€è¡Œã‚»ã‚¯ã‚¿ãƒ¼ã€‘")
            add_metric("Bank Cash", "Bank_Cash", "B", is_level=True)
            add_metric("C&I Lending Std (Large)", "Lending_Standards", " pts", is_level=True)
            add_metric("C&I Lending Std (Small)", "CI_Std_Small", " pts", is_level=True)
            add_metric("C&I Demand", "CI_Demand", " pts", is_level=True)
            add_metric("C&I Loans", "CI_Loans", "B", is_level=True)
            add_metric("CRE Std (Construction)", "CRE_Std_Construction", " pts", is_level=True)
            add_metric("CRE Std (General)", "CRE_Std_Office", " pts", is_level=True)
            add_metric("CRE Loans", "CRE_Loans", "B", True, is_level=True)
            
            # === Risk & Bonds ===
            summary_parts.append("\nã€ãƒªã‚¹ã‚¯ãƒ»å‚µåˆ¸ã€‘")
            add_metric("VIX", "VIX", "", show_date=True, is_level=True)
            add_metric("Credit Spread (HY)", "Credit_Spread", "%", show_date=True, is_level=True)
            add_metric("US 10Y Yield", "US_TNX", "%", show_date=True, is_level=True)
            
            # === Equity & Crypto ===
            summary_parts.append("\nã€æ ªå¼ãƒ»ä»®æƒ³é€šè²¨ã€‘")
            if 'SP500' in df.columns:
                sp = df['SP500'].dropna()
                if len(sp) > 5:
                    change_pct = ((sp.iloc[-1] / sp.iloc[-5]) - 1) * 100
                    summary_parts.append(f"S&P 500 Index [Level]: {sp.iloc[-1]:,.0f} (é€±é–“: {change_pct:+.1f}%)")
            add_metric("BTC", "BTC", "", is_level=True)
            add_metric("ETH", "ETH", "", is_level=True)
            
            # === FX ===
            summary_parts.append("\nã€ç‚ºæ›¿ã€‘")
            add_metric("DXY", "DXY", "", is_level=True)
            add_metric("USD/JPY", "USDJPY", "", is_level=True)
            add_metric("EUR/USD", "EURUSD", "", is_level=True)
            add_metric("USD/CNY", "USDCNY", "", is_level=True)
            
            # === Commodities ===
            summary_parts.append("\nã€ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£ã€‘")
            add_metric("Gold", "Gold", "", is_level=True)
            add_metric("Silver", "Silver", "", is_level=True)
            add_metric("Oil (WTI)", "Oil", "", is_level=True)
            add_metric("Copper", "Copper", "", is_level=True)
            
            # === HYG ===
            summary_parts.append("\nã€ãƒã‚¤ã‚¤ãƒ¼ãƒ«ãƒ‰å‚µã€‘")
            if 'HYG' in df.columns:
                hyg = df['HYG'].dropna()
                if len(hyg) > 5:
                    hyg_change = ((hyg.iloc[-1] / hyg.iloc[-5]) - 1) * 100
                    summary_parts.append(f"HYG (High Yield ETF): {hyg.iloc[-1]:.2f} (é€±é–“: {hyg_change:+.1f}%)")


            
            # === Crypto Liquidity (Fetch if not cached, ensuring availability) ===
            summary_parts.append("\nã€ã‚¯ãƒªãƒ—ãƒˆæµå‹•æ€§ã€‘")
            if 'crypto_summary_cache' not in st.session_state:
                # Proactively fetch to avoid "tab-dependency" for AI
                try:
                    s_data = get_stablecoin_data()
                    t_data = get_tokenized_treasury_data()
                    c_cache = []
                    if s_data:
                        c_cache.append(f"Total Stablecoin Supply [Level]: ${s_data['total_supply']:.1f}B")
                        for coin in s_data.get('top_coins', [])[:3]:
                            d1 = coin['circulating'] - coin['prev_day'] if coin.get('prev_day') else 0
                            c_cache.append(f"  {coin['symbol']} [Level]: ${coin['circulating']:.1f}B (24h Î”: {d1:+.2f}B)")
                    if t_data:
                        c_cache.append(f"Tokenized Treasuries TVL [Level]: ${t_data['treasury']['total_tvl']:.2f}B")
                        c_cache.append(f"Tokenized Gold TVL [Level]: ${t_data['gold']['total_tvl']:.2f}B")
                    st.session_state['crypto_summary_cache'] = c_cache
                except:
                    summary_parts.append("(å–å¾—ã‚¨ãƒ©ãƒ¼: ã‚¯ãƒªãƒ—ãƒˆAPIã«ä¸€æ™‚çš„ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“)")
            
            if 'crypto_summary_cache' in st.session_state:
                for line in st.session_state['crypto_summary_cache']:
                    summary_parts.append(line)
            
            # === Market Sentiment (NEW) ===
            summary_parts.append("\nã€ãƒãƒ¼ã‚±ãƒƒãƒˆã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã€‘")
            
            # VIX (already in df)
            if 'VIX' in df.columns:
                vix = df['VIX'].dropna()
                if len(vix) > 0:
                    vix_val = vix.iloc[-1]
                    vix_label = "Low" if vix_val < 15 else "Normal" if vix_val < 20 else "Elevated" if vix_val < 30 else "High Fear"
                    summary_parts.append(f"VIX (ææ€–æŒ‡æ•°) [Level]: {vix_val:.1f} ({vix_label})")
            
            # Crypto Fear & Greed (fetch with cache)
            if 'sentiment_fg_cache' not in st.session_state:
                try:
                    cfg = get_crypto_fear_greed()
                    if cfg:
                        st.session_state['sentiment_fg_cache'] = f"Crypto Fear & Greed [Level]: {cfg['current']} ({cfg['classification']})"
                    else:
                        st.session_state['sentiment_fg_cache'] = "Crypto Fear & Greed: å–å¾—å¤±æ•—"
                except:
                    st.session_state['sentiment_fg_cache'] = "Crypto Fear & Greed: å–å¾—å¤±æ•—"
            summary_parts.append(st.session_state['sentiment_fg_cache'])
            
            # AAII Sentiment (fetch with cache)
            if 'sentiment_aaii_cache' not in st.session_state:
                try:
                    aaii = get_aaii_sentiment()
                    if aaii:
                        spread = aaii['bull_bear_spread']
                        spread_label = "éç†±æ³¨æ„" if spread >= 20 else "ã‚„ã‚„å¼·æ°—" if spread >= 10 else "ä¸­ç«‹" if spread >= -10 else "ã‚„ã‚„å¼±æ°—" if spread >= -20 else "åº•æ‰“ã¡ã‚µã‚¤ãƒ³?"
                        st.session_state['sentiment_aaii_cache'] = f"AAII Bull-Bear Spread [Level]: {spread:+.1f}% ({spread_label})"
                    else:
                        st.session_state['sentiment_aaii_cache'] = "AAII Sentiment: å–å¾—å¤±æ•—"
                except:
                    st.session_state['sentiment_aaii_cache'] = "AAII Sentiment: å–å¾—å¤±æ•—"
            summary_parts.append(st.session_state['sentiment_aaii_cache'])
            
            return "\n".join(summary_parts)


        
        st.markdown("### ğŸ“Š ç¾åœ¨ã®å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼")
        
        market_summary = get_market_summary()
        with st.expander("ğŸ“‹ AIã«é€ä¿¡ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿", expanded=False):
            st.code(market_summary, language="text")
        
        st.markdown("---")
        
        # AI Status display
        col_status1, col_status2 = st.columns(2)
        with col_status1:
            if gemini_available:
                st.success(f"âœ… Gemini 3 Flash æº–å‚™å®Œäº†")
            else:
                st.warning("âš ï¸ Geminiæœªè¨­å®š")
        with col_status2:
            if claude_available:
                st.success(f"âœ… Claude Opus 4.5 æº–å‚™å®Œäº†")
            else:
                st.warning("âš ï¸ Claudeæœªè¨­å®š")
        
        st.markdown("---")
        
        # AI selection
        ai_options = []
        if gemini_available:
            ai_options.append("ğŸ”· Gemini 3 Flash")
        if claude_available:
            ai_options.append("ğŸŸ£ Claude Opus 4.5")
        if gemini_available and claude_available:
            ai_options.append("âš¡ ãƒ‡ãƒ¥ã‚¢ãƒ«AIæ¯”è¼ƒåˆ†æ")
        
        selected_ai = st.selectbox("ä½¿ç”¨ã™ã‚‹AIã‚’é¸æŠ", ai_options)
        
        # Analysis options
        analysis_type = st.selectbox(
            "åˆ†æã‚¿ã‚¤ãƒ—ã‚’é¸æŠ",
            ["ç·åˆåˆ†æ", "ãƒªã‚¹ã‚¯è©•ä¾¡", "æµå‹•æ€§åˆ†æ", "FRBæ”¿ç­–åˆ†æ", "æŠ•è³‡ã‚¢ã‚¤ãƒ‡ã‚¢"]
        )
        
        # IMPORTANT: Policy context to prevent outdated information and ensure verification
        policy_context = """ã€è¶…é‡è¦ï¼šåˆ†æã®çµ¶å¯¾æ¡ä»¶ï¼ˆæ¤œè¨¼å¯èƒ½æ€§ã¨æ­£ç¢ºæ€§ï¼‰ã€‘
1. **ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå˜˜ï¼‰ã®å³ç¦**: 
   - æœªç™ºè¡¨ã®çµ±è¨ˆã‚„æ¶ç©ºã®æ•°å€¤ã‚’ã€Œç¢ºå®šå€¤ã€ã¨ã—ã¦èªã‚‹ã“ã¨ã¯çµ¶å¯¾ã«è¨±ã•ã‚Œã¾ã›ã‚“ã€‚
   - ã€Œå¸‚å ´ãƒ‡ãƒ¼ã‚¿ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æ•°å€¤ã‚’ã€Œå”¯ä¸€ã®çœŸå®Ÿï¼ˆGround Truthï¼‰ã€ã¨ã—ã€å¤–éƒ¨æ¤œç´¢çµæœãŒã“ã‚Œã¨çŸ›ç›¾ã™ã‚‹å ´åˆã¯ã‚¢ãƒ—ãƒªå†…ã®æ•°å€¤ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚
2. **å‡ºå…¸ï¼ˆEvidenceï¼‰ã®æç¤ºç¾©å‹™**:
   - å…¨ã¦ã®äº‹å®Ÿã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€çµ±è¨ˆå¼•ç”¨ã«ãŠã„ã¦ã€**[å‡ºå…¸æ©Ÿé–¢å] [é…ä¿¡æ—¥æ™‚] [URL]**ã‚’å¿…ãšã‚»ãƒƒãƒˆã§ä½µè¨˜ã—ã¦ãã ã•ã„ã€‚
   - è¨¼æ‹ ãŒæç¤ºã§ããªã„æƒ…å ±ã¯ã€Œæ¨æ¸¬ã€ã§ã‚ã‚‹ã“ã¨ã‚’æ˜è¨˜ã™ã‚‹ã‹ã€å‡ºåŠ›ã‹ã‚‰é™¤å¤–ã—ã¦ãã ã•ã„ã€‚
3. **ä¸€æ¬¡è³‡æ–™ï¼ˆPrimary Sourceï¼‰ã®å„ªå…ˆ**:
   - ä¸­å¤®éŠ€è¡Œï¼ˆFed, ECB, BOJç­‰ï¼‰ã€å›½éš›æ©Ÿé–¢ï¼ˆBIS, IMFç­‰ï¼‰ã€æ”¿åºœæ©Ÿé–¢ï¼ˆBLS, BEAç­‰ï¼‰ã®å…¬å¼ç™ºè¡¨ã‚’æœ€å„ªå…ˆã§æ¢ç´¢ãƒ»å¼•ç”¨ã—ã¦ãã ã•ã„ã€‚
4. **ãƒã‚¯ãƒ­ã®é…ç®¡ï¼ˆPlumbingï¼‰è¦–ç‚¹**:
   - è¡¨é¢çš„ãªå‹•ãã ã‘ã§ãªãã€æº–å‚™é é‡‘ã€ON RRPã€ãƒ¬ãƒå¸‚å ´ã¸ã®æ³¢åŠçµŒè·¯ã‚’è«–ç†çš„ã«è§£èª¬ã—ã¦ãã ã•ã„ã€‚

ã€æœ€æ–°æ”¿ç­–ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ2026å¹´1æœˆæ™‚ç‚¹ï¼‰ã€‘
- FRB QTï¼ˆé‡çš„å¼•ãç· ã‚ï¼‰: 2025å¹´12æœˆã«çµ‚äº†ã€‚ç¾åœ¨ã¯æœˆ450å„„ãƒ‰ãƒ«ãƒšãƒ¼ã‚¹ã®æ‹¡å¤§ãƒ•ã‚§ãƒ¼ã‚ºã«ç§»è¡Œã€‚
- Bills-inæˆ¦ç•¥: FRBã¯çŸ­æœŸå›½å‚µï¼ˆT-Billsï¼‰ã®ä¿æœ‰æ¯”ç‡ã‚’ç©æ¥µçš„ã«å¢—åŠ ä¸­ã€‚
- ON RRP: æ¯æ¸‡çŠ¶æ…‹ï¼ˆScarce Regimeï¼‰ã€‚
"""

        analysis_prompts = {
            "ç·åˆåˆ†æ": f"""{policy_context}
ã€åˆ†ææŒ‡ç¤ºã€‘
1. ç¾åœ¨ã®å¸‚å ´ç’°å¢ƒã‚’ã€æä¾›ã•ã‚ŒãŸã€Œå¸‚å ´ãƒ‡ãƒ¼ã‚¿[Level]ã€ã¨æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’çµ„ã¿åˆã‚ã›ã¦åˆ†æã—ã¦ãã ã•ã„ã€‚
2. ä»–ã®ãƒ¡ãƒ‡ã‚£ã‚¢ãŒè¦‹è½ã¨ã—ã¦ã„ã‚‹ã€Œãƒã‚¯ãƒ­ã®æ­ªã¿ã€ã‚’ç‹¬è‡ªã®è¦–ç‚¹ï¼ˆé…ç®¡è¦–ç‚¹ï¼‰ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
3. æœ€å¾Œã«ã€Xï¼ˆTwitterï¼‰æŠ•ç¨¿ã«ãã®ã¾ã¾ä½¿ãˆã‚‹ã€é­‚ã®è¾¼ã‚‚ã£ãŸã€Œã‚¤ãƒ³ã‚µã‚¤ãƒˆãƒ»ãƒã‚¹ãƒˆã€ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®JSONæ§‹é€ ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆå³å¯†ã«å®ˆã‚‹ã“ã¨ï¼‰ï¼š
{{
  "headline": "ä»Šå›ã®ä¸€ç•ªã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ä¸€è¨€ã§",
  "credibility": 0.0-1.0,
  "importance_rank": "S/A/B/C",
  "sentiment_matrix": {{ "risk_assets": "Pos/Neu/Neg", "currency_usd": "...", "safe_haven": "...", "commodities": "...", "emerging_markets": "..." }},
  "deep_analysis": "è©³ç´°ãªåˆ†æãƒ†ã‚­ã‚¹ãƒˆï¼ˆå‡ºå…¸URLã¨æ—¥ä»˜ã‚’å„é …ç›®ã«å¿…ãšå«ã‚ã‚‹ã“ã¨ï¼‰",
  "x_post": "Xç”¨æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆï¼ˆé­‚ã‚’è¾¼ã‚ã¦ï¼‰"
}}""",
            
            "ãƒªã‚¹ã‚¯è©•ä¾¡": f"""{policy_context}
ã€åˆ†ææŒ‡ç¤ºã€‘
1. ç¾åœ¨ã®å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ãƒ€ã‚¦ãƒ³ã‚µã‚¤ãƒ‰ãƒªã‚¹ã‚¯ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚
2. è­¦æˆ’ã™ã¹ãä¾¡æ ¼å¸¯ã‚„æŒ‡æ¨™ã®å¤‰åŒ–ç‡ã‚’å…·ä½“çš„ã«è¿°ã¹ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®JSONæ§‹é€ ã§å‡ºåŠ›ï¼ˆå³å¯†ï¼‰ï¼š
{{
  "headline": "æœ€å¤§ã®ãƒªã‚¹ã‚¯è¦å› ã‚’ä¸€è¨€ã§",
  "credibility": 0.0-1.0,
  "importance_rank": "S/A/B/C",
  "sentiment_matrix": {{ "risk_assets": "...", "currency_usd": "...", "safe_haven": "...", "commodities": "...", "emerging_markets": "..." }},
  "deep_analysis": "è©³ç´°ãªãƒªã‚¹ã‚¯åˆ†æï¼ˆURL/æ—¥ä»˜å¿…é ˆï¼‰",
  "x_post": "ãƒªã‚¹ã‚¯è­¦å‘Šãƒã‚¹ãƒˆï¼ˆé­‚ï¼‰"
}}""",
            
            "æµå‹•æ€§åˆ†æ": f"""{policy_context}
ã€åˆ†ææŒ‡ç¤ºã€‘
1. Net Liquidity ã¨ SOMA Bills ã®ç›¸é–¢ã€ãŠã‚ˆã³ ON RRP æ¯æ¸‡ã®å½±éŸ¿ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
2. è³‡ç”£ä¾¡æ ¼ï¼ˆæ ªãƒ»BTCï¼‰ã¸ã®æµå‹•æ€§ä¾›çµ¦ã®ã€Œè›‡å£ã€ãŒã©ã†ãªã£ã¦ã„ã‚‹ã‹è¿°ã¹ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONï¼ˆå³å¯†ï¼‰ï¼š
{{
  "headline": "æµå‹•æ€§ã®çœŸã®çŠ¶æ…‹ã‚’ä¸€è¨€ã§",
  "credibility": 0.0-1.0,
  "importance_rank": "S/A/B/C",
  "sentiment_matrix": {{ "risk_assets": "...", "currency_usd": "...", "safe_haven": "...", "commodities": "...", "emerging_markets": "..." }},
  "deep_analysis": "è©³ç´°ãªæµå‹•æ€§åˆ†æï¼ˆURL/æ—¥ä»˜å¿…é ˆï¼‰",
  "x_post": "æµå‹•æ€§ã‚¤ãƒ³ã‚µã‚¤ãƒˆãƒã‚¹ãƒˆï¼ˆé­‚ï¼‰"
}}""",
            
            "FRBæ”¿ç­–åˆ†æ": f"""{policy_context}
ã€åˆ†ææŒ‡ç¤ºã€‘
1. QTçµ‚äº†å¾Œã®ã€Œæ‹¡å¤§ãƒ•ã‚§ãƒ¼ã‚ºã€ã«ã‚ã‚‹FRBã®çœŸã®æ„å›³ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
2. ã€ŒBills-inæˆ¦ç•¥ã€ãŒé‡‘åˆ©æ›²ç·šã‚„éŠ€è¡Œæº–å‚™ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’è§£èª¬ã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONï¼ˆå³å¯†ï¼‰ï¼š
{{
  "headline": "FRBã®éš ã‚ŒãŸæ„å›³ã‚’ä¸€è¨€ã§",
  "credibility": 0.0-1.0,
  "importance_rank": "S/A/B/C",
  "sentiment_matrix": {{ "risk_assets": "...", "currency_usd": "...", "safe_haven": "...", "commodities": "...", "emerging_markets": "..." }},
  "deep_analysis": "è©³ç´°ãªæ”¿ç­–åˆ†æï¼ˆURL/æ—¥ä»˜å¿…é ˆï¼‰",
  "x_post": "ä¸­éŠ€ã‚¦ã‚©ãƒƒãƒãƒã‚¹ãƒˆï¼ˆé­‚ï¼‰"
}}""",
            
            "æŠ•è³‡ã‚¢ã‚¤ãƒ‡ã‚¢": f"""{policy_context}
ã€åˆ†ææŒ‡ç¤ºã€‘
1. å¸‚å ´ã®ã€Œæ­ªã¿ã€ã‹ã‚‰ã€æœ€ã‚‚æœŸå¾…å€¤ã®é«˜ã„è³‡ç”£ã‚¯ãƒ©ã‚¹/ã‚»ã‚¯ã‚¿ãƒ¼ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
2. æ—¢å­˜ã®å®šèª¬ï¼ˆã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹ï¼‰ã‚’ç–‘ã†è¦–ç‚¹ã‚’å«ã‚ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONï¼ˆå³å¯†ï¼‰ï¼š
{{
  "headline": "å‹æ©Ÿã®ã‚ã‚‹ã‚»ã‚¯ã‚¿ãƒ¼ã‚’ä¸€è¨€ã§",
  "credibility": 0.0-1.0,
  "importance_rank": "S/A/B/C",
  "sentiment_matrix": {{ "risk_assets": "...", "currency_usd": "...", "safe_haven": "...", "commodities": "...", "emerging_markets": "..." }},
  "deep_analysis": "è©³ç´°ãªæŠ•è³‡ã‚¢ã‚¤ãƒ‡ã‚¢ï¼ˆURL/æ—¥ä»˜å¿…é ˆï¼‰",
  "x_post": "æŠ•è³‡ã‚¢ã‚¤ãƒ‡ã‚¢ãƒã‚¹ãƒˆï¼ˆé­‚ï¼‰"
}}"""
        }
        
        # Helper function for Gemini with Google Search Grounding
        def run_gemini_analysis(prompt, use_search=True):
            """Run Gemini analysis with optional Google Search grounding for real-time info"""
            from google.genai import types
            
            if use_search:
                # Enable Google Search grounding for real-time information
                response = gemini_client.models.generate_content(
                    model=GEMINI_MODEL,
                    contents=prompt,
                    config=types.GenerateContentConfig(
                        tools=[types.Tool(google_search=types.GoogleSearch())]
                    )
                )
            else:
                response = gemini_client.models.generate_content(
                    model=GEMINI_MODEL,
                    contents=prompt
                )
            return response.text

        
        # Helper function for Claude (defined outside button to be reusable)
        def run_claude_analysis(prompt):
            message = claude_client.messages.create(
                model=CLAUDE_MODEL,
                max_tokens=4096,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            return message.content[0].text
        
        if st.button("ğŸš€ AIåˆ†æã‚’å®Ÿè¡Œ", type="primary"):
            # Create prompt
            full_prompt = f"""{analysis_prompts[analysis_type]}

ã€å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã€‘
{market_summary}

ã€åˆ†ææ—¥æ™‚ã€‘
{datetime.datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}
"""
            
            def display_ai_result(result_text, ai_name):
                # Robust JSON parsing
                data = None
                try:
                    data = json.loads(result_text)
                except json.JSONDecodeError:
                    # Try to extract JSON from markdown block
                    json_match = re.search(r'\{[\s\S]*\}', result_text)
                    if json_match:
                        try:
                            data = json.loads(json_match.group())
                        except: pass
                
                if data:
                    st.markdown(f"### {ai_name} åˆ†æçµæœ: [{data.get('importance_rank', 'N/A')}] {data.get('headline', '')}")
                    
                    col_m1, col_m2, col_m3 = st.columns(3)
                    with col_m1:
                        st.metric("é‡è¦åº¦ãƒ©ãƒ³ã‚¯", data.get('importance_rank', 'N/A'))
                    with col_m2:
                        st.metric("ä¿¡é ¼æ€§", f"{data.get('credibility', 0.0):.2f}")
                    with col_m3:
                        st.write("**5è»¸ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ**")
                        s = data.get('sentiment_matrix', {})
                        st.caption(f"æ ª/BTC:{s.get('risk_assets','-')} | USD:{s.get('currency_usd','-')} | Gold:{s.get('safe_haven','-')}")
                    
                    st.markdown("---")
                    st.markdown(data.get('deep_analysis', result_text))
                    
                    if 'x_post' in data:
                        with st.expander("ğŸ“ XæŠ•ç¨¿ç”¨ï¼ˆæ¤œè¨¼URLä»˜ãï¼‰", expanded=True):
                            st.code(data['x_post'], language="text")
                            st.info("ğŸ’¡ å›ç­”å†…ã®URLã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€æœ€æ–°ã®ä¸€æ¬¡ã‚½ãƒ¼ã‚¹ã‚’å¿…ãšç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                else:
                    st.markdown(f"### {ai_name} åˆ†æçµæœ")
                    st.markdown(result_text)

            if "Gemini" in selected_ai and "Claude" not in selected_ai:
                with st.spinner("ğŸ”· Gemini 3 Flash ãŒæˆ¦ç•¥åˆ†æä¸­..."):
                    try:
                        result = run_gemini_analysis(full_prompt)
                        display_ai_result(result, "ğŸ”· Gemini 3 Flash")
                    except Exception as e:
                        st.error(f"âŒ Gemini ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            elif "Claude" in selected_ai and "Gemini" not in selected_ai:
                with st.spinner("ğŸŸ£ Claude Opus 4.5 ãŒæ·±åº¦åˆ†æä¸­..."):
                    try:
                        result = run_claude_analysis(full_prompt)
                        display_ai_result(result, "ğŸŸ£ Claude Opus 4.5")
                    except Exception as e:
                        st.error(f"âŒ Claude ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            elif "ãƒ‡ãƒ¥ã‚¢ãƒ«AI" in selected_ai:
                col_dual1, col_dual2 = st.columns(2)
                with col_dual1:
                    with st.spinner("ğŸ”· Gemini åˆ†æä¸­..."):
                        try:
                            g_result = run_gemini_analysis(full_prompt)
                            display_ai_result(g_result, "ğŸ”· Gemini 3 Flash")
                        except Exception as e:
                            st.error(f"âŒ Gemini ã‚¨ãƒ©ãƒ¼: {str(e)}")
                with col_dual2:
                    with st.spinner("ğŸŸ£ Claude åˆ†æä¸­..."):
                        try:
                            c_result = run_claude_analysis(full_prompt)
                            display_ai_result(c_result, "ğŸŸ£ Claude Opus 4.5")
                        except Exception as e:
                            st.error(f"âŒ Claude ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            st.markdown("---")
            st.caption("âš ï¸ AIã«ã‚ˆã‚‹åˆ†æã¯å‚è€ƒæƒ…å ±ã§ã™ã€‚æŠ•è³‡åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚")
        
        st.markdown("---")
        
        # Custom question
        st.markdown("### ğŸ’¬ ã‚«ã‚¹ã‚¿ãƒ è³ªå•")
        user_question = st.text_area(
            "å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„",
            placeholder="ä¾‹: ç¾åœ¨ã®Net Liquidityã®æ°´æº–ã¯æ­´å²çš„ã«ã©ã†ã§ã™ã‹ï¼Ÿ",
            height=100
        )
        
        if st.button("ğŸ“¨ è³ªå•ã‚’é€ä¿¡") and user_question:
            # Check for news intent
            news_context = ""
            if any(kw in user_question for kw in ["ãƒ‹ãƒ¥ãƒ¼ã‚¹", "æœ€æ–°", "ç›´è¿‘", "ä»Šæ—¥", "ä»Šé€±", "å‡ºæ¥äº‹"]):
                with st.spinner("ğŸ” é–¢é€£ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œç´¢ä¸­..."):
                    news_headlines = search_google_news(user_question, num_results=3)
                    news_context = f"\n\nã€æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢çµæœï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰ã€‘\n{news_headlines}"

            custom_prompt = f"""{policy_context}

ä»¥ä¸‹ã®å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãŠã‚ˆã³æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«åŸºã¥ã„ã¦ã€æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã€å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã€‘
{market_summary}
{news_context}

ã€è³ªå•ã€‘
{user_question}

å°‚é–€çš„ã‹ã¤å…·ä½“çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚‹å ´åˆã¯ãã®é‡è¦åº¦ï¼ˆæ§‹é€ çš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç­‰ï¼‰ã«ã‚‚è§¦ã‚Œã¦ãã ã•ã„ã€‚"""

            
            if "Gemini" in selected_ai:
                with st.spinner("ğŸ”· Gemini 3 Flash ãŒå›ç­”ä¸­..."):
                    try:
                        result = run_gemini_analysis(custom_prompt)
                        st.markdown("### ğŸ’¡ Gemini å›ç­”")
                        st.markdown(result)
                    except Exception as e:
                        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            elif "Claude" in selected_ai:
                with st.spinner("ğŸŸ£ Claude Opus 4.5 ãŒå›ç­”ä¸­..."):
                    try:
                        result = run_claude_analysis(custom_prompt)
                        st.markdown("### ğŸ’¡ Claude å›ç­”")
                        st.markdown(result)
                    except Exception as e:
                        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")

# Tab 6: Monte Carlo Simulation
with tabs[5]:
    st.subheader("ğŸ² AI Monte Carlo Simulation")
    st.caption("ğŸ’¡ Claude 4.5 OpusãŒæˆ¦ç•¥è¨­è¨ˆã€Gemini 3 FlashãŒ10ä¸‡å›ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ")
    
    # Check AI availability
    mc_gemini_available = gemini_client is not None
    mc_claude_available = claude_client is not None
    
    if not mc_gemini_available or not mc_claude_available:
        st.error("âš ï¸ ã“ã®æ©Ÿèƒ½ã«ã¯ Gemini ã¨ Claude ã®ä¸¡æ–¹ã®APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚")
        if not mc_gemini_available:
            st.warning("âŒ Gemini APIæœªè¨­å®š")
        if not mc_claude_available:
            st.warning("âŒ Claude APIæœªè¨­å®š")
    else:
        st.success("âœ… AIæº–å‚™å®Œäº†ï¼ˆClaude 4.5 Opus + Gemini 3 Flashï¼‰")
        
        st.markdown("---")
        st.markdown("### ğŸ“ è³‡ç”£çŠ¶æ³ã®å…¥åŠ›")
        
        col_input1, col_input2 = st.columns(2)
        
        with col_input1:
            st.markdown("#### ç¾åœ¨ã®ä¿æœ‰è³‡ç”£")
            mc_btc_amount = st.number_input(
                "BTCä¿æœ‰é‡",
                min_value=0.0,
                max_value=100.0,
                value=0.8,
                step=0.1,
                help="ç¾åœ¨ä¿æœ‰ã—ã¦ã„ã‚‹BTCã®æ•°é‡"
            )
            mc_btc_price = st.number_input(
                "BTCç¾åœ¨ä¾¡æ ¼ï¼ˆä¸‡å††ï¼‰",
                min_value=100.0,
                max_value=10000.0,
                value=1400.0,
                step=50.0,
                help="1BTCã®ç¾åœ¨ä¾¡æ ¼ï¼ˆå††å»ºã¦ï¼‰"
            )
            mc_gold_amount = st.number_input(
                "Goldä¿æœ‰é‡ï¼ˆä¸‡å††ï¼‰",
                min_value=0.0,
                max_value=100000.0,
                value=0.0,
                step=10.0,
                help="ç¾åœ¨ä¿æœ‰ã—ã¦ã„ã‚‹ã‚´ãƒ¼ãƒ«ãƒ‰ã®è©•ä¾¡é¡ï¼ˆ0=æœªä¿æœ‰ï¼‰"
            )
            mc_stocks_amount = st.number_input(
                "æ ªå¼/ETFä¿æœ‰é‡ï¼ˆä¸‡å††ï¼‰ã€What-ifç”¨ã€‘",
                min_value=0.0,
                max_value=100000.0,
                value=0.0,
                step=50.0,
                help="S&P500 ETFç­‰ã®ä¿æœ‰é¡ï¼ˆ0=æœªä¿æœ‰ã€What-ifæ¯”è¼ƒç”¨ï¼‰"
            )
            mc_cash = st.number_input(
                "ç¾é‡‘ï¼ˆä¸‡å††ï¼‰",
                min_value=0.0,
                max_value=100000.0,
                value=500.0,
                step=50.0,
                help="æŠ•è³‡å¾…æ©Ÿè³‡é‡‘"
            )
            mc_investment_trust = st.number_input(
                "æŠ•è³‡ä¿¡è¨—ï¼ˆä¸‡å††ï¼‰",
                min_value=0.0,
                max_value=100000.0,
                value=150.0,
                step=10.0,
                help="æ”¾ç½®ä¸­ã®æŠ•è³‡ä¿¡è¨—"
            )
        
        with col_input2:
            st.markdown("#### ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š")
            mc_monthly_deposit = st.number_input(
                "æœˆé–“è¿½åŠ å…¥é‡‘ï¼ˆä¸‡å††ï¼‰",
                min_value=0.0,
                max_value=1000.0,
                value=25.0,
                step=5.0,
                help="æ¯æœˆã®è¿½åŠ å…¥é‡‘é¡"
            )
            mc_survival_line = st.number_input(
                "ç”Ÿå­˜ãƒ©ã‚¤ãƒ³ï¼ˆBTCå††å»ºã¦ä¸‡å††ï¼‰",
                min_value=50.0,
                max_value=5000.0,
                value=300.0,
                step=50.0,
                help="ã“ã®æ°´æº–ã¾ã§ä¸‹è½ã—ã¦ã‚‚ãƒ¡ãƒ³ã‚¿ãƒ«ç¶­æŒå¯èƒ½ãªãƒ©ã‚¤ãƒ³"
            )
            mc_simulation_years = st.selectbox(
                "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æœŸé–“",
                [5, 10, 15, 20],
                index=1,
                help="ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å¯¾è±¡å¹´æ•°"
            )
            mc_num_trials = st.selectbox(
                "è©¦è¡Œå›æ•°",
                [1000, 10000, 100000],
                index=2,
                help="ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­è©¦è¡Œå›æ•°ï¼ˆå¤šã„ã»ã©ç²¾åº¦å‘ä¸Šï¼‰"
            )
            
            st.markdown("#### ğŸ¯ Buy-the-Dip æˆ¦ç•¥è¨­å®š")
            st.caption("æš´è½æ™‚ã®è³¼å…¥æ¡ä»¶ã¨é…åˆ†ã‚’è¨­å®š")
            
            # Trigger settings
            mc_crash_threshold = st.slider(
                "æš´è½ãƒˆãƒªã‚¬ãƒ¼ï¼ˆé«˜å€¤ã‹ã‚‰ã®ä¸‹è½ç‡ %ï¼‰",
                min_value=-70,
                max_value=-10,
                value=-30,
                step=5,
                help="ç›´è¿‘é«˜å€¤ã‹ã‚‰ä½•%ä¸‹è½ã§è²·ã„ç™ºå‹•ã™ã‚‹ã‹"
            )
            
            mc_high_reference = st.selectbox(
                "é«˜å€¤ã®åŸºæº–",
                ["éå»90æ—¥é«˜å€¤", "éå»180æ—¥é«˜å€¤", "1å¹´é«˜å€¤", "å²ä¸Šæœ€é«˜å€¤ï¼ˆATHï¼‰"],
                index=0,
                help="æš´è½åˆ¤å®šã®åŸºæº–ã¨ãªã‚‹é«˜å€¤ã®å®šç¾©"
            )
            
            # Deployment settings
            mc_cash_deploy_ratio = st.slider(
                "1å›ã‚ãŸã‚Šç¾é‡‘æŠ•å…¥æ¯”ç‡ (%)",
                min_value=10,
                max_value=100,
                value=30,
                step=5,
                help="æš´è½1å›ã‚ãŸã‚Šã€ç¾é‡‘ã®ä½•%ã‚’æŠ•å…¥ã™ã‚‹ã‹"
            )
            
            mc_max_buy_events = st.selectbox(
                "æœ€å¤§æŠ•å…¥å›æ•°ï¼ˆæ®µéšçš„ãƒŠãƒ³ãƒ”ãƒ³ï¼‰",
                [1, 2, 3, 4, 5],
                index=2,
                help="ä½•å›ã«åˆ†ã‘ã¦è²·ã„å¢—ã™ã‹ï¼ˆä¾‹: 3å› = 3æ®µéšãƒŠãƒ³ãƒ”ãƒ³ï¼‰"
            )
            
            # Asset allocation
            st.caption("ğŸ“Š æŠ•å…¥è³‡é‡‘ã®é…åˆ†")
            mc_buy_btc_ratio = st.slider(
                "BTC (%)",
                min_value=0,
                max_value=100,
                value=50,
                step=5,
                help="æŠ•å…¥è³‡é‡‘ã®ã†ã¡BTCã«å……ã¦ã‚‹æ¯”ç‡"
            )
            mc_buy_gold_ratio = st.slider(
                "Gold (%)",
                min_value=0,
                max_value=100,
                value=50,
                step=5,
                help="æŠ•å…¥è³‡é‡‘ã®ã†ã¡Goldã«å……ã¦ã‚‹æ¯”ç‡"
            )
            mc_buy_stocks_ratio = st.slider(
                "æ ªå¼ (%) ã€What-ifã€‘",
                min_value=0,
                max_value=100,
                value=0,
                step=5,
                help="æŠ•å…¥è³‡é‡‘ã®ã†ã¡æ ªå¼ã«å……ã¦ã‚‹æ¯”ç‡ï¼ˆWhat-ifç”¨ï¼‰"
            )
            
            # Validate ratios
            total_ratio = mc_buy_btc_ratio + mc_buy_gold_ratio + mc_buy_stocks_ratio
            if total_ratio != 100:
                st.warning(f"âš ï¸ é…åˆ†åˆè¨ˆãŒ{total_ratio}%ã§ã™ï¼ˆ100%æ¨å¥¨ï¼‰")
        
        # Display current asset summary
        st.markdown("---")
        st.markdown("### ğŸ“Š ç¾åœ¨ã®è³‡ç”£ã‚µãƒãƒªãƒ¼")
        
        mc_btc_value = mc_btc_amount * mc_btc_price
        mc_total_assets = mc_btc_value + mc_gold_amount + mc_stocks_amount + mc_cash + mc_investment_trust
        
        col_sum1, col_sum2, col_sum3 = st.columns(3)
        with col_sum1:
            st.metric("BTCè©•ä¾¡é¡", f"Â¥{mc_btc_value:.0f}ä¸‡")
            st.metric("Gold", f"Â¥{mc_gold_amount:.0f}ä¸‡")
        with col_sum2:
            st.metric("æ ªå¼/ETF", f"Â¥{mc_stocks_amount:.0f}ä¸‡")
            st.metric("æŠ•è³‡ä¿¡è¨—", f"Â¥{mc_investment_trust:.0f}ä¸‡")
        with col_sum3:
            st.metric("ç¾é‡‘", f"Â¥{mc_cash:.0f}ä¸‡")
            st.metric("ç·è³‡ç”£", f"Â¥{mc_total_assets:.0f}ä¸‡", delta=f"æœˆ+{mc_monthly_deposit}ä¸‡")
        
        st.markdown("---")
        st.markdown("### ğŸš€ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ")
        
        # Store parameters for simulation
        mc_params = {
            "btc_amount": mc_btc_amount,
            "btc_price": mc_btc_price * 10000,  # Convert to yen
            "gold_amount": mc_gold_amount * 10000,
            "stocks_amount": mc_stocks_amount * 10000,
            "cash": mc_cash * 10000,
            "investment_trust": mc_investment_trust * 10000,
            "monthly_deposit": mc_monthly_deposit * 10000,
            "survival_line": mc_survival_line * 10000,
            "years": mc_simulation_years,
            "trials": mc_num_trials,
            "buy_ratio": {
                "btc": mc_buy_btc_ratio / 100,
                "gold": mc_buy_gold_ratio / 100,
                "stocks": mc_buy_stocks_ratio / 100
            },
            "dip_settings": {
                "cash_deploy_ratio": mc_cash_deploy_ratio / 100,
                "max_buy_events": mc_max_buy_events,
                "crash_threshold": mc_crash_threshold / 100,
                "high_reference": mc_high_reference
            }
        }
        
        col_btn1, col_btn2 = st.columns(2)
        
        with col_btn1:
            if st.button("ğŸ§  Step 1: Claudeã§æˆ¦ç•¥è¨­è¨ˆ", type="primary", key="mc_claude"):
                # Claude prompt for strategy design
                claude_mc_prompt = f"""ã‚ãªãŸã¯é‡‘èå·¥å­¦ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®æ¡ä»¶ã«åŸºã¥ã„ã¦ã€10å¹´é–“ã®ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãŸã‚ã®å¤‰æ•°ã¨ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚

ã€ç¾åœ¨ã®è³‡ç”£çŠ¶æ³ã€‘
- BTCä¿æœ‰é‡: {mc_btc_amount} BTCï¼ˆå£²å´äºˆå®šãªã—ã€é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ç­‰ã®ç ´æ»…çš„ãƒªã‚¹ã‚¯æ™‚ã®ã¿ä¾‹å¤–ï¼‰
- ç¾é‡‘: {mc_cash}ä¸‡å††ï¼ˆæ¯æœˆ{mc_monthly_deposit}ä¸‡å††è¿½åŠ å…¥é‡‘ï¼‰
- æŠ•è³‡ä¿¡è¨—: {mc_investment_trust}ä¸‡å††ï¼ˆæ”¾ç½®ï¼‰
- BTCç¾åœ¨ä¾¡æ ¼: {mc_btc_price}ä¸‡å††

ã€æŠ•è³‡æˆ¦ç•¥ã€‘
Buy the Dipæˆ¦ç•¥: ç¾é‡‘ã‹ã‚‰BTCã¨Goldã‚’æš´è½æ™‚ã®ã¿è³¼å…¥

ã€ãƒªã‚¹ã‚¯è¨±å®¹åº¦ã€‘
ç”Ÿå­˜ãƒ©ã‚¤ãƒ³: BTCå††å»ºã¦{mc_survival_line}ä¸‡å††ã¾ã§ä¸‹è½ã—ã¦ã‚‚ãƒ¡ãƒ³ã‚¿ãƒ«å®‰å®šã‚’ç¶­æŒ

ã€å‡ºåŠ›è¦æ±‚ã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

```json
{{
  "parameters": {{
    "btc": {{"expected_return": å¹´ç‡æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³, "volatility": å¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£, "description": "èª¬æ˜"}},
    "gold": {{"expected_return": å¹´ç‡æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³, "volatility": å¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£, "description": "èª¬æ˜"}},
    "cash": {{"expected_return": å¹´ç‡æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³, "volatility": å¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£, "description": "èª¬æ˜"}},
    "investment_trust": {{"expected_return": å¹´ç‡æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³, "volatility": å¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£, "description": "èª¬æ˜"}}
  }},
  "correlation_matrix": {{
    "btc_gold": BTC-Goldç›¸é–¢ä¿‚æ•°,
    "btc_cash": BTC-ç¾é‡‘ç›¸é–¢ä¿‚æ•°,
    "gold_cash": Gold-ç¾é‡‘ç›¸é–¢ä¿‚æ•°
  }},
  "crash_threshold": æš´è½åˆ¤å®šé–¾å€¤ï¼ˆä¾‹: -0.30 ã¯ç›´è¿‘é«˜å€¤ã‹ã‚‰30%ä¸‹è½ï¼‰,
  "buy_amount_ratio": æš´è½æ™‚ã®ç¾é‡‘ã‹ã‚‰ã®è³¼å…¥æ¯”ç‡,
  "strategy_rationale": "æˆ¦ç•¥ã®æ ¹æ‹ èª¬æ˜",
  "risk_analysis": "ãƒªã‚¹ã‚¯åˆ†æ",
  "best_case_scenario": "æœ€è‰¯ã‚·ãƒŠãƒªã‚ªã®èª¬æ˜",
  "worst_case_scenario": "æœ€æ‚ªã‚·ãƒŠãƒªã‚ªã®èª¬æ˜"
}}
```

éå»ã®BTCãƒ»Goldãƒ»æ ªå¼å¸‚å ´ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ç¾å®Ÿçš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"""
                
                with st.spinner("ğŸ§  Claude 4.5 Opus ãŒæˆ¦ç•¥ã‚’è¨­è¨ˆä¸­..."):
                    try:
                        claude_response = claude_client.messages.create(
                            model=CLAUDE_MODEL,
                            max_tokens=4096,
                            messages=[
                                {"role": "user", "content": claude_mc_prompt}
                            ]
                        )
                        claude_result = claude_response.content[0].text
                        
                        # Store in session state
                        st.session_state['mc_params'] = mc_params
                        st.session_state['mc_claude_result'] = claude_result
                        
                        st.success("âœ… æˆ¦ç•¥è¨­è¨ˆå®Œäº†ï¼")
                        
                        # Display Claude's response
                        st.markdown("### ğŸ§  Claude 4.5 Opus æˆ¦ç•¥è¨­è¨ˆçµæœ")
                        st.markdown(claude_result)
                        
                        # Try to parse JSON from response
                        import re
                        json_match = re.search(r'```json\s*(.*?)\s*```', claude_result, re.DOTALL)
                        if json_match:
                            try:
                                import json
                                strategy_params = json.loads(json_match.group(1))
                                st.session_state['mc_strategy_params'] = strategy_params
                                st.success("âœ… ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ¼ã‚¹å®Œäº†ã€‚Step 2ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œå¯èƒ½ã§ã™ã€‚")
                            except json.JSONDecodeError:
                                st.warning("âš ï¸ JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã€‚æ‰‹å‹•ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                        
                    except Exception as e:
                        st.error(f"âŒ Claude ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        with col_btn2:
            if st.button("âš¡ Step 2: Geminiã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ", type="secondary", key="mc_gemini"):
                if 'mc_strategy_params' not in st.session_state:
                    st.warning("âš ï¸ ã¾ãšStep 1ã§Claudeã«ã‚ˆã‚‹æˆ¦ç•¥è¨­è¨ˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                else:
                    strategy = st.session_state['mc_strategy_params']
                    params = st.session_state.get('mc_params', mc_params)
                    
                    # Build Gemini prompt for simulation
                    gemini_mc_prompt = f"""ä»¥ä¸‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’Pythonã§å®Ÿè¡Œã—ã€çµæœã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‘
{json.dumps(strategy, indent=2, ensure_ascii=False)}

ã€åˆæœŸè³‡ç”£ã€‘
- BTC: {params['btc_amount']} BTC Ã— ç¾åœ¨ä¾¡æ ¼
- ç¾é‡‘: {params['cash']:,.0f}å††
- æŠ•è³‡ä¿¡è¨—: {params['investment_trust']:,.0f}å††
- æœˆé–“è¿½åŠ å…¥é‡‘: {params['monthly_deposit']:,.0f}å††

ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¡ä»¶ã€‘
- æœŸé–“: {params['years']}å¹´ï¼ˆ{params['years'] * 12}ãƒ¶æœˆï¼‰
- è©¦è¡Œå›æ•°: {params['trials']:,}å›
- ç”Ÿå­˜ãƒ©ã‚¤ãƒ³: BTCå††å»ºã¦ {params['survival_line']:,.0f}å††

ã€æ¯”è¼ƒãƒ‘ã‚¿ãƒ¼ãƒ³ã€‘
A) ç¾çŠ¶ç¶­æŒ: æ¯æœˆå…¥é‡‘ã®ã¿ã€è¿½åŠ æŠ•è³‡ãªã—
B) Buy-the-Dip: æš´è½æ™‚ï¼ˆé–¾å€¤ä»¥ä¸‹ï¼‰ã«BTC/Goldã‚’è³¼å…¥

ã€å‡ºåŠ›è¦æ±‚ã€‘
ä»¥ä¸‹ã®å½¢å¼ã§çµæœã‚’æ—¥æœ¬èªã§å ±å‘Šã—ã¦ãã ã•ã„ï¼š

1. **è³‡ç”£äºˆæ¸¬ã‚µãƒãƒªãƒ¼**ï¼ˆè¡¨å½¢å¼ï¼‰
   | æœŸé–“ | æˆ¦ç•¥ | ä¸­å¤®å€¤ | ä¸Šä½10% | ä¸‹ä½10% |
   
2. **ãƒªã‚¹ã‚¯åˆ†æ**
   - ç”Ÿå­˜ãƒ©ã‚¤ãƒ³({params['survival_line']:,.0f}å††)ã‚’ä¸‹å›ã‚‹ç¢ºç‡
   - æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã®ä¸­å¤®å€¤
   
3. **æœ€é©è²·ã„ã‚¿ã‚¤ãƒŸãƒ³ã‚°**
   - Buy-the-Dipã®åŠ¹æœãŒæœ€å¤§åŒ–ã™ã‚‹æ¡ä»¶
   - æ¨å¥¨é–¾å€¤ã¨è³¼å…¥æ¯”ç‡

4. **çµè«–ã¨æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**
   - ã©ã¡ã‚‰ã®æˆ¦ç•¥ãŒå„ªã‚Œã¦ã„ã‚‹ã‹
   - å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³

ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã«åŸºã¥ã„ã¦ã€å°‚é–€çš„ã‹ã¤å…·ä½“çš„ã«åˆ†æã—ã¦ãã ã•ã„ã€‚"""
                    
                    with st.spinner(f"âš¡ Gemini 3 Flash ãŒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸­... ({params['trials']:,}å›è©¦è¡Œ)"):
                        try:
                            gemini_response = gemini_client.models.generate_content(
                                model=GEMINI_MODEL,
                                contents=gemini_mc_prompt
                            )
                            gemini_result = gemini_response.text
                            
                            # Store results
                            st.session_state['mc_gemini_result'] = gemini_result
                            st.session_state['mc_simulation_complete'] = True
                            
                            st.success(f"âœ… ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†ï¼ï¼ˆ{params['trials']:,}å›è©¦è¡Œï¼‰")
                            
                        except Exception as e:
                            st.error(f"âŒ Gemini ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        # Results display
        st.markdown("---")
        st.markdown("### ğŸ“ˆ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ")
        
        if 'mc_gemini_result' in st.session_state and st.session_state.get('mc_simulation_complete'):
            st.markdown(st.session_state['mc_gemini_result'])
            
            # Additional analysis section
            st.markdown("---")
            st.markdown("### ğŸ“Š è¿½åŠ åˆ†æ")
            
            if 'mc_strategy_params' in st.session_state:
                strategy = st.session_state['mc_strategy_params']
                
                col_analysis1, col_analysis2 = st.columns(2)
                
                with col_analysis1:
                    st.markdown("#### ğŸ“‹ ä½¿ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
                    if 'parameters' in strategy:
                        for asset, params_data in strategy['parameters'].items():
                            if isinstance(params_data, dict):
                                st.markdown(f"**{asset.upper()}**")
                                st.caption(f"æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³: {params_data.get('expected_return', 'N/A')}")
                                st.caption(f"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {params_data.get('volatility', 'N/A')}")
                
                with col_analysis2:
                    st.markdown("#### âš™ï¸ æˆ¦ç•¥è¨­å®š")
                    # Show user-defined settings from mc_params
                    user_params = st.session_state.get('mc_params', {})
                    dip_settings = user_params.get('dip_settings', {})
                    
                    crash_val = dip_settings.get('crash_threshold', strategy.get('crash_threshold', 'N/A'))
                    if isinstance(crash_val, (int, float)):
                        crash_val = f"{crash_val:.0%}" if abs(crash_val) < 1 else f"{crash_val}%"
                    st.metric("æš´è½é–¾å€¤", crash_val)
                    
                    deploy_val = dip_settings.get('cash_deploy_ratio', strategy.get('buy_amount_ratio', 'N/A'))
                    if isinstance(deploy_val, (int, float)):
                        deploy_val = f"{deploy_val:.0%}" if deploy_val < 1 else f"{deploy_val}%"
                    st.metric("ç¾é‡‘æŠ•å…¥æ¯”ç‡", deploy_val)
                    
                    max_events = dip_settings.get('max_buy_events', 'N/A')
                    st.metric("æœ€å¤§æŠ•å…¥å›æ•°", f"{max_events}å›" if max_events != 'N/A' else 'N/A')
        else:
            st.caption("Step 1 ã¨ Step 2 ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã“ã“ã«çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
        
        # Parameter preview
        with st.expander("ğŸ“‹ å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿", expanded=False):
            st.json(mc_params)
        
        if 'mc_strategy_params' in st.session_state:
            with st.expander("ğŸ§  Claudeç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿", expanded=False):
                st.json(st.session_state['mc_strategy_params'])
        
        # Follow-up questions section
        if 'mc_gemini_result' in st.session_state and st.session_state.get('mc_simulation_complete'):
            st.markdown("---")
            st.markdown("### ğŸ’¬ çµæœã«ã¤ã„ã¦ã®è¿½åŠ è³ªå•")
            st.caption("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã«ã¤ã„ã¦è‡ªç”±ã«è³ªå•ã§ãã¾ã™")
            
            # Preset question suggestions
            st.markdown("**ğŸ’¡ è³ªå•ä¾‹ï¼š**")
            preset_questions = [
                "BTCãŒ50%ä¸‹è½ã—ãŸå ´åˆã€ç·è³‡ç”£ã¯ã©ã†ãªã‚Šã¾ã™ã‹ï¼Ÿ",
                "æœˆé–“å…¥é‡‘é¡ã‚’å€ã«ã—ãŸå ´åˆã®åŠ¹æœã¯ï¼Ÿ",
                "Goldæ¯”ç‡ã‚’å¢—ã‚„ã—ãŸå ´åˆã®ãƒªã‚¹ã‚¯è»½æ¸›åŠ¹æœã¯ï¼Ÿ",
                "æœ€æ‚ªã®ã‚·ãƒŠãƒªã‚ªã§ã„ãã‚‰æ®‹ã‚Šã¾ã™ã‹ï¼Ÿ",
                "Buy-the-Dipã‚’3å›å®Ÿè¡Œã—ãŸå ´åˆã®æœŸå¾…å€¤ã¯ï¼Ÿ"
            ]
            st.caption(" / ".join(preset_questions[:3]))
            
            mc_followup_question = st.text_area(
                "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                placeholder="ä¾‹: ã‚‚ã—æœˆé–“å…¥é‡‘ã‚’50ä¸‡å††ã«å¢—ã‚„ã—ãŸã‚‰ã€10å¹´å¾Œã®è³‡ç”£ã¯ã©ã†å¤‰ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
                height=100,
                key="mc_followup_input"
            )
            
            col_q1, col_q2 = st.columns(2)
            
            with col_q1:
                if st.button("ğŸ§  Claudeã«è³ªå•", key="mc_followup_claude"):
                    if mc_followup_question:
                        followup_prompt = f"""ä»¥ä¸‹ã®ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã¨è³ªå•ã«åŸºã¥ã„ã¦ã€å°‚é–€çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã€‘
{st.session_state.get('mc_gemini_result', '')}

ã€ä½¿ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‘
{json.dumps(st.session_state.get('mc_strategy_params', {}), indent=2, ensure_ascii=False)}

ã€åˆæœŸè³‡ç”£è¨­å®šã€‘
{json.dumps(st.session_state.get('mc_params', mc_params), indent=2, ensure_ascii=False)}

ã€è³ªå•ã€‘
{mc_followup_question}

å…·ä½“çš„ãªæ•°å€¤ã‚„æ ¹æ‹ ã‚’ç¤ºã—ãªãŒã‚‰å›ç­”ã—ã¦ãã ã•ã„ã€‚"""
                        
                        with st.spinner("ğŸ§  Claude ãŒå›ç­”ä¸­..."):
                            try:
                                response = claude_client.messages.create(
                                    model=CLAUDE_MODEL,
                                    max_tokens=4096,
                                    messages=[{"role": "user", "content": followup_prompt}]
                                )
                                st.markdown("### ğŸ§  Claude ã®å›ç­”")
                                st.markdown(response.content[0].text)
                            except Exception as e:
                                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    else:
                        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            
            with col_q2:
                if st.button("âš¡ Geminiã«è³ªå•", key="mc_followup_gemini"):
                    if mc_followup_question:
                        followup_prompt = f"""ä»¥ä¸‹ã®ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã¨è³ªå•ã«åŸºã¥ã„ã¦ã€å°‚é–€çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã€‘
{st.session_state.get('mc_gemini_result', '')}

ã€ä½¿ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‘
{json.dumps(st.session_state.get('mc_strategy_params', {}), indent=2, ensure_ascii=False)}

ã€åˆæœŸè³‡ç”£è¨­å®šã€‘
{json.dumps(st.session_state.get('mc_params', mc_params), indent=2, ensure_ascii=False)}

ã€è³ªå•ã€‘
{mc_followup_question}

å…·ä½“çš„ãªæ•°å€¤ã‚„æ ¹æ‹ ã‚’ç¤ºã—ãªãŒã‚‰å›ç­”ã—ã¦ãã ã•ã„ã€‚"""
                        
                        with st.spinner("âš¡ Gemini ãŒå›ç­”ä¸­..."):
                            try:
                                response = gemini_client.models.generate_content(
                                    model=GEMINI_MODEL,
                                    contents=followup_prompt
                                )
                                st.markdown("### âš¡ Gemini ã®å›ç­”")
                                st.markdown(response.text)
                            except Exception as e:
                                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")

# Tab 7: Market Voices
with tabs[6]:
    st.subheader("ğŸ“° Market Voices")
    st.caption("ğŸ’¡ AI ãŒä¸–ç•Œä¸­ã®ä¸€æ¬¡æƒ…å ±ã‚’è‡ªå‹•ã‚¹ã‚­ãƒ£ãƒ³ - é‡è¦åº¦ã§ãƒ©ãƒ³ã‚¯ä»˜ã‘")
    
    # --- Auto Intelligence Scanner ---
    st.markdown("### ğŸ¤– å…¨è‡ªå‹•ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ãƒ»ã‚¹ã‚­ãƒ£ãƒŠãƒ¼")
    st.caption("13ã‚«ãƒ†ã‚´ãƒªã‚’è‡ªå‹•å·¡å›ã—ã€AIãŒé‡è¦åº¦ã‚’åˆ¤å®šã—ã¦ä¸Šä½ã®ã¿è¡¨ç¤º")
    
    # ç›£è¦–ã‚«ãƒ†ã‚´ãƒªå®šç¾©
    CONTEXT_KEYWORDS = {
            "ğŸŒ åœ°æ”¿å­¦ãƒªã‚¹ã‚¯ (Geopolitics)": {
                "keywords": ["geopolitical risk", "sanctions", "trade war", "military conflict", "territorial dispute"],
                "desc": "åˆ¶è£ãƒ»è²¿æ˜“æˆ¦äº‰ãƒ»è»äº‹ç´›äº‰",
                "main_keyword": "geopolitical risk"
            },
            "ğŸ“Š ãƒã‚¯ãƒ­çµŒæ¸ˆ (Macro)": {
                "keywords": ["recession risk", "inflation outlook", "GDP growth", "economic slowdown", "yield curve"],
                "desc": "æ™¯æ°—å¾Œé€€ãƒ»ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ»GDP",
                "main_keyword": "recession risk"
            },
            "ğŸ›ï¸ ä¸­å¤®éŠ€è¡Œ (Central Bank)": {
                "keywords": ["Fed policy", "rate cut", "rate hike", "quantitative tightening", "balance sheet"],
                "desc": "åˆ©ä¸‹ã’ãƒ»QTãƒ»ãƒãƒ©ãƒ³ã‚¹ã‚·ãƒ¼ãƒˆ",
                "main_keyword": "Fed policy"
            },
            "ğŸ’§ æµå‹•æ€§ãƒ»é…ç®¡ (Liquidity/Plumbing)": {
                "keywords": ["liquidity crisis", "repo market", "reserve scarcity", "ON RRP", "bank reserves"],
                "desc": "ãƒ¬ãƒãƒ»æº–å‚™é‡‘ãƒ»ON RRP",
                "main_keyword": "liquidity crisis"
            },
            "ğŸ›¢ï¸ ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£ (Commodities)": {
                "keywords": ["oil price", "gold rally", "copper demand", "supply chain", "commodity shortage"],
                "desc": "åŸæ²¹ãƒ»é‡‘ãƒ»éŠ…ãƒ»ä¾›çµ¦åˆ¶ç´„",
                "main_keyword": "oil price gold"
            },
            "â‚¿ ä»®æƒ³é€šè²¨ (Crypto)": {
                "keywords": ["Bitcoin regulation", "crypto ETF", "stablecoin", "CBDC", "mining ban"],
                "desc": "BTCè¦åˆ¶ãƒ»ETFãƒ»ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚³ã‚¤ãƒ³",
                "main_keyword": "Bitcoin regulation"
            },
            "ğŸ¦ éŠ€è¡Œãƒ»ä¿¡ç”¨ (Banking/Credit)": {
                "keywords": ["bank stress", "credit crunch", "loan defaults", "commercial real estate", "deposit flight"],
                "desc": "éŠ€è¡Œç ´ç¶»ãƒ»ä¿¡ç”¨åç¸®ãƒ»CRE",
                "main_keyword": "bank stress"
            },
            "ğŸ¢ ä¸å‹•ç”£ (Real Estate)": {
                "keywords": ["commercial real estate crisis", "office vacancy", "mortgage rates", "housing bubble"],
                "desc": "å•†æ¥­ç”¨ä¸å‹•ç”£ãƒ»ã‚ªãƒ•ã‚£ã‚¹ç©ºå®¤ãƒ»ä½å®…",
                "main_keyword": "commercial real estate"
            },
            "ğŸ’µ é€šè²¨ãƒ»ç‚ºæ›¿ (Currency/FX)": {
                "keywords": ["dollar strength", "yen weakness", "currency crisis", "dedollarization", "forex intervention"],
                "desc": "ãƒ‰ãƒ«é«˜ãƒ»å††å®‰ãƒ»ä»‹å…¥",
                "main_keyword": "dollar strength"
            },
            "ğŸ“‰ æ ªå¼ãƒ»ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ (Equity)": {
                "keywords": ["stock market bubble", "valuation concerns", "earnings recession", "tech selloff", "market correction"],
                "desc": "ãƒãƒ–ãƒ«ãƒ»ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»æ±ºç®—",
                "main_keyword": "stock market bubble"
            },
            "ğŸ‡¨ğŸ‡³ ä¸­å›½ (China)": {
                "keywords": ["China economy", "property crisis", "capital outflow", "yuan devaluation", "stimulus"],
                "desc": "ä¸­å›½çµŒæ¸ˆãƒ»ä¸å‹•ç”£å±æ©Ÿãƒ»è³‡æœ¬æµå‡º",
                "main_keyword": "China economy"
            },
            "ğŸ‡ªğŸ‡º æ¬§å· (Europe)": {
                "keywords": ["ECB policy", "eurozone recession", "energy crisis", "debt crisis", "banking union"],
                "desc": "ECBãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼å±æ©Ÿãƒ»å‚µå‹™",
                "main_keyword": "ECB policy"
            },
            "ğŸŒ æ–°èˆˆå›½ (Emerging Markets)": {
                "keywords": ["emerging market crisis", "capital flight", "debt default", "currency collapse", "IMF bailout"],
                "desc": "æ–°èˆˆå›½å±æ©Ÿãƒ»é€šè²¨æš´è½ãƒ»IMF",
                "main_keyword": "emerging market crisis"
            },
        }
        
    # Auto-scan controls
    col_btn1, col_btn2 = st.columns([3, 1])
    
    with col_btn1:
        st.caption("**ç›£è¦–å¯¾è±¡**: 13ã‚«ãƒ†ã‚´ãƒªï¼ˆåœ°æ”¿å­¦ã€ä¸­éŠ€ã€æµå‹•æ€§ã€æš—å·è³‡ç”£ã€éŠ€è¡Œã€ä¸å‹•ç”£ã€ç‚ºæ›¿ã€æ ªå¼ã€ä¸­å›½ã€æ¬§å·ã€æ–°èˆˆå›½ç­‰ï¼‰")
    
    with col_btn2:
        # Show cached results if available
        if 'daily_briefing_cache' in st.session_state and st.session_state.get('daily_briefing_cache'):
            scan_time = st.session_state.get('daily_briefing_time', 'Unknown')
            st.caption(f"âœ… æœ€çµ‚ã‚¹ã‚­ãƒ£ãƒ³: {scan_time}")
    
    # Main auto-scan button
    if st.button("ğŸš€ ä»Šæ—¥ã®ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ã‚’è‡ªå‹•å–å¾—", type="primary", key="auto_scan_btn", help="å…¨13ã‚«ãƒ†ã‚´ãƒªã‚’å·¡å›ã—ã€AIãŒé‡è¦åº¦åˆ¤å®š"):
        if gemini_client:
            all_findings = []
            
            with st.status("ğŸŒ å…¨ã‚«ãƒ†ã‚´ãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­...", expanded=True) as status:
                # Sample top 3 high-priority categories instead of all 13 to avoid timeout
                priority_categories = [
                    "ğŸ›ï¸ ä¸­å¤®éŠ€è¡Œ (Central Bank)",
                    "ğŸ’§ æµå‹•æ€§ãƒ»é…ç®¡ (Liquidity/Plumbing)", 
                    "ğŸ¦ éŠ€è¡Œãƒ»ä¿¡ç”¨ (Banking/Credit)"
                ]
                
                for category in priority_categories:
                    st.write(f"ğŸ“¡ {category} ã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­...")
                    try:
                        keyword = CONTEXT_KEYWORDS[category]["main_keyword"]
                        # Get news from primary sources only
                        news_us = search_google_news(keyword, num_results=2, gl='US', mode='primary')
                        
                        if news_us and "è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ" not in news_us:
                            # Quick AI scoring (simplified)
                            all_findings.append({
                                'category': category,
                                'keyword': keyword,
                                'headlines': news_us
                            })
                    except:
                        pass
                
                status.update(label="âœ… ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†", state="complete", expanded=False)
            
            # Store results
            if all_findings:
                st.session_state['daily_briefing_cache'] = all_findings
                st.session_state['daily_briefing_time'] = datetime.datetime.now().strftime('%H:%M')
                
                st.success(f"âœ… {len(all_findings)} ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰ä¸€æ¬¡æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ")
                
                # Display findings
                for finding in all_findings:
                    with st.expander(f"ğŸ“Š {finding['category']}", expanded=True):
                        st.caption(f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {finding['keyword']}")
                        st.markdown(finding['headlines'])
            else:
                st.warning("âš ï¸ ä¸€æ¬¡æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å¾Œã»ã©å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
        else:
            st.error("âš ï¸ Gemini APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™")
    
    # Display cached results
    elif 'daily_briefing_cache' in st.session_state and st.session_state.get('daily_briefing_cache'):
        st.info(f"ğŸ“‹ å‰å›ã‚¹ã‚­ãƒ£ãƒ³çµæœã‚’è¡¨ç¤ºä¸­ï¼ˆ{st.session_state.get('daily_briefing_time', 'Unknown')}ï¼‰")
        
        for finding in st.session_state['daily_briefing_cache']:
            with st.expander(f"ğŸ“Š {finding['category']}", expanded=False):
                st.caption(f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {finding['keyword']}")
                st.markdown(finding['headlines'])
    
    st.markdown("---")
    
    # Legacy manual search (collapsed)
    with st.expander("ğŸ”§ æ‰‹å‹•æ¤œç´¢ï¼ˆä¸Šç´šè€…å‘ã‘ï¼‰", expanded=False):
        search_query = st.text_input(
            "ã‚«ã‚¹ã‚¿ãƒ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
            placeholder="ä¾‹: Treasury buyback, Meta nuclear power",
            key="manual_search_query"
        )
        
        if st.button("ğŸ” æ‰‹å‹•æ¤œç´¢", key="manual_search_btn"):
            if search_query and gemini_client:
                with st.spinner(f"ğŸ” '{search_query}' ã®ä¸€æ¬¡è³‡æ–™ã‚’ä¸–ç•Œä¸­ã§ãƒãƒ³ãƒ†ã‚£ãƒ³ã‚°ä¸­..."):
                    try:
                        # Step 1: Get multi-region news/reports headlines
                        with st.status("ğŸŒ ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ»ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ç¶²ã‚’èµ°æŸ»ä¸­...") as status:
                            st.write("ğŸ‡ºğŸ‡¸ USå½“å±€ãƒ»ç ”ç©¶æ©Ÿé–¢ã‚’èµ°æŸ»ä¸­...")
                            news_us = search_google_news(search_query, num_results=3, gl='US', mode='primary')
                            st.write("ğŸ‡ªğŸ‡º æ¬§å·ãƒ»å›½éš›æ±ºæ¸ˆéŠ€è¡Œ(BIS)ç­‰ã‚’èµ°æŸ»ä¸­...")
                            news_gb = search_google_news(search_query, num_results=3, gl='GB', mode='primary')
                            st.write("ğŸ‡¸ğŸ‡¬ ã‚¢ã‚¸ã‚¢ãƒ»æ–°èˆˆå›½ã®è¦–ç‚¹ã‚’å–å¾—ä¸­...")
                            news_sg = search_google_news(search_query, num_results=2, gl='SG', mode='primary')
                            
                            news_headlines = f"ã€US Analysisã€‘\n{news_us}\n\nã€Europe/Global Analysisã€‘\n{news_gb}\n\nã€Asia Analysisã€‘\n{news_sg}"
                        status.update(label="âœ… ãƒãƒ³ãƒ†ã‚£ãƒ³ã‚°å®Œäº†", state="complete", expanded=False)
                    except Exception as e:
                        st.error(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
                        news_headlines = None

                    if not news_headlines or "è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ" in news_headlines:
                        st.warning("æŒ‡å®šã—ãŸæ¡ä»¶ã«åˆè‡´ã™ã‚‹ä¸€æ¬¡è³‡æ–™ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    else:
                        # Step 2: Quick AI summary
                        evaluation_prompt = f"""ã€å½¹å‰²ã€‘
ã‚ãªãŸã¯ä¸€æ¬¡æƒ…å ±ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ãƒ»ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚

ã€ç¾åœ¨æ—¥æ™‚ã€‘
{datetime.datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}

ã€æ¢ç´¢çµæœã€‘
{news_headlines}

ã€åˆ†ææŒ‡ç¤ºã€‘
ä»¥ä¸‹ã®åé›†ã•ã‚ŒãŸä¸€æ¬¡è³‡æ–™ã‚’åˆ†æã—ã€å¸‚å ´ã¸ã®å½±éŸ¿ã‚’ç°¡æ½”ã«æ—¥æœ¬èªã§å ±å‘Šã—ã¦ãã ã•ã„ï¼š
1. ç™ºè¦‹ä¾¡å€¤ï¼ˆ0-1.0ï¼‰: ãƒ¡ãƒ‡ã‚£ã‚¢æœªå ±é“ã®é‡è¦åº¦
2. æ§‹é€ çš„ã‚·ã‚°ãƒŠãƒ«ï¼ˆ1-5ï¼‰: é‡‘èã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã®å¤‰åŒ–åº¦
3. å¸‚å ´ã¸ã®å½±éŸ¿äºˆæ¸¬

æ—¥æœ¬èªã§300æ–‡å­—ä»¥å†…ã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"""

                        # Call Gemini for quick analysis
                        try:
                            response = gemini_client.models.generate_content(
                                model=GEMINI_MODEL,
                                contents=evaluation_prompt
                            )
                            
                            st.success("âœ… AIåˆ†æå®Œäº†")
                            st.markdown(response.text)
                        except Exception as e:
                            st.error(f"âŒ AIåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            else:
                st.warning("âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

                        
                        # å …ç‰¢ãªJSONãƒ‘ãƒ¼ã‚¹ï¼ˆFix 3ï¼‰
                        try:
                            # ã¾ãšç›´æ¥ãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œ
                            data = json.loads(response.text)
                        except json.JSONDecodeError:
                            # å¤±æ•—ã—ãŸå ´åˆã€JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºã—ã¦å†è©¦è¡Œ
                            json_match = re.search(r'\{[\s\S]*\}', response.text)
                            if json_match:
                                try:
                                    data = json.loads(json_match.group())
                                except json.JSONDecodeError as e:
                                    st.error(f"âš ï¸ AIå¿œç­”ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                                    st.code(response.text[:500])
                                    data = None
                            else:
                                st.error("âš ï¸ AIå¿œç­”ã«JSONãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                                st.code(response.text[:500])
                                data = None
                        
                        if data:
                            st.markdown(f"## ğŸ›¸ {data['headline']}")
                            
                            col_score1, col_score2, col_score3, col_score4 = st.columns(4)
                            with col_score1:
                                discovery = data.get('discovery_value', 0.0)
                                st.metric("ç™ºè¦‹ä¾¡å€¤", f"{discovery*100:.0f}%", help="ãƒ¡ãƒ‡ã‚£ã‚¢ãŒã¾ã å ±ã˜ã¦ã„ãªã„ã€Œéš ã‚ŒãŸææ–™ã€ã¨ã—ã¦ã®ä¾¡å€¤")
                            with col_score2:
                                prob = data.get('news_generalization_prob', '0%')
                                st.metric("ãƒ‹ãƒ¥ãƒ¼ã‚¹åŒ–ç¢ºç‡", prob, help="æ•°æ—¥ã€œæ•°é€±é–“å†…ã«ä¸€èˆ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹åŒ–ã™ã‚‹å¯èƒ½æ€§")
                            with col_score3:
                                st.metric("ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢", f"{data.get('credibility', 0.0):.2f}")
                            with col_score4:
                                st.metric("è³‡æ–™ã®æ·±åº¦", data.get('source_depth', 'Unknown'))
                            
                            st.markdown("---")
                            
                            col_desc1, col_desc2 = st.columns(2)
                            with col_desc1:
                                st.markdown(f"**ğŸ’¡ ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹è¦ç´„**: {data.get('intelligence_summary_ja', '')}")
                                st.info(f"**ğŸ—ï¸ æ§‹é€ çš„ã‚·ã‚°ãƒŠãƒ«**: ã‚¹ã‚³ã‚¢ {data.get('structural_impact', '-')}/5")
                            with col_desc2:
                                st.markdown(f"**ğŸ›¡ï¸ ãƒªã‚¹ã‚¯ãƒ»è„†å¼±æ€§**: {data.get('vulnerability_check', 'ç‰¹ã«ãªã—')}")

                            st.success(f"**ğŸ§  Pro Insight**: {data.get('pro_insight', '')}")

                            st.markdown("---")
                            st.markdown("### ğŸ“Š 5è»¸ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆæ³¢åŠäºˆæ¸¬")
                            
                            col_row1_1, col_row1_2, col_row1_3 = st.columns(3)
                            col_row2_1, col_row2_2 = st.columns(2)
                            
                            def get_sent_emoji(s):
                                if "Positive" in s: return "ğŸ“ˆ Positive"
                                if "Negative" in s: return "ğŸ“‰ Negative"
                                return "â¡ï¸ Neutral"

                            with col_row1_1:
                                st.markdown("**æ ªãƒ»æš—å·è³‡ç”£**")
                                st.markdown(get_sent_emoji(data['sentiment_matrix'].get('risk_assets', 'Neutral')))
                            with col_row1_2:
                                st.markdown("**ç±³ãƒ‰ãƒ«ãƒ»é‡‘åˆ©**")
                                st.markdown(get_sent_emoji(data['sentiment_matrix'].get('currency_usd', 'Neutral')))
                            with col_row1_3:
                                st.markdown("**ã‚´ãƒ¼ãƒ«ãƒ‰ãƒ»å®‰å…¨è³‡ç”£**")
                                st.markdown(get_sent_emoji(data['sentiment_matrix'].get('safe_haven', 'Neutral')))
                            with col_row2_1:
                                st.markdown("**åŸæ²¹ãƒ»ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£**")
                                st.markdown(get_sent_emoji(data['sentiment_matrix'].get('commodities', 'Neutral')))
                            with col_row2_2:
                                st.markdown("**æ–°èˆˆå›½**")
                                st.markdown(get_sent_emoji(data['sentiment_matrix'].get('emerging_markets', 'Neutral')))
                            
                            st.markdown("---")
                            
                            with st.expander("ğŸ“ XæŠ•ç¨¿ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚³ãƒ”ãƒšç”¨ï¼‰", expanded=True):
                                st.code(data['x_post_format'], language="text")
                                if st.button("ğŸ“‹ ä¸‹æ›¸ãã¨ã—ã¦ä¿å­˜"):
                                    st.toast("ä¿å­˜ã•ã‚Œã¾ã—ãŸï¼ˆãƒ¢ãƒƒã‚¯æ©Ÿèƒ½ï¼‰")

                            st.markdown("---")
                            st.markdown("**ğŸ“° æ¤œç´¢ã•ã‚ŒãŸå…ƒãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦‹å‡ºã—:**")
                            st.caption(news_headlines)
                        
                except Exception as e:
                    st.error(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
                    st.exception(e)
        elif not search_query:
            st.warning("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        else:
            st.error("âš ï¸ Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

    
    st.markdown("---")
    
# --- RSS News Feeds Section ---
    st.markdown("### ğŸ“¡ Global News Feeds")
    
    # Define RSS feeds (using verified working URLs - Google News is most reliable)
    RSS_FEEDS = {
        "ğŸ›ï¸ Fed": "https://www.federalreserve.gov/feeds/press_all.xml",
        "ğŸ‡ªğŸ‡º ECB": "https://www.ecb.europa.eu/rss/press.html",
        "ğŸ‡¯ğŸ‡µ BOJ": "https://www.boj.or.jp/rss/news.xml",
        "ğŸŒ IMF": "https://www.imf.org/en/News/RSS",
        "ğŸ¦ BIS": "https://www.bis.org/content/publications/itms.xml",
        "ğŸ“ˆ Google News (Business)": "https://news.google.com/rss/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx6TVdZU0FtVnVHZ0pWVXlnQVAB?hl=en-US&gl=US&ceid=US:en",
        "ğŸ’¹ Google News (Markets)": "https://news.google.com/rss/search?q=stock+market+breaking&hl=en-US&gl=US&ceid=US:en",
        "ğŸ‡»ğŸ‡ª Venezuela": "https://news.google.com/rss/search?q=Venezuela+US&hl=en-US&gl=US&ceid=US:en",
        "ğŸŒ Global Hub": "https://news.google.com/rss/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx1YlY4U0FtVnVHZ0pWVXlnQVAB?hl=en-US&gl=US&ceid=US:en",
    }
    
    # Create tabs for each feed
    feed_tabs = st.tabs(list(RSS_FEEDS.keys()))
    
    for idx, (feed_name, feed_url) in enumerate(RSS_FEEDS.items()):
        with feed_tabs[idx]:
            try:
                # Add timeout and headers for better reliability
                import urllib.request
                req = urllib.request.Request(feed_url, headers={'User-Agent': 'Mozilla/5.0'})
                with urllib.request.urlopen(req, timeout=10) as response:
                    feed_content = response.read()
                feed = feedparser.parse(feed_content)
                
                if feed.entries:
                    for i, entry in enumerate(feed.entries[:5]):
                        pub_date_raw = entry.get('published', entry.get('updated', 'N/A'))
                        time_diff = get_time_diff_str(pub_date_raw)
                        
                        title = entry.get('title', 'No Title')
                        
                        # å®‰å…¨ãªé®®åº¦åˆ¤å®šï¼ˆã‚¯ãƒ©ãƒƒã‚·ãƒ¥é˜²æ­¢ï¼‰
                        def is_fresh_news(td):
                            if "åˆ†å‰" in td:
                                return True
                            if "æ™‚é–“å‰" in td:
                                match = re.search(r'\d+', td)
                                if match and int(match.group()) < 12:
                                    return True
                            return False
                        
                        emoji = "ğŸ”¥ " if is_fresh_news(time_diff) else "â³ "
                        with st.expander(f"{emoji}{time_diff} - {title}"):
                            st.caption(f"ğŸ“… å…ƒã®æ—¥ä»˜: {pub_date_raw}")
                            summary = entry.get('summary', entry.get('description', 'No summary available'))
                            # Clean HTML tags from summary
                            clean_summary = re.sub('<[^<]+?>', '', summary)
                            st.write(clean_summary[:500] + "..." if len(clean_summary) > 500 else clean_summary)
                            link = entry.get('link', '#')
                            st.markdown(f"[ğŸ”— Read more]({link})")
                else:
                    st.caption("ğŸ“­ è¨˜äº‹ãŒã‚ã‚Šã¾ã›ã‚“")
            except Exception as e:
                st.warning(f"âš ï¸ ãƒ•ã‚£ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿ä¸­... å†è©¦è¡Œã—ã¦ãã ã•ã„")
    
    st.markdown("---")
    
    # --- Quick Geopolitical Risk Monitor with REAL-TIME WEB SEARCH ---
    st.markdown("### ğŸŒ åœ°æ”¿å­¦ãƒªã‚¹ã‚¯ãƒ»ã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒ‹ã‚¿ãƒ¼")
    st.caption("ğŸ” ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ Webæ¤œç´¢ + AIåˆ†æï¼ˆæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã—ã¦åˆ†æï¼‰")
    
    col_geo1, col_geo2, col_geo3 = st.columns(3)
    
    quick_topics = [
        ("ğŸ‡»ğŸ‡ª ãƒ™ãƒã‚ºã‚¨ãƒ©æƒ…å‹¢", "Venezuela US military operation 2026"),
        ("ğŸ‡¨ğŸ‡³ ä¸­å›½ãƒ»å°æ¹¾", "China Taiwan tensions 2026"),
        ("ğŸ›¢ï¸ ä¸­æ±ãƒ»åŸæ²¹", "Middle East oil crisis 2026"),
    ]
    
    for idx, (label, query) in enumerate(quick_topics):
        col = [col_geo1, col_geo2, col_geo3][idx]
        with col:
            if st.button(label, key=f"geo_quick_{idx}"):
                with st.spinner("ğŸ” æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œç´¢ä¸­..."):
                    # Step 1: Get real-time news headlines
                    news_headlines = search_google_news(query)
                    
                    if gemini_client:
                        # Step 2: Send headlines to AI for analysis
                        analysis_prompt = f"""ä»¥ä¸‹ã¯ã€Œ{label}ã€ã«é–¢ã™ã‚‹æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦‹å‡ºã—ã§ã™ã€‚
ã“ã‚Œã‚‰ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«åŸºã¥ã„ã¦ã€å¸‚å ´ã¸ã®å½±éŸ¿ã‚’æ—¥æœ¬èªã§åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢çµæœï¼‰ã€‘
{news_headlines}

ã€åˆ†ææ—¥æ™‚ã€‘
{datetime.datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}

ã€å‡ºåŠ›å½¢å¼ã€‘
1. **çŠ¶æ³è¦ç´„**ï¼ˆ100æ–‡å­—ä»¥å†…ï¼‰
2. **å¸‚å ´ã¸ã®å½±éŸ¿**: å¼·æ°—/å¼±æ°—/ä¸­ç«‹
3. **æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ**

ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å†…å®¹ã«åŸºã¥ã„ã¦å…·ä½“çš„ã«åˆ†æã—ã¦ãã ã•ã„ã€‚"""
                        
                        try:
                            response = gemini_client.models.generate_content(
                                model=GEMINI_MODEL,
                                contents=analysis_prompt
                            )
                            st.success("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢å®Œäº†")
                            st.markdown("**ğŸ“° å–å¾—ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹:**")
                            st.caption(news_headlines)
                            st.markdown("---")
                            st.markdown("**ğŸ¤– AIåˆ†æ:**")
                            st.info(response.text)
                        except Exception as e:
                            st.error(f"AIåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
                    else:
                        st.warning("Gemini APIæœªè¨­å®š")
                        st.markdown("**ğŸ“° å–å¾—ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹:**")
                        st.caption(news_headlines)
    
    st.markdown("---")
    st.info("""
    ğŸ’¡ **Market Voices ã®ä½¿ã„æ–¹**
    - **AI Global Pulse Search**: æ°—ã«ãªã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦AIã«åˆ†æã•ã›ã‚‹
    - **Global News Feeds**: ä¸»è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®æœ€æ–°è¨˜äº‹ã‚’ç¢ºèªï¼ˆGoogle Newsãƒ™ãƒ¼ã‚¹ï¼‰
    - **åœ°æ”¿å­¦ãƒªã‚¹ã‚¯ãƒ»ã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒ‹ã‚¿ãƒ¼**: ğŸ” ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œç´¢ã—ã€AIãŒåˆ†æ
    """)


# Tab 8: Market Sentiment
with tabs[7]:
    st.subheader("ğŸ­ Market Sentiment")
    st.caption("ğŸ’¡ å¸‚å ´å¿ƒç†ã‚’ä¸€ç›®ã§æŠŠæ¡ - Fear & Greedã€Put/Call Ratioã€æŠ•è³‡å®¶å¿ƒç†èª¿æŸ»")
    
    # Fetch all sentiment data
    crypto_fg = get_crypto_fear_greed()
    cnn_fg = get_cnn_fear_greed()
    aaii = get_aaii_sentiment()
    # VIX is already in df from get_market_data()
    vix_value = df.get('VIX').iloc[-1] if df.get('VIX') is not None else None
    
    # === ROW 1: Fear & Greed Gauges ===
    st.markdown("### ğŸ¯ Fear & Greed Index")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### ğŸ“ˆ CNN Fear & Greed (æ ªå¼)")
        if cnn_fg and cnn_fg.get('current'):
            fg_value = cnn_fg['current']
            fg_class = cnn_fg.get('classification', '')
            
            # Color based on value
            if fg_value <= 25:
                color = "ğŸ”´"
                label = "Extreme Fear"
            elif fg_value <= 45:
                color = "ğŸŸ "
                label = "Fear"
            elif fg_value <= 55:
                color = "ğŸŸ¡"
                label = "Neutral"
            elif fg_value <= 75:
                color = "ğŸŸ¢"
                label = "Greed"
            else:
                color = "ğŸŸ£"
                label = "Extreme Greed"
            
            st.metric(f"{color} {label}", f"{fg_value}")
            st.progress(fg_value / 100)
            
            # Chart if available
            if cnn_fg.get('history') is not None and len(cnn_fg['history']) > 0:
                st.caption("ğŸ“Š 30æ—¥é–“ã®æ¨ç§»")
                st.line_chart(cnn_fg['history']['value'], height=120)
        else:
            st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­... (APIåˆ¶é™ã®å¯èƒ½æ€§)")
            st.caption("CNN Fear & Greed Indexã¯å¤–éƒ¨APIã‹ã‚‰å–å¾—ã—ã¾ã™")
    
    with col2:
        st.markdown("#### â‚¿ Crypto Fear & Greed")
        if crypto_fg:
            cfg_value = crypto_fg['current']
            cfg_class = crypto_fg.get('classification', '')
            
            # Color based on value
            if cfg_value <= 25:
                color = "ğŸ”´"
            elif cfg_value <= 45:
                color = "ğŸŸ "
            elif cfg_value <= 55:
                color = "ğŸŸ¡"
            elif cfg_value <= 75:
                color = "ğŸŸ¢"
            else:
                color = "ğŸŸ£"
            
            st.metric(f"{color} {cfg_class}", f"{cfg_value}")
            st.progress(cfg_value / 100)
            
            # æä¾›å…ƒæ›´æ–°æ—¥
            if crypto_fg.get('history') is not None and len(crypto_fg['history']) > 0:
                latest_date = crypto_fg['history'].index[-1]
                st.caption(f"ğŸ”„ æä¾›å…ƒæ›´æ–°æ—¥: {latest_date.strftime('%Y-%m-%d %H:%M')}")
            
            # Chart
            if crypto_fg.get('history') is not None and len(crypto_fg['history']) > 0:
                st.caption("ğŸ“Š 30æ—¥é–“ã®æ¨ç§»")
                st.line_chart(crypto_fg['history']['value'], height=120)
        else:
            st.warning("âš ï¸ Crypto Fear & Greed å–å¾—ã‚¨ãƒ©ãƒ¼")
    
    with col3:
        st.markdown("#### ğŸ“Š VIX (ææ€–æŒ‡æ•°)")
        if vix_value is not None:
            # VIX interpretation
            if vix_value < 15:
                vix_label = "ğŸŸ¢ Low Volatility"
            elif vix_value < 20:
                vix_label = "ğŸŸ¡ Normal"
            elif vix_value < 30:
                vix_label = "ğŸŸ  Elevated"
            else:
                vix_label = "ğŸ”´ High Fear"
            
            st.metric(vix_label, f"{vix_value:.1f}")
            
            # æä¾›å…ƒæ›´æ–°æ—¥
            vix_series = df.get('VIX')
            if vix_series is not None and not vix_series.isna().all():
                latest_vix_date = vix_series.dropna().index[-1]
                st.caption(f"ğŸ”„ æä¾›å…ƒæ›´æ–°æ—¥: {latest_vix_date.strftime('%Y-%m-%d')}")
            
            # VIX chart from df
            if vix_series is not None and not vix_series.isna().all():
                st.caption("ğŸ“Š 60æ—¥é–“ã®æ¨ç§»")
                st.line_chart(vix_series.tail(60), height=120)
        else:
            st.warning("âš ï¸ VIXãƒ‡ãƒ¼ã‚¿ãªã—")
    
    st.markdown("---")
    
    # === ROW 2: AAII Investor Sentiment ===
    st.markdown("### ğŸ‘¥ AAII Investor Sentiment Survey")
    st.caption("å€‹äººæŠ•è³‡å®¶ã®å¿ƒç†èª¿æŸ»ï¼ˆé€±æ¬¡æ›´æ–°ï¼‰- é€†å¼µã‚ŠæŒ‡æ¨™ã¨ã—ã¦æœ‰å")
    
    if aaii:
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ‚ Bullish (å¼·æ°—)", f"{aaii['bullish']:.1f}%")
        with col2:
            st.metric("ğŸ˜ Neutral (ä¸­ç«‹)", f"{aaii['neutral']:.1f}%")
        with col3:
            st.metric("ğŸ» Bearish (å¼±æ°—)", f"{aaii['bearish']:.1f}%")
        with col4:
            spread = aaii['bull_bear_spread']
            # Color and emoji based on spread value
            if spread >= 20:
                spread_emoji = "ğŸ”´"
                spread_hint = "(éç†±æ³¨æ„)"
            elif spread >= 10:
                spread_emoji = "ğŸŸ "
                spread_hint = "(ã‚„ã‚„å¼·æ°—)"
            elif spread >= -10:
                spread_emoji = "ğŸŸ¢"
                spread_hint = "(ä¸­ç«‹)"
            elif spread >= -20:
                spread_emoji = "ğŸŸ "
                spread_hint = "(ã‚„ã‚„å¼±æ°—)"
            else:
                spread_emoji = "ğŸ”´"
                spread_hint = "(åº•æ‰“ã¡ã‚µã‚¤ãƒ³?)"
            st.metric(f"{spread_emoji} Bull-Bear Spread", f"{spread:+.1f}%")
            st.caption(spread_hint)
        
        # æä¾›å…ƒæ›´æ–°æ—¥
        if aaii.get('date'):
            st.caption(f"ğŸ”„ æä¾›å…ƒæ›´æ–°æ—¥: {aaii['date']} (é€±æ¬¡)")
        
        # Visual bar
        st.markdown("**ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†å¸ƒ:**")
        bar_data = pd.DataFrame({
            'ã‚«ãƒ†ã‚´ãƒª': ['Bullish', 'Neutral', 'Bearish'],
            'å‰²åˆ': [aaii['bullish'], aaii['neutral'], aaii['bearish']]
        })
        st.bar_chart(bar_data.set_index('ã‚«ãƒ†ã‚´ãƒª'), height=150)
        
        # Bull-Bear Spread èª­ã¿æ–¹ã‚¬ã‚¤ãƒ‰
        with st.expander("ğŸ“ˆ Bull-Bear Spread ã®èª­ã¿æ–¹"):
            st.markdown("""
            **Bull-Bear Spread** = Bullish(å¼·æ°—)% âˆ’ Bearish(å¼±æ°—)%
            
            | æ•°å€¤ | æ„å‘³ | è§£é‡ˆ |
            |-----|------|------|
            | **+20%ä»¥ä¸Š** | å¼·æ°—å„ªå‹¢ | ğŸ”´ éç†±æ³¨æ„ï¼ˆå¤©äº•ã‚µã‚¤ãƒ³ï¼Ÿï¼‰ |
            | **+10%ã€œ+20%** | ã‚„ã‚„å¼·æ°— | ğŸŸ  æ¥½è¦³çš„ |
            | **âˆ’10%ã€œ+10%** | ä¸­ç«‹ | ğŸŸ¢ ãƒãƒ©ãƒ³ã‚¹è‰¯ã— |
            | **âˆ’10%ã€œâˆ’20%** | ã‚„ã‚„å¼±æ°— | ğŸŸ  æ‚²è¦³çš„ |
            | **âˆ’20%ä»¥ä¸‹** | å¼±æ°—å„ªå‹¢ | ğŸ”´ åº•æ‰“ã¡ã‚µã‚¤ãƒ³ï¼Ÿ |
            
            ğŸ’¡ **é€†å¼µã‚Šæˆ¦ç•¥**: ã¿ã‚“ãªãŒå¼·æ°—ã®æ™‚ã¯å¤©äº•ã€å¼±æ°—ã®æ™‚ã¯åº•ã«ãªã‚Šã‚„ã™ã„ï¼
            """)
        
        if aaii.get('note'):
            st.caption(f"ğŸ“ {aaii['note']}")
    else:
        st.warning("âš ï¸ AAIIãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼")
    
    st.markdown("---")
    
    # === ROW 3: Put/Call Ratio ===
    st.markdown("### ğŸ“Š Put/Call Ratio")
    st.caption("ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¸‚å ´ã®å¼±æ°—/å¼·æ°—åº¦ - é«˜ã„ = å¼±æ°—ã€ä½ã„ = å¼·æ°—")
    
    pc_ratio = get_put_call_ratio()
    if pc_ratio:
        st.metric("Equity P/C Ratio", f"{pc_ratio:.2f}")
    else:
        st.info("ğŸ“ Put/Call Ratioã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’æº–å‚™ä¸­ã§ã™ã€‚VIXã§ä»£æ›¿è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
        # Show VIX as proxy
        if vix_value is not None:
            st.caption(f"VIX (å‚è€ƒ): {vix_value:.1f}")
    
    st.markdown("---")
    
    # === Interpretation Guide ===
    st.markdown("### ğŸ“š ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆæŒ‡æ¨™ã®èª­ã¿æ–¹")
    with st.expander("ğŸ’¡ æŒ‡æ¨™ã®è§£é‡ˆã‚¬ã‚¤ãƒ‰"):
        st.markdown("""
        | æŒ‡æ¨™ | æ¥µç«¯ãªææ€– | ææ€– | ä¸­ç«‹ | å¼·æ¬² | æ¥µç«¯ãªå¼·æ¬² |
        |------|-----------|------|------|------|-----------|
        | **Fear & Greed** | 0-25 | 25-45 | 45-55 | 55-75 | 75-100 |
        | **VIX** | >30 | 20-30 | 15-20 | 10-15 | <10 |
        | **Put/Call** | >1.2 | 0.9-1.2 | 0.7-0.9 | 0.5-0.7 | <0.5 |
        
        **é€†å¼µã‚Šæˆ¦ç•¥ã®ãƒ’ãƒ³ãƒˆ:**
        - ã€ŒExtreme Fearã€ã¯è²·ã„ã®ãƒãƒ£ãƒ³ã‚¹ã‹ã‚‚
        - ã€ŒExtreme Greedã€ã¯åˆ©ç¢ºã®ã‚µã‚¤ãƒ³ã‹ã‚‚
        - AAIIã§å¼·æ°—ãŒæ¥µç«¯ã«å¤šã„æ™‚ã¯æ³¨æ„
        """)

